{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Recognizing Hand-Written Digits with Neural Networks\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "![image.png](img/chengjun.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## Recognizing Hand-Written Digits Using Numpy\n",
    "\n",
    "<div>\n",
    "<img src =\"img/dl20.png\" width = 500 align = 'right'>\n",
    "</div>\n",
    "\n",
    "**Each image has 8*8 = 64 pixels**\n",
    "\n",
    "\n",
    "\n",
    "- input = 64\n",
    "    - [0, 0, 1, 0, ..., 0]\n",
    "- batch size = 100\n",
    "- hidden neurons = 50\n",
    "- output = 10\n",
    "- using relu activation function\n",
    "\n",
    "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
    "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T01:15:53.914700Z",
     "start_time": "2020-08-14T01:15:53.837761Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from sklearn import datasets\n",
    "\n",
    "# load data\n",
    "digits = datasets.load_digits()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T01:16:04.329089Z",
     "start_time": "2020-08-14T01:16:04.324890Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797 1617\n"
     ]
    }
   ],
   "source": [
    "# prepare training sets\n",
    "N, D_in, H, D_out = 100, 64,  50, 10 # batch size, input, hidden, output dimension\n",
    "k = 0.9 # the fraction traning data\n",
    "learning_rate = 1e-6 # 1e-1\n",
    "L = len(digits.data)\n",
    "l = int(L*k)\n",
    "print(L, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T01:17:13.944574Z",
     "start_time": "2020-08-14T01:17:13.915042Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Batches = {}\n",
    "M = 200 # number of batches\n",
    "for j in range(M):\n",
    "    index=list(np.random.randint(l, size=N)) # randomly sample N data points\n",
    "    y = np.zeros((N, 10))\n",
    "    y[np.arange(N), list(digits.target[index])] = 1\n",
    "    x=digits.data[index]\n",
    "    Batches[j]=[x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T15:26:25.905290Z",
     "start_time": "2020-08-13T15:26:25.900012Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# softmax\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x)) # to avoid inf\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def softmaxByRow(x):\n",
    "    e_x = np.exp(x - x.max(axis=1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "# flush print\n",
    "def flushPrint(d):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(str(d))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T01:28:49.913034Z",
     "start_time": "2020-08-14T01:28:42.432292Z"
    },
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =199"
     ]
    }
   ],
   "source": [
    "w1 = np.random.randn(D_in, H)/H \n",
    "w2 = np.random.randn(H, D_out)/H\n",
    "w1c = w1.copy() # for comprision in viz\n",
    "w2c = w2.copy()\n",
    "Loss=defaultdict(lambda:[])\n",
    "# traning \n",
    "for t in range(200):# epoch_num\n",
    "    flushPrint('epoch ='+str( t))\n",
    "    for j in Batches:\n",
    "        x,y=Batches[j]\n",
    "        # Forward\n",
    "        h = x.dot(w1)\n",
    "        h_relu = np.maximum(h, 0)\n",
    "        y_pred = h_relu.dot(w2)\n",
    "        y_pred_soft=softmaxByRow(y_pred)\n",
    "        # loss\n",
    "        loss = np.square(y_pred_soft-y).sum()\n",
    "        Loss[j].append([t,loss])\n",
    "        # Backprop \n",
    "        grad_y_pred = 2.0 * (y_pred_soft-y)\n",
    "        grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "        grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "        grad_h = grad_h_relu.copy()\n",
    "        grad_h[h < 0] = 0 \n",
    "        grad_w1 = x.T.dot(grad_h)\n",
    "        # Update weights\n",
    "        w1 -= learning_rate * grad_w1\n",
    "        w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![image.png](img/dl21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#pytorch-tensors\n",
    "\n",
    "```\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "    # Backprop to compute gradients \n",
    "    # of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T15:26:37.069443Z",
     "start_time": "2020-08-13T15:26:37.062925Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "TestData=digits.data[-(L-l):]\n",
    "PredictData=np.maximum(TestData.dot(w1),0).dot(w2)\n",
    "compare=np.argmax(PredictData,axis=1)-digits.target[-(L-l):]\n",
    "Accuracy=list(compare).count(0)/float(len(compare))\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recognizing Hand-Written Digits Using Pytorch\n",
    "\n",
    "1. Using relu for only one time\n",
    "2. learning rate = 0.1 \n",
    "3. choose to use MSELoss \n",
    "4. Convert y_batch from the form of [1] to the form of [0,1,0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T01:46:11.090955Z",
     "start_time": "2020-05-26T01:46:11.082481Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim, from_numpy\n",
    "import numpy as np\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(digits.data, digits.target,\n",
    "                                                train_size = 0.9, test_size = 0.1, random_state=1)\n",
    "\n",
    "Xtrain = torch.tensor(Xtrain, dtype = torch.float32)\n",
    "ytrain = torch.tensor(ytrain, dtype = torch.int64)\n",
    "Xtest = torch.tensor(Xtest, dtype = torch.float32)\n",
    "ytest = torch.tensor(ytest, dtype = torch.int64)\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "train = torch.utils.data.TensorDataset(Xtrain, ytrain)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test = torch.utils.data.TensorDataset(Xtest, ytest)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T01:46:12.294544Z",
     "start_time": "2020-05-26T01:46:12.287619Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = nn.Linear(64, 50)\n",
    "        self.l2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.l1(x))\n",
    "        out = self.l2(out)\n",
    "        y_pred = F.softmax(out, dim = -1)\n",
    "        return y_pred\n",
    "\n",
    "# our model\n",
    "model = Model()\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1) # learning rate is very sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T01:46:11.636968Z",
     "start_time": "2020-05-26T01:46:11.632848Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def get_prob(y_batch):\n",
    "    y = np.zeros((len(y_batch), 10))\n",
    "    y[np.arange(len(y_batch)), list(y_batch)] = 1\n",
    "    y = torch.tensor(y, dtype = torch.float32)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T01:46:18.013287Z",
     "start_time": "2020-05-26T01:46:13.127312Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/num_epoch | Loss: 0.0959\n",
      "Epoch: 0/num_epoch | Loss: 0.0992\n",
      "Epoch: 0/num_epoch | Loss: 0.0986\n",
      "Epoch: 0/num_epoch | Loss: 0.0944\n",
      "Epoch: 0/num_epoch | Loss: 0.0907\n",
      "Epoch: 0/num_epoch | Loss: 0.0948\n",
      "Epoch: 0/num_epoch | Loss: 0.0895\n",
      "Epoch: 0/num_epoch | Loss: 0.0934\n",
      "Epoch: 0/num_epoch | Loss: 0.0907\n",
      "Epoch: 0/num_epoch | Loss: 0.0876\n",
      "Epoch: 0/num_epoch | Loss: 0.0907\n",
      "Epoch: 0/num_epoch | Loss: 0.0856\n",
      "Epoch: 0/num_epoch | Loss: 0.0893\n",
      "Epoch: 0/num_epoch | Loss: 0.0868\n",
      "Epoch: 0/num_epoch | Loss: 0.0833\n",
      "Epoch: 0/num_epoch | Loss: 0.0864\n",
      "Epoch: 0/num_epoch | Loss: 0.0729\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epoch = 100\n",
    "for k, epoch in enumerate(range(num_epoch)):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = model(x_batch)  \n",
    "        y_batch = get_prob(y_batch)\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        #loss = criterion(torch.max(y_pred, 1)[1], y_batch)\n",
    "        if k % 100 ==0:\n",
    "            print(f'Epoch: {epoch}/num_epoch | Loss: {loss.item():.4f}')\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div><img src=\"img/dl22.png\" align = \"Middle\" width = 300 /></div>\n",
    "\n",
    "<font size = 25>Model Validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T01:46:18.026629Z",
     "start_time": "2020-05-26T01:46:18.015674Z"
    },
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "model.eval()  # Change model to 'eval' mode \n",
    "correct = 0\n",
    "total = 0\n",
    "for xval, yval in test_loader:\n",
    "    outputs = model(xval)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += yval.size(0)\n",
    "    correct += (predicted == yval).sum()\n",
    "\n",
    "print('Test Accuracy: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recognizing Hand-Written Digits with CNN Using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T06:43:08.269932Z",
     "start_time": "2020-05-26T06:43:08.232106Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim, from_numpy\n",
    "import numpy as np\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(digits.data, digits.target,\n",
    "                                                train_size = 0.9, test_size = 0.1, random_state=1)\n",
    "# reshape the vector of length 64 to a matrix of 8*8\n",
    "Xtrain = [i.reshape(8, 8) for i in Xtrain]\n",
    "Xtest  = [i.reshape(8, 8) for i in Xtest]\n",
    "\n",
    "Xtrain = torch.tensor(Xtrain, dtype = torch.float32)\n",
    "ytrain = torch.tensor(ytrain, dtype = torch.int64)\n",
    "Xtest = torch.tensor(Xtest, dtype = torch.float32)\n",
    "ytest = torch.tensor(ytest, dtype = torch.int64)\n",
    "\n",
    "batch_size = 100\n",
    "train = torch.utils.data.TensorDataset(Xtrain, ytrain)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test = torch.utils.data.TensorDataset(Xtest, ytest)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T06:43:12.155505Z",
     "start_time": "2020-05-26T06:43:12.151396Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1617, 8, 8])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T06:53:36.609793Z",
     "start_time": "2020-05-26T06:53:36.605999Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([180, 8, 8])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T06:43:18.292556Z",
     "start_time": "2020-05-26T06:43:18.287053Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  2., 13., 16., 16.,  7.,  0.],\n",
       "        [ 0.,  0., 12., 15., 12., 16., 10.,  0.],\n",
       "        [ 0.,  0., 16.,  9.,  0., 14.,  6.,  0.],\n",
       "        [ 0.,  0.,  3.,  0.,  4., 16.,  1.,  0.],\n",
       "        [ 0.,  0.,  0., 10., 14., 16.,  6.,  0.],\n",
       "        [ 0.,  0.,  3., 16., 16., 11.,  2.,  0.],\n",
       "        [ 0.,  0.,  0.,  9., 14.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., 15.,  6.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T06:53:46.507282Z",
     "start_time": "2020-05-26T06:53:46.502005Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  6., 16., 11.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  9., 16., 16.,  5.,  0.,  0.],\n",
       "        [ 0.,  0.,  8., 16., 16.,  4.,  0.,  0.],\n",
       "        [ 0.,  0., 10., 16., 13.,  0.,  0.,  0.],\n",
       "        [ 0.,  0., 13., 16., 12.,  0.,  0.,  0.],\n",
       "        [ 0.,  0., 10., 16.,  9.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  9., 16., 10.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  4., 15., 16.,  3.,  0.,  0.]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T06:44:01.727676Z",
     "start_time": "2020-05-26T06:44:01.718369Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# CNN Model (2 conv layer)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=2), # in_channels = 1, out_channels = 32, kernel_size= 3\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(3*3*64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "cnn = CNN()\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T06:51:39.067823Z",
     "start_time": "2020-05-26T06:51:36.737097Z"
    },
    "code_folding": [],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Iter [1/16] Loss: 0.0766\n",
      "Epoch [1/5], Iter [2/16] Loss: 0.1281\n",
      "Epoch [1/5], Iter [3/16] Loss: 0.1132\n",
      "Epoch [1/5], Iter [4/16] Loss: 0.0562\n",
      "Epoch [1/5], Iter [5/16] Loss: 0.1689\n",
      "Epoch [1/5], Iter [6/16] Loss: 0.0223\n",
      "Epoch [1/5], Iter [7/16] Loss: 0.0726\n",
      "Epoch [1/5], Iter [8/16] Loss: 0.0336\n",
      "Epoch [1/5], Iter [9/16] Loss: 0.1128\n",
      "Epoch [1/5], Iter [10/16] Loss: 0.0445\n",
      "Epoch [1/5], Iter [11/16] Loss: 0.1064\n",
      "Epoch [1/5], Iter [12/16] Loss: 0.0843\n",
      "Epoch [1/5], Iter [13/16] Loss: 0.1876\n",
      "Epoch [1/5], Iter [14/16] Loss: 0.0871\n",
      "Epoch [1/5], Iter [15/16] Loss: 0.0484\n",
      "Epoch [1/5], Iter [16/16] Loss: 0.0237\n",
      "Epoch [1/5], Iter [17/16] Loss: 0.0027\n",
      "Epoch [2/5], Iter [1/16] Loss: 0.0637\n",
      "Epoch [2/5], Iter [2/16] Loss: 0.0636\n",
      "Epoch [2/5], Iter [3/16] Loss: 0.0870\n",
      "Epoch [2/5], Iter [4/16] Loss: 0.0358\n",
      "Epoch [2/5], Iter [5/16] Loss: 0.0563\n",
      "Epoch [2/5], Iter [6/16] Loss: 0.0901\n",
      "Epoch [2/5], Iter [7/16] Loss: 0.0532\n",
      "Epoch [2/5], Iter [8/16] Loss: 0.0934\n",
      "Epoch [2/5], Iter [9/16] Loss: 0.0656\n",
      "Epoch [2/5], Iter [10/16] Loss: 0.0664\n",
      "Epoch [2/5], Iter [11/16] Loss: 0.0906\n",
      "Epoch [2/5], Iter [12/16] Loss: 0.0122\n",
      "Epoch [2/5], Iter [13/16] Loss: 0.1302\n",
      "Epoch [2/5], Iter [14/16] Loss: 0.1345\n",
      "Epoch [2/5], Iter [15/16] Loss: 0.0308\n",
      "Epoch [2/5], Iter [16/16] Loss: 0.0289\n",
      "Epoch [2/5], Iter [17/16] Loss: 0.0416\n",
      "Epoch [3/5], Iter [1/16] Loss: 0.1061\n",
      "Epoch [3/5], Iter [2/16] Loss: 0.0319\n",
      "Epoch [3/5], Iter [3/16] Loss: 0.0453\n",
      "Epoch [3/5], Iter [4/16] Loss: 0.0667\n",
      "Epoch [3/5], Iter [5/16] Loss: 0.0448\n",
      "Epoch [3/5], Iter [6/16] Loss: 0.0632\n",
      "Epoch [3/5], Iter [7/16] Loss: 0.0150\n",
      "Epoch [3/5], Iter [8/16] Loss: 0.0695\n",
      "Epoch [3/5], Iter [9/16] Loss: 0.0993\n",
      "Epoch [3/5], Iter [10/16] Loss: 0.1005\n",
      "Epoch [3/5], Iter [11/16] Loss: 0.0447\n",
      "Epoch [3/5], Iter [12/16] Loss: 0.0735\n",
      "Epoch [3/5], Iter [13/16] Loss: 0.0721\n",
      "Epoch [3/5], Iter [14/16] Loss: 0.0868\n",
      "Epoch [3/5], Iter [15/16] Loss: 0.0723\n",
      "Epoch [3/5], Iter [16/16] Loss: 0.1377\n",
      "Epoch [3/5], Iter [17/16] Loss: 0.0644\n",
      "Epoch [4/5], Iter [1/16] Loss: 0.0281\n",
      "Epoch [4/5], Iter [2/16] Loss: 0.0462\n",
      "Epoch [4/5], Iter [3/16] Loss: 0.0133\n",
      "Epoch [4/5], Iter [4/16] Loss: 0.0393\n",
      "Epoch [4/5], Iter [5/16] Loss: 0.0414\n",
      "Epoch [4/5], Iter [6/16] Loss: 0.0641\n",
      "Epoch [4/5], Iter [7/16] Loss: 0.0274\n",
      "Epoch [4/5], Iter [8/16] Loss: 0.0094\n",
      "Epoch [4/5], Iter [9/16] Loss: 0.0189\n",
      "Epoch [4/5], Iter [10/16] Loss: 0.0692\n",
      "Epoch [4/5], Iter [11/16] Loss: 0.1650\n",
      "Epoch [4/5], Iter [12/16] Loss: 0.0403\n",
      "Epoch [4/5], Iter [13/16] Loss: 0.1196\n",
      "Epoch [4/5], Iter [14/16] Loss: 0.0699\n",
      "Epoch [4/5], Iter [15/16] Loss: 0.0748\n",
      "Epoch [4/5], Iter [16/16] Loss: 0.0594\n",
      "Epoch [4/5], Iter [17/16] Loss: 0.0053\n",
      "Epoch [5/5], Iter [1/16] Loss: 0.0327\n",
      "Epoch [5/5], Iter [2/16] Loss: 0.0092\n",
      "Epoch [5/5], Iter [3/16] Loss: 0.0700\n",
      "Epoch [5/5], Iter [4/16] Loss: 0.0681\n",
      "Epoch [5/5], Iter [5/16] Loss: 0.0065\n",
      "Epoch [5/5], Iter [6/16] Loss: 0.0608\n",
      "Epoch [5/5], Iter [7/16] Loss: 0.0288\n",
      "Epoch [5/5], Iter [8/16] Loss: 0.0438\n",
      "Epoch [5/5], Iter [9/16] Loss: 0.0358\n",
      "Epoch [5/5], Iter [10/16] Loss: 0.0297\n",
      "Epoch [5/5], Iter [11/16] Loss: 0.0194\n",
      "Epoch [5/5], Iter [12/16] Loss: 0.0239\n",
      "Epoch [5/5], Iter [13/16] Loss: 0.0462\n",
      "Epoch [5/5], Iter [14/16] Loss: 0.0111\n",
      "Epoch [5/5], Iter [15/16] Loss: 0.0383\n",
      "Epoch [5/5], Iter [16/16] Loss: 0.0819\n",
      "Epoch [5/5], Iter [17/16] Loss: 0.0052\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "from torch.autograd import Variable\n",
    "\n",
    "num_epoch = 5\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # reshape the shape of data\n",
    "        images = images.view(len(images), 1, 8, 8)\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 1 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n",
    "                   %(epoch+1, num_epoch, i+1, len(train)//batch_size, loss.data.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T06:54:22.307724Z",
     "start_time": "2020-05-26T06:54:22.278583Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "model.eval()  # Change model to 'eval' mode \n",
    "correct = 0\n",
    "total = 0\n",
    "for xval, yval in test_loader:\n",
    "    # reshape the shape of data\n",
    "    xval = xval.view(len(xval), 1, 8, 8)\n",
    "    outputs = cnn(xval)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += yval.size(0)\n",
    "    correct += (predicted == yval).sum()\n",
    "\n",
    "print('Test Accuracy: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image.png](img/chengjun2.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
