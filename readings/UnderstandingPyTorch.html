<!DOCTYPE html>
<!-- saved from url=(0105)https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e -->
<html xmlns:cc="http://creativecommons.org/ns#"><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# medium-com: http://ogp.me/ns/fb/medium-com#"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=contain"><title>Understanding PyTorch with an example: a step-by-step tutorial</title><link rel="canonical" href="https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e"><meta name="title" content="Understanding PyTorch with an example: a step-by-step tutorial"><meta name="referrer" content="always"><meta name="description" content="This tutorial will guide you through the main reasons why it’s easier and more intuitive to build a Deep Learning model in PyTorch, while also showing you how to avoid some common pitfalls and errors."><meta name="theme-color" content="#000000"><meta property="og:title" content="Understanding PyTorch with an example: a step-by-step tutorial"><meta property="twitter:title" content="Daniel Godoy – Towards Data Science"><meta property="og:url" content="https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1200/0*DG_jU1dr2RG2R1SF"><meta property="fb:app_id" content="542599432471018"><meta property="og:description" content="A structured, incremental and from first principles approach."><meta name="twitter:description" content="A structured, incremental and from first principles approach."><meta name="twitter:image:src" content="https://cdn-images-1.medium.com/max/1200/1*7kL4DitERABkDkP-caSAZA.png"><link rel="me" href="https://twitter.com/dvgodoy"><meta property="fb:profile_id" content="1714299755315485"><meta property="og:type" content="article"><meta name="twitter:card" content="summary"><meta name="twitter:app:name:iphone" content="Medium"><meta name="twitter:app:id:iphone" content="828256236"><meta property="al:ios:app_name" content="Medium"><meta property="al:ios:app_store_id" content="828256236"><meta property="al:android:package" content="com.medium.reader"><meta property="al:android:app_name" content="Medium"><meta property="al:web:url" content="https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e"><link rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://towardsdatascience.com/osd.xml"><link rel="alternate" href="android-app://com.medium.reader/https/medium.com"><meta name="parsely-link" content="https://towardsdatascience.com/@dvgodoy"><link rel="stylesheet" type="text/css" class="js-glyph-" id="glyph-8" href="./Understanding PyTorch with an example_ a step-by-step tutorial_files/m2.css"><link rel="stylesheet" href="./Understanding PyTorch with an example_ a step-by-step tutorial_files/main-branding-base.tcUUUzQ2VpR_H2vWPHs61w.css"><script async="" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/branch-latest.min.js"></script><script>!function(n,e){var t,o,i,c=[],f={passive:!0,capture:!0},r=new Date,a="pointerup",u="pointercancel";function p(n,c){t||(t=c,o=n,i=new Date,w(e),s())}function s(){o>=0&&o<i-r&&(c.forEach(function(n){n(o,t)}),c=[])}function l(t){if(t.cancelable){var o=(t.timeStamp>1e12?new Date:performance.now())-t.timeStamp;"pointerdown"==t.type?function(t,o){function i(){p(t,o),r()}function c(){r()}function r(){e(a,i,f),e(u,c,f)}n(a,i,f),n(u,c,f)}(o,t):p(o,t)}}function w(n){["click","mousedown","keydown","touchstart","pointerdown"].forEach(function(e){n(e,l,f)})}w(n),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){c.push(n),s()}}(addEventListener,removeEventListener);</script><script>if (window.top !== window.self) window.top.location = window.self.location.href;var OB_startTime = new Date().getTime(); var OB_loadErrors = []; function _onerror(e) { OB_loadErrors.push(e) }; if (document.addEventListener) document.addEventListener("error", _onerror, true); else if (document.attachEvent) document.attachEvent("onerror", _onerror); function _asyncScript(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("script"); s.type = "text/javascript"; s.async = true; s.src = u; f.parentNode.insertBefore(s, f);}function _asyncStyles(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("link"); s.rel = "stylesheet"; s.href = u; f.parentNode.insertBefore(s, f); return s}(new Image()).src = "/_/stat?event=pixel.load&origin=" + encodeURIComponent(location.origin);</script><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga("create", "UA-24232453-2", "auto", {"allowLinker": true, "legacyCookieDomain": window.location.hostname}); ga("send", "pageview");ga("create", "UA-19707169-24", "auto", 'tracker0'); ga("tracker0.send", "pageview");</script><script async="" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/analytics.js"></script><!--[if lt IE 9]><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js"></script><![endif]--><link rel="icon" href="https://cdn-images-1.medium.com/fit/c/256/256/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg" class="js-favicon"><link rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/304/304/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/240/240/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/152/152/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="apple-touch-icon" sizes="60x60" href="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"><script src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/saved_resource"></script><meta content="index, follow"><style>.is-transitioningSurfaces {height: 767px; width: 1276px;}.is-transitioningSurfaces .surface-container {min-height: 767px; min-width: 1276px; top: 0px; left: 0px;}.is-transitioningSurfaces .is-transitioningSurfaceIn .surface-content, .is-transitioningSurfaces .is-transitioningSurfaceOut .surface-content {height: 767px; width: 1276px; position: relative;}.is-transitioningSurfaces .is-transitioningSurfaceIn .surface-content {margin-top: 0px; margin-left: 0px;}.is-transitioningSurfaces .is-transitioningSurfaceOut .surface-content {margin-top: 0px; margin-left: 0px;}</style><meta content="index, follow"><meta property="article:author" content="1714299755315485"><meta property="article:publisher" content="https://www.facebook.com/towardsdatascience"><meta property="article:published_time" content="2019-05-07T13:27:54.860Z"><script type="application/ld+json">{"@context":"http://schema.org","@type":"NewsArticle","image":{"@type":"ImageObject","width":1920,"height":1279,"url":"https://cdn-images-1.medium.com/max/2600/0*DG_jU1dr2RG2R1SF"},"url":"https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e","dateCreated":"2019-05-07T13:27:54.860Z","datePublished":"2019-05-07T13:27:54.860Z","dateModified":"2019-05-07T13:27:55.247Z","headline":"Understanding PyTorch with an example: a step-by-step tutorial","name":"Understanding PyTorch with an example: a step-by-step tutorial","articleId":"81fc5f8c4e8e","thumbnailUrl":"https://cdn-images-1.medium.com/max/2600/0*DG_jU1dr2RG2R1SF","keywords":["Tag:Machine Learning","Tag:Deep Learning","Tag:Pytorch","Tag:Towards Data Science","Tag:Tutorial","Publication:towards-data-science","LockedPostSource:0","Elevated:false","LayerCake:0"],"author":{"@type":"Person","name":"Daniel Godoy","url":"https://towardsdatascience.com/@dvgodoy"},"creator":["Daniel Godoy"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"https://towardsdatascience.com","logo":{"@type":"ImageObject","width":161,"height":60,"url":"https://cdn-images-1.medium.com/max/322/1*5EUO1kUYBthpOCPzRj_l2g.png"}},"mainEntityOfPage":"https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e"}</script><meta content="index, follow"></head><body itemscope="" class="browser-chrome os-mac is-withMagicUnderlines v-glyph v-glyph--m2 is-js postShowScreen" data-action-scope="_actionscope_0"><script>document.body.className = document.body.className.replace(/(^|\s)is-noJs(\s|$)/, "$1is-js$2")</script><div class="site-main surface-container" id="container"><div class="butterBar butterBar--error" data-action-scope="_actionscope_1"></div><div id="_obv.shell._surface_1558100588339" class="surface" style="visibility: visible; display: block;"><div class="screenContent surface-content is-supplementalPostContentLoaded" data-action-scope="_actionscope_19"><canvas class="canvas-renderer" width="1276" height="648"></canvas><div class="container u-maxWidth740 u-xs-margin0 notesPositionContainer js-notesPositionContainer"><div class="notesMarkers" data-action-scope="_actionscope_21"></div></div><div class="metabar u-clearfix u-boxShadow4px12pxBlackLighter u-textColorTransparentWhiteDarker js-metabar is-withBottomSection is-hiddenWhenMinimized is-transitioning is-maximized"><div class="branch-journeys-top"></div><div class="js-metabarMiddle metabar-inner u-marginAuto u-maxWidth1032 u-flexCenter u-justifyContentSpaceBetween u-height65 u-xs-height56 u-paddingHorizontal20"><div class="metabar-block u-flex1 u-flexCenter"><div class="u-xs-hide js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-fillTransparentBlackDarker u-flex0 u-flexCenter u-paddingTop0"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0"><svg class="svgIcon-use" width="45" height="45"><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div><div class="u-xs-show js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-fillTransparentBlackDarker u-flex0 u-flexCenter u-paddingTop0"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0"><svg class="svgIcon-use" width="45" height="45"><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div></div><div class="metabar-block u-flex0 u-flexCenter"><div class="u-flexCenter u-height65 u-xs-height56"><div class="buttonSet buttonSet--wide u-lineHeightInherit"><label class="button button--small button--chromeless button--withIcon button--withSvgIcon inputGroup u-sm-hide metabar-predictiveSearch u-baseColor--buttonNormal u-baseColor--placeholderNormal" title="Search"><span class="svgIcon svgIcon--search svgIcon--25px u-baseColor--iconLight"><svg class="svgIcon-use" width="25" height="25"><path d="M20.067 18.933l-4.157-4.157a6 6 0 1 0-.884.884l4.157 4.157a.624.624 0 1 0 .884-.884zM6.5 11c0-2.62 2.13-4.75 4.75-4.75S16 8.38 16 11s-2.13 4.75-4.75 4.75S6.5 13.62 6.5 11z"></path></svg></span><input class="js-predictiveSearchInput textInput textInput--rounded textInput--darkText u-baseColor--textNormal textInput--transparent" type="search" placeholder="Search" required="true" data-collection-id="7f60cf5620c9"></label><a class="button button--small button--chromeless u-sm-show is-inSiteNavBar u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--chromeless u-xs-top1" href="https://towardsdatascience.com/search" title="Search" aria-label="Search"><span class="button-defaultState"><span class="svgIcon svgIcon--search svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M20.067 18.933l-4.157-4.157a6 6 0 1 0-.884.884l4.157 4.157a.624.624 0 1 0 .884-.884zM6.5 11c0-2.62 2.13-4.75 4.75-4.75S16 8.38 16 11s-2.13 4.75-4.75 4.75S6.5 13.62 6.5 11z"></path></svg></span></span></a><button class="button button--small button--chromeless is-inSiteNavBar u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--activity js-notificationsButton u-marginRight16 u-xs-marginRight10 u-lineHeight0 u-size25x25" title="Notifications" aria-label="Notifications" data-action="open-notifications"><span class="svgIcon svgIcon--bell svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="-293 409 25 25"><path d="M-273.327 423.67l-1.673-1.52v-3.646a5.5 5.5 0 0 0-6.04-5.474c-2.86.273-4.96 2.838-4.96 5.71v3.41l-1.68 1.553c-.204.19-.32.456-.32.734V427a1 1 0 0 0 1 1h3.49a3.079 3.079 0 0 0 3.01 2.45 3.08 3.08 0 0 0 3.01-2.45h3.49a1 1 0 0 0 1-1v-2.59c0-.28-.12-.55-.327-.74zm-7.173 5.63c-.842 0-1.55-.546-1.812-1.3h3.624a1.92 1.92 0 0 1-1.812 1.3zm6.35-2.45h-12.7v-2.347l1.63-1.51c.236-.216.37-.522.37-.843v-3.41c0-2.35 1.72-4.356 3.92-4.565a4.353 4.353 0 0 1 4.78 4.33v3.645c0 .324.137.633.376.85l1.624 1.477v2.373z"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal is-inSiteNavBar js-userActions" aria-haspopup="true" data-action="open-userActions"><div class="avatar"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/0_Mpgm7EXaTEICpUOi.jpg" class="avatar-image avatar-image--icon" alt="Cheng-Jun Wang"></div></button></div></div></div></div><div class="u-tintBgColor u-tintSpectrum "><div class="metabar-inner u-marginAuto u-maxWidth1032 u-paddingHorizontal20 js-metabarBottom"><nav role="navigation" class="metabar-block metabar-block--below u-flexCenter u-overflowHidden u-height54"><div class="u-flexCenter u-overflowHidden"><div class="u-marginRight40"><a href="https://towardsdatascience.com/?source=logo-3751a3493996---7f60cf5620c9" class="u-flexCenter js-collectionLogoOrName"><img height="36" width="97" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_5EUO1kUYBthpOCPzRj_l2g.png" alt="Towards Data Science"></a></div><div class="u-overflowHidden u-xs-hide"><ul class="u-textAlignLeft u-noWrap u-overflowX u-height80 u-marginTop40 js-collectionNavItems"><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/data-science/home">Data Science</a></li><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/machine-learning/home">Machine Learning</a></li><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/programming/home">Programming</a></li><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/data-visualization/home">Visualization</a></li><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/artificial-intelligence/home">AI</a></li><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/data-journalism/home">Journalism</a></li><li class="metabar-navItem js-collectionNavItem u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/editors-picks/home">Picks</a></li><span class="u-borderLeft1 u-baseColor--borderLight"></span><li class="metabar-navItem js-collectionNavItem is-external u-inlineBlock u-fontSize13 u-textUppercase u-letterSpacing1px u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-xs-paddingTop10"><a class="link link--darkenOnHover u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/contribute/home" rel="nofollow noopener" target="_blank">Contribute</a></li></ul></div></div></nav></div></div></div><div class="metabar metabar--spacer js-metabarSpacer u-tintBgColor  u-height119 u-xs-height110"></div><main role="main"><article class=" u-minHeight100vhOffset65 u-overflowHidden postArticle postArticle--full is-withAccentColors" lang="en"><div class="postArticle-content js-postField js-notesSource js-trackPostScrolls" data-post-id="81fc5f8c4e8e" data-source="post_page" data-collection-id="7f60cf5620c9" data-tracking-context="postPage" data-scroll="native"><section name="e72a" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h1 name="f3e5" id="f3e5" class="graf graf--h3 graf--leading graf--title">Understanding PyTorch with an example: a step-by-step tutorial</h1><div class="uiScale uiScale-ui--regular uiScale-caption--regular u-flexCenter u-marginVertical24 u-fontSize15 js-postMetaLockup"><div class="u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@dvgodoy?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="c79695e37339" data-action-type="hover" data-user-id="c79695e37339" data-collection-slug="towards-data-science" dir="auto"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_7kL4DitERABkDkP-caSAZA.png" class="avatar-image u-size50x50" alt="Go to the profile of Daniel Godoy"></a></div><div class="u-flex1 u-paddingLeft15 u-overflowHidden"><div class="u-paddingBottom3"><a class="ds-link ds-link--styleSubtle ui-captionStrong u-inlineBlock link link--darken link--darker" href="https://towardsdatascience.com/@dvgodoy" data-action="show-user-card" data-action-value="c79695e37339" data-action-type="hover" data-user-id="c79695e37339" data-collection-slug="towards-data-science" dir="auto">Daniel Godoy</a><span class="followState js-followState" data-user-id="c79695e37339"><button class="button button--smallest u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton u-marginLeft10 u-xs-hide" data-action="toggle-block-user" data-action-value="c79695e37339" data-action-source="post_header_lockup"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--smallest button--dark u-noUserSelect button--withChrome u-accentColor--buttonDark button--follow js-followButton u-marginLeft10 u-xs-hide" data-action="toggle-subscribe-user" data-action-value="c79695e37339" data-action-source="post_header_lockup-c79695e37339-------------------------follow_byline" data-subscribe-source="post_header_lockup" data-follow-context-entity-id="81fc5f8c4e8e"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="ui-caption u-noWrapWithEllipsis js-testPostMetaInlineSupplemental"><time datetime="2019-05-07T13:27:54.860Z">May 7</time><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="21 min read"></span></div></div></div><figure name="538e" id="538e" class="graf graf--figure graf-after--h3"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 467px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.7%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="0*DG_jU1dr2RG2R1SF" data-width="5339" data-height="3559" data-unsplash-photo-id="Y4RxCIaYaSk" data-is-featured="true" data-action="zoom" data-action-value="0*DG_jU1dr2RG2R1SF" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/0_DG_jU1dr2RG2R1SF" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="48"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/0*DG_jU1dr2RG2R1SF" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/0_DG_jU1dr2RG2R1SF(1)"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/0*DG_jU1dr2RG2R1SF"></noscript></div></div><figcaption class="imageCaption">Photo by <a href="https://unsplash.com/@aycai?utm_source=medium&amp;utm_medium=referral" data-href="https://unsplash.com/@aycai?utm_source=medium&amp;utm_medium=referral" class="markup--anchor markup--figure-anchor" rel="photo-creator noopener" target="_blank">Allen Cai</a> on&nbsp;<a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" data-href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" class="markup--anchor markup--figure-anchor" rel="photo-source noopener" target="_blank">Unsplash</a></figcaption></figure><h3 name="a479" id="a479" class="graf graf--h3 graf-after--figure">Introduction</h3><p name="75de" id="75de" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">PyTorch</strong> is the <strong class="markup--strong markup--p-strong">fastest growing</strong> Deep Learning framework and it is also used by <strong class="markup--strong markup--p-strong">Fast.ai</strong> in its MOOC, <a href="https://course.fast.ai/" data-href="https://course.fast.ai/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Deep Learning for Coders</a> and its <a href="https://docs.fast.ai/" data-href="https://docs.fast.ai/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">library</a>.</p><p name="dc9c" id="dc9c" class="graf graf--p graf-after--p">PyTorch is also very <em class="markup--em markup--p-em">pythonic</em>, meaning, it feels more natural to use it if you already are a Python developer.</p><p name="e3b6" id="e3b6" class="graf graf--p graf-after--p">Besides, using PyTorch may even <em class="markup--em markup--p-em">improve your health</em>, according to <a href="https://twitter.com/karpathy/status/868178954032513024" data-href="https://twitter.com/karpathy/status/868178954032513024" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Andrej Karpathy</a>&nbsp;:-)</p><h3 name="3873" id="3873" class="graf graf--h3 graf-after--p">Motivation</h3><p name="ba15" id="ba15" class="graf graf--p graf-after--h3">There are <em class="markup--em markup--p-em">many many</em> PyTorch tutorials around and its documentation is quite complete and extensive. So, <strong class="markup--strong markup--p-strong">why</strong> should you keep reading this step-by-step tutorial?</p><p name="6a47" id="6a47" class="graf graf--p graf-after--p">Well, even though one can find information on pretty much <em class="markup--em markup--p-em">anything</em> PyTorch can do, I missed having a <strong class="markup--strong markup--p-strong">structured</strong>, <strong class="markup--strong markup--p-strong">incremental</strong> and <strong class="markup--strong markup--p-strong">from first principles</strong> approach to it.</p><p name="aa9e" id="aa9e" class="graf graf--p graf-after--p">In this post, I will guide you through the <em class="markup--em markup--p-em">main reasons</em> why PyTorch makes it much <strong class="markup--strong markup--p-strong">easier</strong> and more <strong class="markup--strong markup--p-strong">intuitive</strong> to build a Deep Learning model in Python — <strong class="markup--strong markup--p-strong">autograd</strong>, <strong class="markup--strong markup--p-strong">dynamic computation graph</strong>, <strong class="markup--strong markup--p-strong">model classes</strong> and more — and I will also show you <strong class="markup--strong markup--p-strong">how to avoid</strong> some <strong class="markup--strong markup--p-strong">common pitfalls</strong> and <strong class="markup--strong markup--p-strong">errors</strong> along the way.</p><p name="4e1e" id="4e1e" class="graf graf--p graf-after--p">Moreover, since this is quite a <strong class="markup--strong markup--p-strong">long</strong> post, I built a <em class="markup--em markup--p-em">Table of Contents</em> to make navigation easier, should you use it as a <strong class="markup--strong markup--p-strong">mini-course</strong> and work your way through the content one topic at a time.</p><h3 name="241f" id="241f" class="graf graf--h3 graf-after--p">Table of&nbsp;Contents</h3><ul class="postList"><li name="8829" id="8829" class="graf graf--li graf-after--h3"><a href="https://medium.com/p/81fc5f8c4e8e#40de" data-href="https://medium.com/p/81fc5f8c4e8e#40de" class="markup--anchor markup--li-anchor">A Simple Regression Problem</a></li><li name="aeeb" id="aeeb" class="graf graf--li graf-after--li"><a href="https://medium.com/p/81fc5f8c4e8e#dc96" data-href="https://medium.com/p/81fc5f8c4e8e#dc96" class="markup--anchor markup--li-anchor">Gradient Descent</a></li><li name="f1ff" id="f1ff" class="graf graf--li graf-after--li"><a href="https://medium.com/p/81fc5f8c4e8e#a657" data-href="https://medium.com/p/81fc5f8c4e8e#a657" class="markup--anchor markup--li-anchor">Linear Regression in Numpy</a></li><li name="ba43" id="ba43" class="graf graf--li graf-after--li"><a href="https://medium.com/p/81fc5f8c4e8e#3a3f" data-href="https://medium.com/p/81fc5f8c4e8e#3a3f" class="markup--anchor markup--li-anchor">PyTorch</a></li><li name="e4e2" id="e4e2" class="graf graf--li graf-after--li"><a href="https://medium.com/p/81fc5f8c4e8e#ea0d" data-href="https://medium.com/p/81fc5f8c4e8e#ea0d" class="markup--anchor markup--li-anchor">Autograd</a></li><li name="7e18" id="7e18" class="graf graf--li graf-after--li"><a href="https://medium.com/p/81fc5f8c4e8e#3806" data-href="https://medium.com/p/81fc5f8c4e8e#3806" class="markup--anchor markup--li-anchor">Dynamic Computation Graph</a></li><li name="6ae0" id="6ae0" class="graf graf--li graf-after--li"><a href="https://medium.com/p/81fc5f8c4e8e#cf51" data-href="https://medium.com/p/81fc5f8c4e8e#cf51" class="markup--anchor markup--li-anchor">Optimizer</a></li><li name="1e23" id="1e23" class="graf graf--li graf-after--li"><a href="https://medium.com/p/81fc5f8c4e8e#8877" data-href="https://medium.com/p/81fc5f8c4e8e#8877" class="markup--anchor markup--li-anchor">Loss</a></li><li name="4ddd" id="4ddd" class="graf graf--li graf-after--li"><a href="https://medium.com/p/81fc5f8c4e8e#6208" data-href="https://medium.com/p/81fc5f8c4e8e#6208" class="markup--anchor markup--li-anchor">Model</a></li><li name="90ab" id="90ab" class="graf graf--li graf-after--li"><a href="https://medium.com/p/81fc5f8c4e8e#2e24" data-href="https://medium.com/p/81fc5f8c4e8e#2e24" class="markup--anchor markup--li-anchor">Dataset</a></li><li name="b175" id="b175" class="graf graf--li graf-after--li"><a href="https://medium.com/p/81fc5f8c4e8e#58f2" data-href="https://medium.com/p/81fc5f8c4e8e#58f2" class="markup--anchor markup--li-anchor">DataLoader</a></li><li name="504e" id="504e" class="graf graf--li graf-after--li"><a href="https://medium.com/p/81fc5f8c4e8e#5017" data-href="https://medium.com/p/81fc5f8c4e8e#5017" class="markup--anchor markup--li-anchor">Evaluation</a></li></ul><h3 name="40de" id="40de" class="graf graf--h3 graf-after--li">A Simple Regression Problem</h3><p name="5259" id="5259" class="graf graf--p graf-after--h3">Most tutorials start with some nice and pretty <em class="markup--em markup--p-em">image classification problem</em> to illustrate how to use PyTorch. It may seem cool, but I believe it <strong class="markup--strong markup--p-strong">distracts</strong> you from the <strong class="markup--strong markup--p-strong">main goal</strong>: <strong class="markup--strong markup--p-strong">how PyTorch works</strong>?</p><p name="2fd3" id="2fd3" class="graf graf--p graf-after--p">For this reason, in this tutorial, I will stick with a <strong class="markup--strong markup--p-strong">simple</strong> and <strong class="markup--strong markup--p-strong">familiar</strong> problem: a <strong class="markup--strong markup--p-strong">linear regression</strong> <strong class="markup--strong markup--p-strong">with a single feature <em class="markup--em markup--p-em">x</em></strong>! It doesn’t get much simpler than that…</p><figure name="b7ae" id="b7ae" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 188px; max-height: 46px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 24.5%;"></div><img class="graf-image" data-image-id="1*a7_GUQQT5BjvAhh3qq0JwA.png" data-width="188" data-height="46" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_a7_GUQQT5BjvAhh3qq0JwA.png"></div><figcaption class="imageCaption">Simple Linear Regression model</figcaption></figure><h4 name="1aa0" id="1aa0" class="graf graf--h4 graf-after--figure">Data Generation</h4><p name="ff1f" id="ff1f" class="graf graf--p graf-after--h4">Let’s start <strong class="markup--strong markup--p-strong">generating</strong> some synthetic data: we start with a vector of 100 points for our <strong class="markup--strong markup--p-strong">feature <em class="markup--em markup--p-em">x</em></strong> and create our <strong class="markup--strong markup--p-strong">labels</strong> using <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">a = 1</em></strong>, <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">b = 2</em></strong> and some Gaussian noise.</p><p name="53e0" id="53e0" class="graf graf--p graf-after--p">Next, let’s <strong class="markup--strong markup--p-strong">split</strong> our synthetic data into <strong class="markup--strong markup--p-strong">train</strong> and <strong class="markup--strong markup--p-strong">validation</strong> sets, shuffling the array of indices and using the first 80 shuffled points for training.</p><figure name="7dbb" id="7dbb" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 59.571%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/1b3483151f4241bb26aa517f81ebe83f?postId=81fc5f8c4e8e" data-media-id="1b3483151f4241bb26aa517f81ebe83f" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1b3483151f4241bb26aa517f81ebe83f.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/1b3483151f4241bb26aa517f81ebe83f?postId=81fc5f8c4e8e" data-media-id="1b3483151f4241bb26aa517f81ebe83f" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Generating synthetic train and validation sets for a linear regression</figcaption></figure><figure name="796b" id="796b" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 241px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 34.5%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*SsuTZ1y-pWikYJcaMnZgag.png" data-width="809" data-height="279" data-action="zoom" data-action-value="1*SsuTZ1y-pWikYJcaMnZgag.png" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_SsuTZ1y-pWikYJcaMnZgag.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="25"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*SsuTZ1y-pWikYJcaMnZgag.png" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_SsuTZ1y-pWikYJcaMnZgag(1).png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*SsuTZ1y-pWikYJcaMnZgag.png"></noscript></div></div><figcaption class="imageCaption">Figure 1: Synthetic data — Train and Validation sets</figcaption></figure><p name="75c7" id="75c7" class="graf graf--p graf-after--figure">We <strong class="markup--strong markup--p-strong">know</strong> that a = 1 and b = 2, but now let’s see how close we can get to the true values by using <strong class="markup--strong markup--p-strong">gradient descent</strong> and the 80 points in the <strong class="markup--strong markup--p-strong">training</strong> <strong class="markup--strong markup--p-strong">set</strong>…</p><h3 name="dc96" id="dc96" class="graf graf--h3 graf-after--p">Gradient Descent</h3><p name="7553" id="7553" class="graf graf--p graf-after--h3">If you are comfortable with the inner workings of gradient descent, <em class="markup--em markup--p-em">feel free to skip</em> this section. It goes beyond the scope of this post to fully explain how gradient descent works, but I’ll cover the <strong class="markup--strong markup--p-strong">four basic steps</strong> you’d need to go through to compute it.</p><h4 name="8161" id="8161" class="graf graf--h4 graf-after--p">Step 1: Compute the&nbsp;Loss</h4><p name="a519" id="a519" class="graf graf--p graf-after--h4">For a regression problem, the <strong class="markup--strong markup--p-strong">loss</strong> is given by the <strong class="markup--strong markup--p-strong">Mean Square Error (MSE)</strong>, that is, the average of all squared differences between <strong class="markup--strong markup--p-strong">labels</strong> (y) and <strong class="markup--strong markup--p-strong">predictions</strong> (a + bx).</p><blockquote name="0102" id="0102" class="graf graf--blockquote graf-after--p">It is worth mentioning that, if we use <strong class="markup--strong markup--blockquote-strong">all points</strong> in the training set (<em class="markup--em markup--blockquote-em">N</em>) to compute the loss, we are performing a <strong class="markup--strong markup--blockquote-strong">batch</strong> gradient descent. If we were to use a <strong class="markup--strong markup--blockquote-strong">single point</strong> at each time, it would be a <strong class="markup--strong markup--blockquote-strong">stochastic</strong> gradient descent. Anything else (n) <strong class="markup--strong markup--blockquote-strong">in-between 1 and N</strong> characterizes a <strong class="markup--strong markup--blockquote-strong">mini-batch</strong> gradient descent.</blockquote><figure name="eecd" id="eecd" class="graf graf--figure graf-after--blockquote"><div class="aspectRatioPlaceholder is-locked" style="max-width: 345px; max-height: 184px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 53.300000000000004%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*7fmJUcQT578OBfX7Q8hluQ.png" data-width="345" data-height="184" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_7fmJUcQT578OBfX7Q8hluQ.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="40"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*7fmJUcQT578OBfX7Q8hluQ.png" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_7fmJUcQT578OBfX7Q8hluQ(1).png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*7fmJUcQT578OBfX7Q8hluQ.png"></noscript></div></div><figcaption class="imageCaption">Loss: Mean Squared Error&nbsp;(MSE)</figcaption></figure><h4 name="2759" id="2759" class="graf graf--h4 graf-after--figure">Step 2: Compute the Gradients</h4><p name="9fae" id="9fae" class="graf graf--p graf-after--h4">A <strong class="markup--strong markup--p-strong">gradient</strong> is a <strong class="markup--strong markup--p-strong">partial derivative</strong> — <em class="markup--em markup--p-em">why</em> <em class="markup--em markup--p-em">partial</em>? Because one computes it with respect to (w.r.t.) a <strong class="markup--strong markup--p-strong">single</strong> <strong class="markup--strong markup--p-strong">parameter</strong>. We have two parameters, <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">a</em></strong> and <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">b</em></strong>, so we must compute two partial derivatives.</p><p name="6d5b" id="6d5b" class="graf graf--p graf-after--p">A <strong class="markup--strong markup--p-strong">derivative</strong> tells you <em class="markup--em markup--p-em">how much</em> <strong class="markup--strong markup--p-strong">a given</strong> <strong class="markup--strong markup--p-strong">quantity changes</strong> when you <em class="markup--em markup--p-em">slightly</em> <em class="markup--em markup--p-em">vary</em> some <strong class="markup--strong markup--p-strong">other quantity</strong>. In our case, how much does our <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">MSE</em></strong> <strong class="markup--strong markup--p-strong">loss</strong> change when we vary <strong class="markup--strong markup--p-strong">each one of our two parameters</strong>?</p><p name="e39a" id="e39a" class="graf graf--p graf-after--p">The <em class="markup--em markup--p-em">right-most</em> part of the equations below is what you usually see in implementations of gradient descent for a simple linear regression. In the <strong class="markup--strong markup--p-strong">intermediate step</strong>, I show you <strong class="markup--strong markup--p-strong">all elements</strong> that pop-up from the application of the <a href="https://en.wikipedia.org/wiki/Chain_rule" data-href="https://en.wikipedia.org/wiki/Chain_rule" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">chain rule</a>, so you know how the final expression came to be.</p><figure name="26ae" id="26ae" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 150px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 21.4%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*YvTj1B-h1gzSI5F24OgrrA.png" data-width="850" data-height="182" data-action="zoom" data-action-value="1*YvTj1B-h1gzSI5F24OgrrA.png" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_YvTj1B-h1gzSI5F24OgrrA.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="15"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*YvTj1B-h1gzSI5F24OgrrA.png" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_YvTj1B-h1gzSI5F24OgrrA(1).png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*YvTj1B-h1gzSI5F24OgrrA.png"></noscript></div></div><figcaption class="imageCaption">Computing gradients w.r.t coefficients a and&nbsp;b</figcaption></figure><h4 name="d000" id="d000" class="graf graf--h4 graf-after--figure">Step 3: Update the Parameters</h4><p name="ed18" id="ed18" class="graf graf--p graf-after--h4">In the final step, we <strong class="markup--strong markup--p-strong">use the gradients to update</strong> the parameters. Since we are trying to <strong class="markup--strong markup--p-strong">minimize</strong> our <strong class="markup--strong markup--p-strong">losses</strong>, we <strong class="markup--strong markup--p-strong">reverse the sign</strong> of the gradient for the update.</p><p name="408c" id="408c" class="graf graf--p graf-after--p">There is still another parameter to consider: the <strong class="markup--strong markup--p-strong">learning rate</strong>, denoted by the <em class="markup--em markup--p-em">Greek letter </em><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">eta</em></strong> (that looks like the letter <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">n</em></strong>), which is the <strong class="markup--strong markup--p-strong">multiplicative factor</strong> that we need to apply to the gradient for the parameter update.</p><figure name="18a4" id="18a4" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 209px; max-height: 136px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 65.10000000000001%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*eWnUloBYcSNPRBzVcaIr1g.png" data-width="209" data-height="136" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_eWnUloBYcSNPRBzVcaIr1g.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="48"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*eWnUloBYcSNPRBzVcaIr1g.png" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_eWnUloBYcSNPRBzVcaIr1g(1).png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*eWnUloBYcSNPRBzVcaIr1g.png"></noscript></div></div><figcaption class="imageCaption">Updating coefficients a and b using computed gradients and a learning&nbsp;rate</figcaption></figure><p name="e79d" id="e79d" class="graf graf--p graf-after--figure">How to <strong class="markup--strong markup--p-strong">choose</strong> a learning rate? That is a topic on its own and beyond the scope of this post as well.</p><h4 name="5e46" id="5e46" class="graf graf--h4 graf-after--p">Step 4: Rinse and&nbsp;Repeat!</h4><p name="4ffa" id="4ffa" class="graf graf--p graf-after--h4">Now we use the <strong class="markup--strong markup--p-strong">updated</strong> <strong class="markup--strong markup--p-strong">parameters</strong> to go back to <strong class="markup--strong markup--p-strong">Step 1</strong> and restart the process.</p><blockquote name="8c44" id="8c44" class="graf graf--blockquote graf--hasDropCapModel graf-after--p"><strong class="markup--strong markup--blockquote-strong">An epoch is complete whenever every point has been already used for computing the loss</strong>. For <strong class="markup--strong markup--blockquote-strong">batch</strong> gradient descent, this is trivial, as it uses all points for computing the loss — <strong class="markup--strong markup--blockquote-strong">one epoch</strong> is the same as <strong class="markup--strong markup--blockquote-strong">one update</strong>. For <strong class="markup--strong markup--blockquote-strong">stochastic</strong> gradient descent, <strong class="markup--strong markup--blockquote-strong">one epoch</strong> means <strong class="markup--strong markup--blockquote-strong">N</strong> <strong class="markup--strong markup--blockquote-strong">updates</strong>, while for <strong class="markup--strong markup--blockquote-strong">mini-batch </strong>(of size n), <strong class="markup--strong markup--blockquote-strong">one epoch</strong> has <strong class="markup--strong markup--blockquote-strong">N/n updates</strong>.</blockquote><p name="cf7e" id="cf7e" class="graf graf--p graf-after--blockquote">Repeating this process over and over, for <strong class="markup--strong markup--p-strong">many epochs</strong>, is, in a nutshell, <strong class="markup--strong markup--p-strong">training</strong> a model.</p><h3 name="a657" id="a657" class="graf graf--h3 graf-after--p">Linear Regression in&nbsp;Numpy</h3><p name="c9ef" id="c9ef" class="graf graf--p graf-after--h3">It’s time to implement our linear regression model using gradient descent using <strong class="markup--strong markup--p-strong">Numpy only</strong>.</p><blockquote name="b0bf" id="b0bf" class="graf graf--blockquote graf-after--p">Wait a minute… I thought this tutorial was about PyTorch!</blockquote><p name="42f2" id="42f2" class="graf graf--p graf-after--blockquote">Yes, it is, but this serves <strong class="markup--strong markup--p-strong">two purposes</strong>: <em class="markup--em markup--p-em">first</em>, to introduce the <strong class="markup--strong markup--p-strong">structure</strong> of our task, which will remain largely the same and, <em class="markup--em markup--p-em">second</em>, to show you the main <strong class="markup--strong markup--p-strong">pain points</strong> so you can fully appreciate how much PyTorch makes your life easier&nbsp;:-)</p><p name="4574" id="4574" class="graf graf--p graf-after--p">For training a model, there are <strong class="markup--strong markup--p-strong">two initialization steps</strong>:</p><ul class="postList"><li name="63f6" id="63f6" class="graf graf--li graf-after--p">Random initialization of parameters/weights (we have only two, <em class="markup--em markup--li-em">a</em> and <em class="markup--em markup--li-em">b</em>) — lines 3 and 4;</li><li name="45ae" id="45ae" class="graf graf--li graf-after--li">Initialization of hyper-parameters (in our case, only <em class="markup--em markup--li-em">learning rate</em> and <em class="markup--em markup--li-em">number of epochs</em>) — lines 9 and 11;</li></ul><p name="502b" id="502b" class="graf graf--p graf-after--li">Make sure to <em class="markup--em markup--p-em">always initialize your random seed</em> to ensure <strong class="markup--strong markup--p-strong">reproducibility</strong> of your results. As usual, the random seed is <a href="https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Answer_to_the_Ultimate_Question_of_Life,_the_Universe,_and_Everything_%2842%29" data-href="https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Answer_to_the_Ultimate_Question_of_Life,_the_Universe,_and_Everything_(42)" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">42</a>, the <em class="markup--em markup--p-em">least random</em> of all random seeds one could possibly choose&nbsp;:-)</p><p name="d073" id="d073" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">For each epoch</strong>, there are <strong class="markup--strong markup--p-strong">four training steps</strong>:</p><ul class="postList"><li name="fd66" id="fd66" class="graf graf--li graf-after--p">Compute model’s predictions — this is the <strong class="markup--strong markup--li-strong">forward pass </strong>— line 15;</li><li name="a2e4" id="a2e4" class="graf graf--li graf-after--li">Compute the loss, using <em class="markup--em markup--li-em">predictions</em> and and <em class="markup--em markup--li-em">labels</em> and the appropriate <strong class="markup--strong markup--li-strong">loss function</strong> for the task at hand — lines 18 and 20;</li><li name="3b62" id="3b62" class="graf graf--li graf-after--li">Compute the <strong class="markup--strong markup--li-strong">gradients</strong> for every parameter — lines 23 and 24;</li><li name="0749" id="0749" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Update</strong> the parameters — lines 27 and 28;</li></ul><p name="5ce0" id="5ce0" class="graf graf--p graf-after--li">Just keep in mind that, if you <em class="markup--em markup--p-em">don’t</em> use batch gradient descent (our example does),you’ll have to write an <strong class="markup--strong markup--p-strong">inner loop</strong> to perform the <strong class="markup--strong markup--p-strong">four training steps</strong> for either each <strong class="markup--strong markup--p-strong">individual point</strong> (<strong class="markup--strong markup--p-strong">stochastic</strong>) or <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">n</em> points</strong> (<strong class="markup--strong markup--p-strong">mini-batch</strong>). We’ll see a mini-batch example later down the line.</p><figure name="0099" id="0099" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 119.286%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/3574d0dea05b049e8992ab8b12e32197?postId=81fc5f8c4e8e" data-media-id="3574d0dea05b049e8992ab8b12e32197" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/3574d0dea05b049e8992ab8b12e32197.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/3574d0dea05b049e8992ab8b12e32197?postId=81fc5f8c4e8e" data-media-id="3574d0dea05b049e8992ab8b12e32197" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Implementing gradient descent for linear regression using Numpy</figcaption></figure><p name="ec64" id="ec64" class="graf graf--p graf-after--figure">Just to make sure we haven’t done any mistakes in our code, we can use <em class="markup--em markup--p-em">Scikit-Learn’s Linear Regression</em> to fit the model and compare the coefficients.</p><pre name="67d2" id="67d2" class="graf graf--pre graf-after--p"># a and b after initialization<br>[0.49671415] [-0.1382643]<br># a and b after our gradient descent<br>[1.02354094] [1.96896411]<br># intercept and coef from Scikit-Learn<br>[1.02354075] [1.96896447]</pre><p name="a548" id="a548" class="graf graf--p graf-after--pre">They <strong class="markup--strong markup--p-strong">match</strong> up to 6 decimal places — we have a <em class="markup--em markup--p-em">fully working implementation of linear regression</em> using Numpy.</p><p name="a1a6" id="a1a6" class="graf graf--p graf-after--p">Time to <strong class="markup--strong markup--p-strong">TORCH</strong> it&nbsp;:-)</p><h3 name="3a3f" id="3a3f" class="graf graf--h3 graf-after--p">PyTorch</h3><p name="b702" id="b702" class="graf graf--p graf-after--h3">First, we need to cover a <strong class="markup--strong markup--p-strong">few basic concepts</strong> that may throw you off-balance if you don’t grasp them well enough before going full-force on modeling.</p><p name="c5bb" id="c5bb" class="graf graf--p graf-after--p">In Deep Learning, we see <strong class="markup--strong markup--p-strong">tensors</strong> everywhere. Well, Google’s framework is called <em class="markup--em markup--p-em">TensorFlow</em> for a reason! <em class="markup--em markup--p-em">What is a tensor, anyway?</em></p><h4 name="2f02" id="2f02" class="graf graf--h4 graf-after--p">Tensor</h4><p name="c0e6" id="c0e6" class="graf graf--p graf-after--h4">In <em class="markup--em markup--p-em">Numpy</em>, you may have an <strong class="markup--strong markup--p-strong">array</strong> that has <strong class="markup--strong markup--p-strong">three dimensions</strong>, right? That is, technically speaking, a <strong class="markup--strong markup--p-strong">tensor</strong>.</p><p name="5858" id="5858" class="graf graf--p graf-after--p">A <strong class="markup--strong markup--p-strong">scalar</strong> (a single number) has <strong class="markup--strong markup--p-strong">zero</strong> dimensions, a <strong class="markup--strong markup--p-strong">vector</strong> <strong class="markup--strong markup--p-strong">has</strong> <strong class="markup--strong markup--p-strong">one</strong> dimension, a <strong class="markup--strong markup--p-strong">matrix has two</strong> dimensions and a <strong class="markup--strong markup--p-strong">tensor has three or more</strong> dimensions. That’s it!</p><p name="cd59" id="cd59" class="graf graf--p graf-after--p">But, to keep things simple, it is commonplace to call vectors and matrices tensors as well — so, from now on, <strong class="markup--strong markup--p-strong">everything is either a scalar or a tensor</strong>.</p><figure name="4e8c" id="4e8c" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 175px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 25%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*GbwKkmA0NdndXRhOOwNclA.jpeg" data-width="1200" data-height="300" data-action="zoom" data-action-value="1*GbwKkmA0NdndXRhOOwNclA.jpeg" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_GbwKkmA0NdndXRhOOwNclA.jpeg" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="18"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*GbwKkmA0NdndXRhOOwNclA.jpeg" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_GbwKkmA0NdndXRhOOwNclA(1).jpeg"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*GbwKkmA0NdndXRhOOwNclA.jpeg"></noscript></div></div><figcaption class="imageCaption">Figure 2: Tensors are just higher-dimensional matrices&nbsp;:-)&nbsp;<a href="http://karlstratos.com/drawings/drawings.html" data-href="http://karlstratos.com/drawings/drawings.html" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Source</a></figcaption></figure><h4 name="594d" id="594d" class="graf graf--h4 graf-after--figure">Loading Data, Devices and&nbsp;CUDA</h4><p name="115d" id="115d" class="graf graf--p graf--startsWithDoubleQuote graf-after--h4">”<em class="markup--em markup--p-em">How do we go from Numpy’s arrays to PyTorch’s tensors</em>”, you ask? That’s what <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/torch.html#torch.from_numpy" data-href="https://pytorch.org/docs/stable/torch.html#torch.from_numpy" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">from_numpy</strong></a></code> is good for. It returns a <strong class="markup--strong markup--p-strong">CPU tensor</strong>, though.</p><p name="e021" id="e021" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“<em class="markup--em markup--p-em">But I want to use my fancy GPU…</em>”, you say. No worries, that’s what <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.to" data-href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.to" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">to()</strong></a></code> is good for. It sends your tensor to whatever <strong class="markup--strong markup--p-strong">device</strong> you specify, including your <strong class="markup--strong markup--p-strong">GPU</strong> (referred to as <code class="markup--code markup--p-code">cuda</code> or <code class="markup--code markup--p-code">cuda:0</code>).</p><p name="e578" id="e578" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“<em class="markup--em markup--p-em">What if I want my code to fallback to CPU if no GPU is available?</em>”, you may be wondering… PyTorch got your back once more — you can use <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/cuda.html?highlight=is_available#torch.cuda.is_available" data-href="https://pytorch.org/docs/stable/cuda.html?highlight=is_available#torch.cuda.is_available" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">cuda.is_available()</strong></a></code> to find out if you have a GPU at your disposal and set your device accordingly.</p><p name="4fbb" id="4fbb" class="graf graf--p graf-after--p">You can also easily <strong class="markup--strong markup--p-strong">cast</strong> it to a lower precision (32-bit float) using <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.float" data-href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.float" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">float()</a></code>.</p><figure name="403b" id="403b" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 53.286%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/20cacb348a3941965689ef7ad2b47e0b?postId=81fc5f8c4e8e" data-media-id="20cacb348a3941965689ef7ad2b47e0b" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/20cacb348a3941965689ef7ad2b47e0b.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/20cacb348a3941965689ef7ad2b47e0b?postId=81fc5f8c4e8e" data-media-id="20cacb348a3941965689ef7ad2b47e0b" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Loading data: turning Numpy arrays into PyTorch tensors</figcaption></figure><p name="1ef1" id="1ef1" class="graf graf--p graf-after--figure">If you compare the <strong class="markup--strong markup--p-strong">types</strong> of both variables, you’ll get what you’d expect: <code class="markup--code markup--p-code">numpy.ndarray</code> for the first one and <code class="markup--code markup--p-code">torch.Tensor</code> for the second one.</p><p name="758e" id="758e" class="graf graf--p graf-after--p">But where does your nice tensor “live”? In your CPU or your GPU? You can’t say… but if you use PyTorch’s <code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">type()</strong></code>, it will reveal its <strong class="markup--strong markup--p-strong">location </strong>— <code class="markup--code markup--p-code">torch.cuda.FloatTensor</code> — a GPU tensor in this case.</p><p name="5629" id="5629" class="graf graf--p graf-after--p">We can also go the other way around, turning tensors back into Numpy arrays, using <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/tensors.html?highlight=numpy#torch.Tensor.numpy" data-href="https://pytorch.org/docs/stable/tensors.html?highlight=numpy#torch.Tensor.numpy" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">numpy()</strong></a></code>. It should be easy as <code class="markup--code markup--p-code">x_train_tensor.numpy()</code> <strong class="markup--strong markup--p-strong">but</strong>…</p><pre name="b253" id="b253" class="graf graf--pre graf-after--p">TypeError: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.</pre><p name="1e31" id="1e31" class="graf graf--p graf-after--pre">Unfortunately, Numpy <strong class="markup--strong markup--p-strong">cannot</strong> handle GPU tensors… you need to make them CPU tensors first using <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.cpu" data-href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.cpu" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">cpu()</strong></a></code>.</p><h4 name="d4c5" id="d4c5" class="graf graf--h4 graf-after--p">Creating Parameters</h4><p name="f80a" id="f80a" class="graf graf--p graf-after--h4">What distinguishes a <em class="markup--em markup--p-em">tensor</em> used for <em class="markup--em markup--p-em">data </em>— like the ones we’ve just created — from a <strong class="markup--strong markup--p-strong">tensor</strong> used as a (<em class="markup--em markup--p-em">trainable</em>) <strong class="markup--strong markup--p-strong">parameter/weight</strong>?</p><p name="3a8c" id="3a8c" class="graf graf--p graf-after--p">The latter tensors require the <strong class="markup--strong markup--p-strong">computation of its gradients</strong>, so we can <strong class="markup--strong markup--p-strong">update</strong> their values (the parameters’ values, that is). That’s what the <code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">requires_grad=True</strong></code> argument is good for. It tells PyTorch we want it to compute gradients for us.</p><p name="9bc5" id="9bc5" class="graf graf--p graf-after--p">You may be tempted to create a simple tensor for a parameter and, later on, send it to your chosen device, as we did with our data, right? Not so fast…</p><figure name="59a2" id="59a2" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 78.429%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/2f5918e69191cd0d963e0faf5c44bc8a?postId=81fc5f8c4e8e" data-media-id="2f5918e69191cd0d963e0faf5c44bc8a" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/2f5918e69191cd0d963e0faf5c44bc8a.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/2f5918e69191cd0d963e0faf5c44bc8a?postId=81fc5f8c4e8e" data-media-id="2f5918e69191cd0d963e0faf5c44bc8a" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Trying to create variables for the coefficients…</figcaption></figure><p name="0932" id="0932" class="graf graf--p graf-after--figure">The first chunk of code creates two nice tensors for our parameters, gradients and all. But they are <strong class="markup--strong markup--p-strong">CPU</strong> tensors.</p><pre name="b453" id="b453" class="graf graf--pre graf-after--p"># FIRST<br>tensor([-0.5531], requires_grad=True)<br>tensor([-0.7314], requires_grad=True)</pre><p name="32d5" id="32d5" class="graf graf--p graf-after--pre">In the second chunk of code, we tried the <strong class="markup--strong markup--p-strong">naive</strong> approach of sending them to our GPU. We succeeded in sending them to another device, but we <strong class="markup--strong markup--p-strong">”lost”</strong> the <strong class="markup--strong markup--p-strong">gradients</strong> somehow…</p><pre name="79be" id="79be" class="graf graf--pre graf-after--p"># SECOND<br>tensor([0.5158], device='cuda:0', grad_fn=&lt;CopyBackwards&gt;) tensor([0.0246], device='cuda:0', grad_fn=&lt;CopyBackwards&gt;)</pre><p name="f7c0" id="f7c0" class="graf graf--p graf-after--pre">In the third chunk, we <strong class="markup--strong markup--p-strong">first</strong> send our tensors to the <strong class="markup--strong markup--p-strong">device</strong> and <strong class="markup--strong markup--p-strong">then</strong> use <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.requires_grad_" data-href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.requires_grad_" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">requires_grad_()</strong></a></code> method to set its <code class="markup--code markup--p-code">requires_grad</code> to <code class="markup--code markup--p-code">True</code> in place.</p><pre name="632c" id="632c" class="graf graf--pre graf-after--p"># THIRD<br>tensor([-0.8915], device='cuda:0', requires_grad=True) tensor([0.3616], device='cuda:0', requires_grad=True)</pre><blockquote name="c979" id="c979" class="graf graf--blockquote graf-after--pre">In PyTorch, every method that <strong class="markup--strong markup--blockquote-strong">ends</strong> with an <strong class="markup--strong markup--blockquote-strong">underscore</strong> (<strong class="markup--strong markup--blockquote-strong">_</strong>) makes changes <strong class="markup--strong markup--blockquote-strong">in-place</strong>, meaning, they will <strong class="markup--strong markup--blockquote-strong">modify</strong> the underlying variable.</blockquote><p name="dd8a" id="dd8a" class="graf graf--p graf-after--blockquote">Although the last approach worked fine, it is much better to <strong class="markup--strong markup--p-strong">assign</strong> tensors to a <strong class="markup--strong markup--p-strong">device</strong> at the moment of their <strong class="markup--strong markup--p-strong">creation</strong>.</p><figure name="a626" id="a626" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 21.857%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/27b072eeee6b64eb7d79cf60754e7075?postId=81fc5f8c4e8e" data-media-id="27b072eeee6b64eb7d79cf60754e7075" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/27b072eeee6b64eb7d79cf60754e7075.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/27b072eeee6b64eb7d79cf60754e7075?postId=81fc5f8c4e8e" data-media-id="27b072eeee6b64eb7d79cf60754e7075" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Actually creating variables for the coefficients&nbsp;:-)</figcaption></figure><pre name="ed99" id="ed99" class="graf graf--pre graf-after--figure">tensor([0.6226], device='cuda:0', requires_grad=True) tensor([1.4505], device='cuda:0', requires_grad=True)</pre><p name="4ec6" id="4ec6" class="graf graf--p graf-after--pre">Much easier, right?</p><p name="eb40" id="eb40" class="graf graf--p graf-after--p">Now that we know how to create tensors that require gradients, let’s see how PyTorch handles them — that’s the role of the…</p><h3 name="ea0d" id="ea0d" class="graf graf--h3 graf-after--p">Autograd</h3><p name="efda" id="efda" class="graf graf--p graf-after--h3">Autograd is PyTorch’s <em class="markup--em markup--p-em">automatic differentiation package</em>. Thanks to it, we <strong class="markup--strong markup--p-strong">don’t need to worry</strong> about <em class="markup--em markup--p-em">partial derivatives, chain rule</em> or anything like it.</p><p name="139f" id="139f" class="graf graf--p graf-after--p">So, how do we tell PyTorch to do its thing and <strong class="markup--strong markup--p-strong">compute all gradients</strong>? That’s what <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/autograd.html#torch.autograd.backward" data-href="https://pytorch.org/docs/stable/autograd.html#torch.autograd.backward" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">backward()</strong></a></code> is good for.</p><p name="b734" id="b734" class="graf graf--p graf-after--p">Do you remember the <strong class="markup--strong markup--p-strong">starting point</strong> for <strong class="markup--strong markup--p-strong">computing the gradients</strong>? It was the <strong class="markup--strong markup--p-strong">loss</strong>, as we computed its partial derivatives w.r.t. our parameters. Hence, we need to invoke the <code class="markup--code markup--p-code">backward()</code> method from the corresponding Python variable, like, <code class="markup--code markup--p-code">loss.backward().</code></p><p name="c349" id="c349" class="graf graf--p graf-after--p">What about the <strong class="markup--strong markup--p-strong">actual values</strong> of the <strong class="markup--strong markup--p-strong">gradients</strong>? We can inspect them by looking at the <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/autograd.html#torch.Tensor.grad" data-href="https://pytorch.org/docs/stable/autograd.html#torch.Tensor.grad" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">grad</strong></a></code> <strong class="markup--strong markup--p-strong">attribute</strong> of a tensor.</p><p name="e2b5" id="e2b5" class="graf graf--p graf-after--p">If you check the method’s documentation, it clearly states that <strong class="markup--strong markup--p-strong">gradients are accumulated</strong>. So, every time we use the <strong class="markup--strong markup--p-strong">gradients</strong> to <strong class="markup--strong markup--p-strong">update</strong> the parameters, we need to <strong class="markup--strong markup--p-strong">zero the gradients afterwards</strong>. And that’s what <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.zero_" data-href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.zero_" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">zero_()</strong></a></code> is good for.</p><p name="4c1f" id="4c1f" class="graf graf--p graf-after--p">What does the <strong class="markup--strong markup--p-strong">underscore</strong> (<strong class="markup--strong markup--p-strong">_</strong>) at the <strong class="markup--strong markup--p-strong">end of the method name</strong> mean? Do you remember? If not, scroll back to the previous section and find out.</p><p name="1afa" id="1afa" class="graf graf--p graf-after--p">So, let’s <strong class="markup--strong markup--p-strong">ditch</strong> the <strong class="markup--strong markup--p-strong">manual</strong> <strong class="markup--strong markup--p-strong">computation of gradients</strong> and use both <code class="markup--code markup--p-code">backward()</code> and <code class="markup--code markup--p-code">zero_()</code> methods instead.</p><p name="33fe" id="33fe" class="graf graf--p graf-after--p">That’s it? Well, pretty much… but, there is always a <strong class="markup--strong markup--p-strong">catch</strong>, and this time it has to do with the <strong class="markup--strong markup--p-strong">update</strong> of the <strong class="markup--strong markup--p-strong">parameters</strong>…</p><figure name="4a53" id="4a53" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 153.857%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/8f328e36827c11e97dfaeb217f285b66?postId=81fc5f8c4e8e" data-media-id="8f328e36827c11e97dfaeb217f285b66" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/8f328e36827c11e97dfaeb217f285b66.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/8f328e36827c11e97dfaeb217f285b66?postId=81fc5f8c4e8e" data-media-id="8f328e36827c11e97dfaeb217f285b66" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div></figure><p name="005d" id="005d" class="graf graf--p graf-after--figure">In the first attempt, if we use the same update structure as in our <em class="markup--em markup--p-em">Numpy</em> code, we’ll get the weird <strong class="markup--strong markup--p-strong">error</strong> below… but we can get a <em class="markup--em markup--p-em">hint</em> of what’s going on by looking at the tensor itself — once again we <strong class="markup--strong markup--p-strong">“lost”</strong> the <strong class="markup--strong markup--p-strong">gradient</strong> while reassigning the update results to our parameters. Thus, the <code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">grad</strong></code> attribute turns out to be <code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">None</strong></code> and it raises the error…</p><pre name="295b" id="295b" class="graf graf--pre graf-after--p"># FIRST ATTEMPT<br>tensor([0.7518], device='cuda:0', grad_fn=&lt;SubBackward0&gt;)<br>AttributeError: 'NoneType' object has no attribute 'zero_'</pre><p name="7cee" id="7cee" class="graf graf--p graf-after--pre">We then change it slightly, using a familiar <strong class="markup--strong markup--p-strong">in-place Python assignment</strong> in our second attempt. And, once again, PyTorch complains about it and raises an <strong class="markup--strong markup--p-strong">error</strong>.</p><pre name="aa62" id="aa62" class="graf graf--pre graf-after--p"># SECOND ATTEMPT<br>RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.</pre><blockquote name="84c2" id="84c2" class="graf graf--blockquote graf-after--pre">Why?! It turns out to be a case of <strong class="markup--strong markup--blockquote-strong">“too much of a good thing”</strong>. The culprit is PyTorch’s ability to build a <strong class="markup--strong markup--blockquote-strong">dynamic computation graph</strong> from every <strong class="markup--strong markup--blockquote-strong">Python operation</strong> that involves any <strong class="markup--strong markup--blockquote-strong">gradient-computing tensor</strong> or <strong class="markup--strong markup--blockquote-strong">its dependencies</strong>.</blockquote><blockquote name="2e8e" id="2e8e" class="graf graf--blockquote graf-after--blockquote">We’ll go deeper into the inner workings of the dynamic computation graph in the next section.</blockquote><p name="cb86" id="cb86" class="graf graf--p graf-after--blockquote">So, how do we tell PyTorch to <strong class="markup--strong markup--p-strong">“back off”</strong> and let us <strong class="markup--strong markup--p-strong">update our parameters</strong> without messing up with its <em class="markup--em markup--p-em">fancy dynamic computation graph</em>? That’s what <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad" data-href="https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">torch.no_grad()</strong></a></code> is good for. It allows us to <strong class="markup--strong markup--p-strong">perform regular Python operations on tensors</strong>,<strong class="markup--strong markup--p-strong"> independent of PyTorch’s computation graph</strong>.</p><p name="7d04" id="7d04" class="graf graf--p graf-after--p">Finally, we managed to successfully run our model and get the <strong class="markup--strong markup--p-strong">resulting parameters</strong>. Surely enough, they <strong class="markup--strong markup--p-strong">match</strong> the ones we got in our <em class="markup--em markup--p-em">Numpy</em>-only implementation.</p><pre name="f2c1" id="f2c1" class="graf graf--pre graf-after--p"># THIRD ATTEMPT<br>tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)</pre><h3 name="3806" id="3806" class="graf graf--h3 graf-after--pre">Dynamic Computation Graph</h3><blockquote name="3318" id="3318" class="graf graf--pullquote graf--startsWithDoubleQuote graf-after--h3">“Unfortunately, no one can be told what the dynamic computation graph is. You have to see it for yourself.” Morpheus</blockquote><p name="eaa5" id="eaa5" class="graf graf--p graf-after--pullquote">How great was “<em class="markup--em markup--p-em">The Matrix</em>”? Right, right? But, jokes aside, I want <strong class="markup--strong markup--p-strong">you</strong> to <strong class="markup--strong markup--p-strong">see the graph for yourself </strong>too!</p><blockquote name="3d87" id="3d87" class="graf graf--blockquote graf-after--p">The <a href="https://github.com/szagoruyko/pytorchviz" data-href="https://github.com/szagoruyko/pytorchviz" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank">PyTorchViz</a> package and its <code class="markup--code markup--blockquote-code"><em class="markup--em markup--blockquote-em">make_dot(variable)</em></code> method allows us to easily visualize a graph associated with a given Python variable.</blockquote><p name="0756" id="0756" class="graf graf--p graf-after--blockquote">So, let’s stick with the <strong class="markup--strong markup--p-strong">bare minimum</strong>: two (<em class="markup--em markup--p-em">gradient computing</em>) <strong class="markup--strong markup--p-strong">tensors</strong> for our parameters, predictions, errors and loss.</p><figure name="c039" id="c039" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 28.143%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/2386e532a1abcefb3b6fb2b70e0d6970?postId=81fc5f8c4e8e" data-media-id="2386e532a1abcefb3b6fb2b70e0d6970" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/2386e532a1abcefb3b6fb2b70e0d6970.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/2386e532a1abcefb3b6fb2b70e0d6970?postId=81fc5f8c4e8e" data-media-id="2386e532a1abcefb3b6fb2b70e0d6970" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Computing MSE in three steps</figcaption></figure><p name="9fa5" id="9fa5" class="graf graf--p graf-after--figure">If we call <code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">make_dot(yhat)</strong></code> we’ll get the <strong class="markup--strong markup--p-strong">left-most</strong> <strong class="markup--strong markup--p-strong">graph</strong> on Figure 3 below:</p><figure name="e6de" id="e6de" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 433px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 61.9%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*K2QnR_TRF9XfqNgNGDRqng.png" data-width="832" data-height="515" data-action="zoom" data-action-value="1*K2QnR_TRF9XfqNgNGDRqng.png" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_K2QnR_TRF9XfqNgNGDRqng.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="46"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*K2QnR_TRF9XfqNgNGDRqng.png" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_K2QnR_TRF9XfqNgNGDRqng(1).png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*K2QnR_TRF9XfqNgNGDRqng.png"></noscript></div></div><figcaption class="imageCaption">Figure 3: Computation graph for every step in computing MSE</figcaption></figure><p name="5da4" id="5da4" class="graf graf--p graf-after--figure">Let’s take a closer look at its components:</p><ul class="postList"><li name="a117" id="a117" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">blue boxes</strong>: these correspond to the <strong class="markup--strong markup--li-strong">tensors</strong> we use as <strong class="markup--strong markup--li-strong">parameters</strong>, the ones we’re asking PyTorch to <strong class="markup--strong markup--li-strong">compute gradients</strong> for;</li><li name="7cc9" id="7cc9" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">gray box</strong>: a <strong class="markup--strong markup--li-strong">Python operation</strong> that involves a <strong class="markup--strong markup--li-strong">gradient-computing tensor</strong> or <strong class="markup--strong markup--li-strong">its dependencies</strong>;</li><li name="12e7" id="12e7" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">green box</strong>: the same as the gray box, except it is the <strong class="markup--strong markup--li-strong">starting point for the computation</strong> of gradients (assuming the <code class="markup--code markup--li-code"><strong class="markup--strong markup--li-strong">backward()</strong></code>method is called from the <strong class="markup--strong markup--li-strong">variable used to visualize</strong> the graph)— they are computed from the <strong class="markup--strong markup--li-strong">bottom-up</strong> in a graph.</li></ul><p name="05c0" id="05c0" class="graf graf--p graf-after--li">If we plot graphs for the <code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">error</strong></code> (center) and <code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">loss</strong></code> (right) <strong class="markup--strong markup--p-strong">variables</strong>, the <strong class="markup--strong markup--p-strong">only difference</strong> between them and the first one is the number of <strong class="markup--strong markup--p-strong">intermediate steps</strong> (<strong class="markup--strong markup--p-strong">gray boxes</strong>).</p><p name="9f8f" id="9f8f" class="graf graf--p graf-after--p">Now, take a closer look at the <strong class="markup--strong markup--p-strong">green box</strong> of the <strong class="markup--strong markup--p-strong">left-most</strong> graph: there are <strong class="markup--strong markup--p-strong">two</strong> <strong class="markup--strong markup--p-strong">arrows</strong> pointing to it, since it is <strong class="markup--strong markup--p-strong">adding</strong> up <strong class="markup--strong markup--p-strong">two</strong> <strong class="markup--strong markup--p-strong">variables</strong>, <code class="markup--code markup--p-code">a</code> and <code class="markup--code markup--p-code">b*x</code>. Seems obvious, right?</p><p name="36fc" id="36fc" class="graf graf--p graf-after--p">Then, look at the <strong class="markup--strong markup--p-strong">gray</strong> <strong class="markup--strong markup--p-strong">box</strong> of the same graph: it is performing a <strong class="markup--strong markup--p-strong">multiplication</strong>, namely, <code class="markup--code markup--p-code">b*x</code>. But there is only one arrow pointing to it! The arrow comes from the <strong class="markup--strong markup--p-strong">blue</strong> <strong class="markup--strong markup--p-strong">box</strong> that corresponds to our <strong class="markup--strong markup--p-strong">parameter</strong> <strong class="markup--strong markup--p-strong">b</strong>.</p><p name="0f2e" id="0f2e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Why</strong> don’t we have a box for our <strong class="markup--strong markup--p-strong">data x</strong>? The answer is: we <strong class="markup--strong markup--p-strong">do not compute gradients</strong> for it! So, even though there are <em class="markup--em markup--p-em">more</em> tensors involved in the operations performed by the computation graph, it <strong class="markup--strong markup--p-strong">only</strong> shows <strong class="markup--strong markup--p-strong">gradient-computing tensors </strong>and<strong class="markup--strong markup--p-strong"> its dependencies</strong>.</p><p name="916a" id="916a" class="graf graf--p graf-after--p">What would happen to the computation graph if we set <code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">requires_grad</strong></code> to <code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">False</strong></code> for our <strong class="markup--strong markup--p-strong">parameter a</strong>?</p><figure name="c2cc" id="c2cc" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 646px; max-height: 301px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 46.6%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*HXZ6QxILteV3RlzaTaULcw.png" data-width="646" data-height="301" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_HXZ6QxILteV3RlzaTaULcw.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="33"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*HXZ6QxILteV3RlzaTaULcw.png" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_HXZ6QxILteV3RlzaTaULcw(1).png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*HXZ6QxILteV3RlzaTaULcw.png"></noscript></div></div><figcaption class="imageCaption">Figure 4: now variable a does NOT have its gradient computed anymore. But it is STILL used in computation</figcaption></figure><p name="bfb5" id="bfb5" class="graf graf--p graf-after--figure">Unsurprisingly, the <strong class="markup--strong markup--p-strong">blue box</strong> corresponding to the <strong class="markup--strong markup--p-strong">parameter a</strong> is no more! Simple enough:<strong class="markup--strong markup--p-strong"> no gradients, no graph</strong>.</p><p name="2dc5" id="2dc5" class="graf graf--p graf-after--p">The <strong class="markup--strong markup--p-strong">best</strong> thing about the <em class="markup--em markup--p-em">dynamic computing graph</em> is the fact that you can make it <strong class="markup--strong markup--p-strong">as complex as you want</strong> it. You can even use <em class="markup--em markup--p-em">control flow statements</em> (e.g., if statements) to <strong class="markup--strong markup--p-strong">control the flow of the gradients </strong>(obviously!)&nbsp;:-)</p><p name="5529" id="5529" class="graf graf--p graf-after--p">Figure 5 below shows an example of this. And yes, I do know that the computation itself is <em class="markup--em markup--p-em">completely</em> <em class="markup--em markup--p-em">nonsense</em>…</p><figure name="58d5" id="58d5" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 512px; max-height: 746px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 145.70000000000002%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*IxlhJ_iTKQh46ixxRK8BNg.png" data-width="512" data-height="746" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_IxlhJ_iTKQh46ixxRK8BNg.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="51" height="75"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*IxlhJ_iTKQh46ixxRK8BNg.png" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_IxlhJ_iTKQh46ixxRK8BNg(1).png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*IxlhJ_iTKQh46ixxRK8BNg.png"></noscript></div></div><figcaption class="imageCaption">Figure 5: Complex computation graph just to make a point&nbsp;:-)</figcaption></figure><h3 name="cf51" id="cf51" class="graf graf--h3 graf-after--figure">Optimizer</h3><p name="d74e" id="d74e" class="graf graf--p graf-after--h3">So far, we’ve been <strong class="markup--strong markup--p-strong">manually</strong> updating the parameters using the computed gradients. That’s probably fine for <em class="markup--em markup--p-em">two parameters</em>… but what if we had a <strong class="markup--strong markup--p-strong">whole lot of them</strong>?! We use one of PyTorch’s <strong class="markup--strong markup--p-strong">optimizers</strong>, like <a href="https://pytorch.org/docs/stable/optim.html#torch.optim.SGD" data-href="https://pytorch.org/docs/stable/optim.html#torch.optim.SGD" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">SGD</strong></a> or <a href="https://pytorch.org/docs/stable/optim.html#torch.optim.Adam" data-href="https://pytorch.org/docs/stable/optim.html#torch.optim.Adam" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Adam</strong></a>.</p><p name="756b" id="756b" class="graf graf--p graf-after--p">An optimizer takes the <strong class="markup--strong markup--p-strong">parameters</strong> we want to update, the <strong class="markup--strong markup--p-strong">learning rate</strong> we want to use (and possibly many other hyper-parameters as well!) and <strong class="markup--strong markup--p-strong">performs</strong> <strong class="markup--strong markup--p-strong">the</strong> <strong class="markup--strong markup--p-strong">updates</strong> through its <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer.step" data-href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer.step" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">step()</strong></a></code> method.</p><p name="bd30" id="bd30" class="graf graf--p graf-after--p">Besides, we also don’t need to zero the gradients one by one anymore. We just invoke the optimizer’s <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer.zero_grad" data-href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer.zero_grad" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">zero_grad()</strong></a></code> method and that’s it!</p><p name="8fbf" id="8fbf" class="graf graf--p graf-after--p">In the code below, we create a <em class="markup--em markup--p-em">Stochastic Gradient Descent</em> (SGD) optimizer to update our parameters <strong class="markup--strong markup--p-strong">a</strong> and <strong class="markup--strong markup--p-strong">b</strong>.</p><blockquote name="95bf" id="95bf" class="graf graf--blockquote graf-after--p">Don’t be fooled by the <strong class="markup--strong markup--blockquote-strong">optimizer</strong>’s name: if we use <strong class="markup--strong markup--blockquote-strong">all training data</strong> at once for the update — as we are actually doing in the code — the optimizer is performing a <strong class="markup--strong markup--blockquote-strong">batch</strong> gradient descent, despite of its name.</blockquote><figure name="bde3" id="bde3" class="graf graf--figure graf--iframe graf-after--blockquote"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 100.429%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/366ad9a10086099ef4da1ae0e0743143?postId=81fc5f8c4e8e" data-media-id="366ad9a10086099ef4da1ae0e0743143" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/366ad9a10086099ef4da1ae0e0743143.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/366ad9a10086099ef4da1ae0e0743143?postId=81fc5f8c4e8e" data-media-id="366ad9a10086099ef4da1ae0e0743143" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">PyTorch’s optimizer in action — no more manual update of parameters!</figcaption></figure><p name="d872" id="d872" class="graf graf--p graf-after--figure">Let’s check our two parameters, before and after, just to make sure everything is still working fine:</p><pre name="887e" id="887e" class="graf graf--pre graf-after--p"># BEFORE: a, b<br>tensor([0.6226], device='cuda:0', requires_grad=True) tensor([1.4505], device='cuda:0', requires_grad=True)<br># AFTER: a, b<br>tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)</pre><p name="a328" id="a328" class="graf graf--p graf-after--pre">Cool! We’ve <em class="markup--em markup--p-em">optimized</em> the <strong class="markup--strong markup--p-strong">optimization</strong> process&nbsp;:-) What’s left?</p><h3 name="8877" id="8877" class="graf graf--h3 graf-after--p">Loss</h3><p name="eaa7" id="eaa7" class="graf graf--p graf-after--h3">We now tackle the <strong class="markup--strong markup--p-strong">loss computation</strong>. As expected, PyTorch got us covered once again. There are many <a href="https://pytorch.org/docs/stable/nn.html#loss-functions" data-href="https://pytorch.org/docs/stable/nn.html#loss-functions" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">loss functions</a> to choose from, depending on the task at hand. Since ours is a regression, we are using the <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.MSELoss" data-href="https://pytorch.org/docs/stable/nn.html#torch.nn.MSELoss" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Mean Square Error (MSE) loss</a>.</p><blockquote name="64e3" id="64e3" class="graf graf--blockquote graf-after--p">Notice that <code class="markup--code markup--blockquote-code"><em class="markup--em markup--blockquote-em">nn.MSELoss</em></code> actually <strong class="markup--strong markup--blockquote-strong">creates a loss function</strong> for us — <strong class="markup--strong markup--blockquote-strong">it is NOT the loss function itself</strong>. Moreover, you can specify a <strong class="markup--strong markup--blockquote-strong">reduction method</strong> to be applied, that is, <strong class="markup--strong markup--blockquote-strong">how do you want to aggregate the results for individual points</strong> — you can average them (reduction=’mean’) or simply sum them up (reduction=’sum’).</blockquote><p name="1e64" id="1e64" class="graf graf--p graf-after--blockquote">We then <strong class="markup--strong markup--p-strong">use</strong> the created loss function later, at line 20, to compute the loss given our <strong class="markup--strong markup--p-strong">predictions</strong> and our <strong class="markup--strong markup--p-strong">labels</strong>.</p><p name="7a9e" id="7a9e" class="graf graf--p graf-after--p">Our code looks like this now:</p><figure name="a86c" id="a86c" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 87.857%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/a5386f1c645e0a29e56849d5a2c07c69?postId=81fc5f8c4e8e" data-media-id="a5386f1c645e0a29e56849d5a2c07c69" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/a5386f1c645e0a29e56849d5a2c07c69.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/a5386f1c645e0a29e56849d5a2c07c69?postId=81fc5f8c4e8e" data-media-id="a5386f1c645e0a29e56849d5a2c07c69" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">PyTorch’s loss in action — no more manual loss computation!</figcaption></figure><p name="b72a" id="b72a" class="graf graf--p graf-after--figure">At this point, there’s only one piece of code left to change: the <strong class="markup--strong markup--p-strong">predictions</strong>. It is then time to introduce PyTorch’s way of implementing a…</p><h3 name="6208" id="6208" class="graf graf--h3 graf-after--p">Model</h3><p name="7845" id="7845" class="graf graf--p graf-after--h3">In PyTorch, a <strong class="markup--strong markup--p-strong">model</strong> is represented by a regular <strong class="markup--strong markup--p-strong">Python class</strong> that inherits from the <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" data-href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Module</strong></a> class.</p><p name="f8c5" id="f8c5" class="graf graf--p graf-after--p">The most fundamental methods it needs to implement are:</p><ul class="postList"><li name="3250" id="3250" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code"><strong class="markup--strong markup--li-strong">__init__(self)</strong></code>:<strong class="markup--strong markup--li-strong"> it defines the parts that make up the model</strong> —in our case, two <em class="markup--em markup--li-em">parameters</em>, <strong class="markup--strong markup--li-strong">a</strong> and <strong class="markup--strong markup--li-strong">b</strong>.</li></ul><blockquote name="bd66" id="bd66" class="graf graf--blockquote graf-after--li">You are <strong class="markup--strong markup--blockquote-strong">not</strong> limited to defining <strong class="markup--strong markup--blockquote-strong">parameters</strong>, though… <strong class="markup--strong markup--blockquote-strong">models can contain other models (or layers) as its attributes</strong> as well, so you can easily nest them. We’ll see an example of this shortly as well.</blockquote><ul class="postList"><li name="dce0" id="dce0" class="graf graf--li graf-after--blockquote"><code class="markup--code markup--li-code"><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.forward" data-href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.forward" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">forward(self, x)</strong></a></code>: it performs the <strong class="markup--strong markup--li-strong">actual computation</strong>, that is, it <strong class="markup--strong markup--li-strong">outputs a prediction</strong>, given the input <strong class="markup--strong markup--li-strong">x</strong>.</li></ul><blockquote name="8e3e" id="8e3e" class="graf graf--blockquote graf-after--li">You should <strong class="markup--strong markup--blockquote-strong">NOT call the </strong><code class="markup--code markup--blockquote-code"><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">forward(x)</em></strong></code> method, though. You should <strong class="markup--strong markup--blockquote-strong">call the whole model itself</strong>, as in <code class="markup--code markup--blockquote-code"><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">model(x)</em></strong></code> to perform a forward pass and output predictions.</blockquote><p name="5ff0" id="5ff0" class="graf graf--p graf-after--blockquote">Let’s build a proper (yet simple) model for our regression task. It should look like this:</p><figure name="050d" id="050d" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 37.571%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/7c2fcbe5e42de8f5ce24c0813b3b2430?postId=81fc5f8c4e8e" data-media-id="7c2fcbe5e42de8f5ce24c0813b3b2430" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/7c2fcbe5e42de8f5ce24c0813b3b2430.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/7c2fcbe5e42de8f5ce24c0813b3b2430?postId=81fc5f8c4e8e" data-media-id="7c2fcbe5e42de8f5ce24c0813b3b2430" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Building our “Manual” model, creating parameter by parameter!</figcaption></figure><p name="9378" id="9378" class="graf graf--p graf-after--figure">In the <code class="markup--code markup--p-code">__init__</code> method, we define our <strong class="markup--strong markup--p-strong">two parameters</strong>, <strong class="markup--strong markup--p-strong">a</strong> and <strong class="markup--strong markup--p-strong">b</strong>, using the <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Parameter" data-href="https://pytorch.org/docs/stable/nn.html#torch.nn.Parameter" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Parameter()</strong></a></code> class, to tell PyTorch these <strong class="markup--strong markup--p-strong">tensors should be considered parameters of the model they are an attribute of</strong>.</p><p name="de68" id="de68" class="graf graf--p graf-after--p">Why should we care about that? By doing so, we can use our model’s <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.parameters" data-href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.parameters" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">parameters()</strong></a></code> method to retrieve <strong class="markup--strong markup--p-strong">an iterator over all model’s parameters</strong>, <strong class="markup--strong markup--p-strong">even</strong> those parameters of <strong class="markup--strong markup--p-strong">nested models</strong>, that we can use to feed our optimizer (instead of building a list of parameters ourselves!).</p><p name="c644" id="c644" class="graf graf--p graf-after--p">Moreover, we can get the <strong class="markup--strong markup--p-strong">current values for all parameters</strong> using our model’s <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.state_dict" data-href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.state_dict" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">state_dict()</strong></a></code> method.</p><blockquote name="846e" id="846e" class="graf graf--blockquote graf-after--p"><strong class="markup--strong markup--blockquote-strong">IMPORTANT</strong>: we need to <strong class="markup--strong markup--blockquote-strong">send our model to the same device where the data is</strong>. If our data is made of GPU tensors, our model must “live” inside the GPU as well.</blockquote><p name="87a5" id="87a5" class="graf graf--p graf-after--blockquote">We can use all these handy methods to change our code, which should be looking like this:</p><figure name="890e" id="890e" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 91%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/fbed630588d5ec7298ab570bf3c3ede4?postId=81fc5f8c4e8e" data-media-id="fbed630588d5ec7298ab570bf3c3ede4" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/fbed630588d5ec7298ab570bf3c3ede4.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/fbed630588d5ec7298ab570bf3c3ede4?postId=81fc5f8c4e8e" data-media-id="fbed630588d5ec7298ab570bf3c3ede4" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">PyTorch’s model in action — no more manual prediction/forward step!</figcaption></figure><p name="b07d" id="b07d" class="graf graf--p graf-after--figure">Now, the printed statements will look like this — final values for parameters <strong class="markup--strong markup--p-strong">a</strong> and <strong class="markup--strong markup--p-strong">b</strong> are still the same, so everything is ok&nbsp;:-)</p><pre name="e1cc" id="e1cc" class="graf graf--pre graf-after--p">OrderedDict([('a', tensor([0.3367], device='cuda:0')), ('b', tensor([0.1288], device='cuda:0'))])<br>OrderedDict([('a', tensor([1.0235], device='cuda:0')), ('b', tensor([1.9690], device='cuda:0'))])</pre><p name="e147" id="e147" class="graf graf--p graf-after--pre">I hope you noticed one particular statement in the code, to which I assigned a comment <strong class="markup--strong markup--p-strong">“What is this?!?” — </strong><code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">model.train()</strong></code>.</p><blockquote name="eb9c" id="eb9c" class="graf graf--blockquote graf-after--p">In PyTorch, models have a <code class="markup--code markup--blockquote-code"><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.train" data-href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.train" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--blockquote-strong"><em class="markup--em markup--blockquote-em">train()</em></strong></a></code> method which, somewhat disappointingly, <strong class="markup--strong markup--blockquote-strong">does NOT perform a training step</strong>. Its only purpose is to <strong class="markup--strong markup--blockquote-strong">set the model to training mode</strong>. Why is this important? Some models may use mechanisms like <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout" data-href="https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--blockquote-strong">Dropout</strong></a>, for instance, which have <strong class="markup--strong markup--blockquote-strong">distinct behaviors in training and evaluation</strong> phases.</blockquote><h4 name="54f8" id="54f8" class="graf graf--h4 graf-after--blockquote">Nested Models</h4><p name="90b8" id="90b8" class="graf graf--p graf-after--h4">In our model, we manually created two parameters to perform a linear regression. Let’s use PyTorch’s <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Linear" data-href="https://pytorch.org/docs/stable/nn.html#torch.nn.Linear" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Linear</strong></a> model as an attribute of our own, thus creating a nested model.</p><p name="d3f8" id="d3f8" class="graf graf--p graf-after--p">Even though this clearly is a contrived example, as we are pretty much wrapping the underlying model without adding anything useful (or, at all!) to it, it illustrates well the concept.</p><p name="8749" id="8749" class="graf graf--p graf-after--p">In the <code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">__init__</strong></code> method, we created an <strong class="markup--strong markup--p-strong">attribute</strong> that contains our <strong class="markup--strong markup--p-strong">nested </strong><code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">Linear</strong></code><strong class="markup--strong markup--p-strong"> model</strong>.</p><p name="ac3f" id="ac3f" class="graf graf--p graf-after--p">In the <code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">forward()</strong></code> method, we <strong class="markup--strong markup--p-strong">call the nested model itself</strong> to perform the forward pass (<em class="markup--em markup--p-em">notice, we are </em><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">not</em></strong><em class="markup--em markup--p-em"> calling </em><code class="markup--code markup--p-code"><em class="markup--em markup--p-em">self.linear.forward(x)</em></code><em class="markup--em markup--p-em">!</em>).</p><figure name="d5d1" id="d5d1" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 34.429%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/cc011f0227ae4101d9b3d19f5b46ff29?postId=81fc5f8c4e8e" data-media-id="cc011f0227ae4101d9b3d19f5b46ff29" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/cc011f0227ae4101d9b3d19f5b46ff29.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/cc011f0227ae4101d9b3d19f5b46ff29?postId=81fc5f8c4e8e" data-media-id="cc011f0227ae4101d9b3d19f5b46ff29" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Building a model using PyTorch’s Linear layer</figcaption></figure><p name="532b" id="532b" class="graf graf--p graf-after--figure">Now, if we call the <code class="markup--code markup--p-code"><strong class="markup--strong markup--p-strong">parameters()</strong></code> method of this model, <strong class="markup--strong markup--p-strong">PyTorch will figure the parameters of its attributes in a recursive way</strong>. You can try it yourself using something like: <code class="markup--code markup--p-code">[*LayerLinearRegression().parameters()]</code> to get a list of all parameters. You can also add new <code class="markup--code markup--p-code">Linear</code> attributes and, even if you don’t use them at all in the forward pass, they will <strong class="markup--strong markup--p-strong">still</strong> be listed under <code class="markup--code markup--p-code">parameters()</code>.</p><h4 name="0f2d" id="0f2d" class="graf graf--h4 graf-after--p">Sequential Models</h4><p name="8060" id="8060" class="graf graf--p graf-after--h4">Our model was simple enough… You may be thinking: <em class="markup--em markup--p-em">“why even bother to build a class for it?!”</em> Well, you have a point…</p><p name="000c" id="000c" class="graf graf--p graf-after--p">For <strong class="markup--strong markup--p-strong">straightforward models</strong>, that use <strong class="markup--strong markup--p-strong">run-of-the-mill layers</strong>, where the output of a layer is sequentially fed as an input to the next, we can use a, er… <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential" data-href="https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Sequential</strong></a> model&nbsp;:-)</p><p name="cc24" id="cc24" class="graf graf--p graf-after--p">In our case, we would build a Sequential model with a single argument, that is, the <code class="markup--code markup--p-code">Linear</code> layer we used to train our linear regression. The model would look like this:</p><pre name="e70f" id="e70f" class="graf graf--pre graf-after--p"># Alternatively, you can use a Sequential model<br>model = nn.Sequential(nn.Linear(1, 1)).to(device)</pre><p name="5b2b" id="5b2b" class="graf graf--p graf-after--pre">Simple enough, right?</p><h4 name="b1d0" id="b1d0" class="graf graf--h4 graf-after--p">Training Step</h4><p name="fa5a" id="fa5a" class="graf graf--p graf-after--h4">So far, we’ve defined an <strong class="markup--strong markup--p-strong">optimizer</strong>, a <strong class="markup--strong markup--p-strong">loss function</strong> and a <strong class="markup--strong markup--p-strong">model</strong>. Scroll up a bit and take a quick look at the code <em class="markup--em markup--p-em">inside the loop</em>. Would it <strong class="markup--strong markup--p-strong">change</strong> if we were using a <strong class="markup--strong markup--p-strong">different optimizer</strong>, or <strong class="markup--strong markup--p-strong">loss</strong>, or even <strong class="markup--strong markup--p-strong">model</strong>? If not, how can we make it <strong class="markup--strong markup--p-strong">more generic</strong>?</p><p name="36b8" id="36b8" class="graf graf--p graf-after--p">Well, I guess we could say all these lines of code <strong class="markup--strong markup--p-strong">perform a training step</strong>, given those <strong class="markup--strong markup--p-strong">three elements</strong> (<em class="markup--em markup--p-em">optimizer, loss and model</em>),the <strong class="markup--strong markup--p-strong">features</strong> and the <strong class="markup--strong markup--p-strong">labels</strong>.</p><p name="6e55" id="6e55" class="graf graf--p graf-after--p">So, how about <strong class="markup--strong markup--p-strong">writing a function that takes those three elements</strong> and <strong class="markup--strong markup--p-strong">returns another function that performs a training step</strong>,<strong class="markup--strong markup--p-strong"> </strong>taking a set of features and labels as arguments and returning the corresponding loss?</p><p name="98bf" id="98bf" class="graf graf--p graf-after--p">Then we can use this general-purpose function to build a <code class="markup--code markup--p-code u-paddingRight0 u-marginRight0"><strong class="markup--strong markup--p-strong">train_step()</strong> </code>function to be called inside our training loop. Now our code should look like this… see how <strong class="markup--strong markup--p-strong">tiny</strong> the training loop is now?</p><figure name="fe9d" id="fe9d" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 106.714%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/6de63a0f698032317c21eca41d936d0f?postId=81fc5f8c4e8e" data-media-id="6de63a0f698032317c21eca41d936d0f" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/6de63a0f698032317c21eca41d936d0f.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/6de63a0f698032317c21eca41d936d0f?postId=81fc5f8c4e8e" data-media-id="6de63a0f698032317c21eca41d936d0f" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Building a function to perform one step of training!</figcaption></figure><p name="2094" id="2094" class="graf graf--p graf-after--figure">Let’s give our training loop a rest and focus on our <strong class="markup--strong markup--p-strong">data</strong> for a while… so far, we’ve simply used our <em class="markup--em markup--p-em">Numpy arrays</em> turned <strong class="markup--strong markup--p-strong">PyTorch tensors</strong>. But we can do better, we can build a…</p><h3 name="2e24" id="2e24" class="graf graf--h3 graf-after--p">Dataset</h3><p name="63f4" id="63f4" class="graf graf--p graf-after--h3">In PyTorch, a <strong class="markup--strong markup--p-strong">dataset</strong> is represented by a regular <strong class="markup--strong markup--p-strong">Python class</strong> that inherits from the <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" data-href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Dataset</strong></a> class. You can think of it as a kind of a Python <strong class="markup--strong markup--p-strong">list of tuples</strong>, each tuple corresponding to <strong class="markup--strong markup--p-strong">one point (features, label)</strong>.</p><p name="941e" id="941e" class="graf graf--p graf-after--p">The most fundamental methods it needs to implement are:</p><ul class="postList"><li name="b9ac" id="b9ac" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code"><strong class="markup--strong markup--li-strong">__init__(self)</strong></code><strong class="markup--strong markup--li-strong">&nbsp;</strong>: it takes <strong class="markup--strong markup--li-strong">whatever arguments</strong> needed to build a <strong class="markup--strong markup--li-strong">list of tuples</strong> — it may be the name of a CSV file that will be loaded and processed; it may be <em class="markup--em markup--li-em">two tensors</em>, one for features, another one for labels; or anything else, depending on the task at hand.</li></ul><blockquote name="e3a7" id="e3a7" class="graf graf--blockquote graf-after--li">There is <strong class="markup--strong markup--blockquote-strong">no need to load the whole dataset in the constructor method </strong>(<code class="markup--code markup--blockquote-code">__init__</code>). If your <strong class="markup--strong markup--blockquote-strong">dataset is big</strong> (tens of thousands of image files, for instance), loading it at once would not be memory efficient. It is recommended to <strong class="markup--strong markup--blockquote-strong">load them on demand</strong> (whenever <code class="markup--code markup--blockquote-code">__get_item__</code> is called).</blockquote><ul class="postList"><li name="90ad" id="90ad" class="graf graf--li graf-after--blockquote"><code class="markup--code markup--li-code"><strong class="markup--strong markup--li-strong">__get_item__(self, index)</strong></code>: it allows the dataset to be <strong class="markup--strong markup--li-strong">indexed</strong>, so it can work <strong class="markup--strong markup--li-strong">like a list</strong> (<code class="markup--code markup--li-code">dataset[i]</code>) — it must <strong class="markup--strong markup--li-strong">return a tuple (features, label)</strong> corresponding to the requested data point. We can either return the <strong class="markup--strong markup--li-strong">corresponding slices</strong> of our <strong class="markup--strong markup--li-strong">pre-loaded</strong> dataset or tensors or, as mentioned above, <strong class="markup--strong markup--li-strong">load</strong> <strong class="markup--strong markup--li-strong">them on demand</strong> (like in this <a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class" data-href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">example</a>).</li><li name="ed31" id="ed31" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code"><strong class="markup--strong markup--li-strong">__len__(self)</strong></code>: it should simply return the <strong class="markup--strong markup--li-strong">size</strong> of the whole dataset so, whenever it is sampled, its indexing is limited to the actual size.</li></ul><p name="0373" id="0373" class="graf graf--p graf-after--li">Let’s build a simple custom dataset that takes two tensors as arguments: one for the features, one for the labels. For any given index, our dataset class will return the corresponding slice of each of those tensors. It should look like this:</p><figure name="36c8" id="36c8" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 75.286%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/14e1c7cc81207c834aaaa47a4e65292c?postId=81fc5f8c4e8e" data-media-id="14e1c7cc81207c834aaaa47a4e65292c" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/14e1c7cc81207c834aaaa47a4e65292c.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/14e1c7cc81207c834aaaa47a4e65292c?postId=81fc5f8c4e8e" data-media-id="14e1c7cc81207c834aaaa47a4e65292c" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Creating datasets using train tensors</figcaption></figure><p name="772c" id="772c" class="graf graf--p graf-after--figure">Once again, you may be thinking “<em class="markup--em markup--p-em">why go through all this trouble to wrap a couple of tensors in a class?</em>”. And, once again, you do have a point… if a dataset is nothing else but a <strong class="markup--strong markup--p-strong">couple of tensors</strong>, we can use PyTorch’s <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset" data-href="https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">TensorDataset</strong></a> class, which will do pretty much what we did in our custom dataset above.</p><blockquote name="3825" id="3825" class="graf graf--blockquote graf-after--p">Did you notice we built our <strong class="markup--strong markup--blockquote-strong">training tensors</strong> out of Numpy arrays but we <strong class="markup--strong markup--blockquote-strong">did not send them to a device</strong>? So, they are <strong class="markup--strong markup--blockquote-strong">CPU</strong> tensors now! <strong class="markup--strong markup--blockquote-strong">Why</strong>?</blockquote><blockquote name="9b02" id="9b02" class="graf graf--blockquote graf-after--blockquote">We <strong class="markup--strong markup--blockquote-strong">don’t want our whole training data to be loaded into GPU tensors</strong>, as we have been doing in our example so far, because<strong class="markup--strong markup--blockquote-strong"> it takes up space</strong> in our precious <strong class="markup--strong markup--blockquote-strong">graphics card’s RAM.</strong></blockquote><p name="a322" id="a322" class="graf graf--p graf-after--blockquote">OK, fine, but then again, <strong class="markup--strong markup--p-strong">why</strong> are we building a dataset anyway? We’re doing it because we want to use a…</p><h3 name="58f2" id="58f2" class="graf graf--h3 graf-after--p">DataLoader</h3><p name="9ba5" id="9ba5" class="graf graf--p graf-after--h3">Until now, we have used the <strong class="markup--strong markup--p-strong">whole training data</strong> at every training step. It has been <strong class="markup--strong markup--p-strong">batch gradient descent</strong> all along. This is fine for our <em class="markup--em markup--p-em">ridiculously small dataset</em>, sure, but if we want to go serious about all this, we <strong class="markup--strong markup--p-strong">must</strong> use <strong class="markup--strong markup--p-strong">mini-batch</strong> gradient descent. Thus, we need mini-batches. Thus, we need to <strong class="markup--strong markup--p-strong">slice</strong> our dataset accordingly. Do you want to do it <em class="markup--em markup--p-em">manually</em>?! Me neither!</p><p name="5cf0" id="5cf0" class="graf graf--p graf-after--p">So we use PyTorch’s <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" data-href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">DataLoader</strong></a> class for this job. We tell it which <strong class="markup--strong markup--p-strong">dataset</strong> to use (the one we just built in the previous section), the desired <strong class="markup--strong markup--p-strong">mini-batch size</strong> and if we’d like to <strong class="markup--strong markup--p-strong">shuffle</strong> it or not. That’s it!</p><p name="1eb1" id="1eb1" class="graf graf--p graf-after--p">Our <strong class="markup--strong markup--p-strong">loader</strong> will behave like an <strong class="markup--strong markup--p-strong">iterator</strong>, so we can <strong class="markup--strong markup--p-strong">loop over it</strong> and <strong class="markup--strong markup--p-strong">fetch a different mini-batch</strong> every time.</p><figure name="a39f" id="a39f" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 15.571%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/7eb844f7971351ce51dab5e5f9e448a5?postId=81fc5f8c4e8e" data-media-id="7eb844f7971351ce51dab5e5f9e448a5" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/7eb844f7971351ce51dab5e5f9e448a5.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/7eb844f7971351ce51dab5e5f9e448a5?postId=81fc5f8c4e8e" data-media-id="7eb844f7971351ce51dab5e5f9e448a5" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Building a data loader for our training data</figcaption></figure><p name="41d4" id="41d4" class="graf graf--p graf-after--figure">To retrieve a sample mini-batch, one can simply run the command below — it will return a list containing two tensors, one for the features, another one for the labels.</p><pre name="d37e" id="d37e" class="graf graf--pre graf-after--p">next(iter(train_loader))</pre><p name="3c32" id="3c32" class="graf graf--p graf-after--pre">How does this change our training loop? Let’s check it out!</p><figure name="9bba" id="9bba" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 53.286%;"></div><div class="progressiveMedia js-progressiveMedia is-imageLoaded is-canvasLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/59ce5b39db04431f6400f2c60ebb7cc9?postId=81fc5f8c4e8e" data-media-id="59ce5b39db04431f6400f2c60ebb7cc9" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/59ce5b39db04431f6400f2c60ebb7cc9.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/59ce5b39db04431f6400f2c60ebb7cc9?postId=81fc5f8c4e8e" data-media-id="59ce5b39db04431f6400f2c60ebb7cc9" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Using mini-batch gradient descent!</figcaption></figure><p name="037b" id="037b" class="graf graf--p graf-after--figure">Two things are different now: not only we have an<strong class="markup--strong markup--p-strong"> </strong><em class="markup--em markup--p-em">inner loop</em> to load each and every <em class="markup--em markup--p-em">mini-batch</em> from our <code class="markup--code markup--p-code">DataLoader</code> but, more importantly, we are now <strong class="markup--strong markup--p-strong">sending only one mini-batch to the device</strong>.</p><blockquote name="9815" id="9815" class="graf graf--blockquote graf-after--p">For bigger datasets, <strong class="markup--strong markup--blockquote-strong">loading data</strong> <strong class="markup--strong markup--blockquote-strong">sample by sample</strong> (into a <strong class="markup--strong markup--blockquote-strong">CPU</strong> tensor) using <strong class="markup--strong markup--blockquote-strong">Dataset’s</strong><code class="markup--code markup--blockquote-code"><strong class="markup--strong markup--blockquote-strong"> __get_item__</strong></code> and then <strong class="markup--strong markup--blockquote-strong">sending all samples</strong> that belong to the same <strong class="markup--strong markup--blockquote-strong">mini-batch at once to your GPU</strong> (device) is the way to go in order to make the <strong class="markup--strong markup--blockquote-strong">best use of your graphics card’s RAM</strong>.</blockquote><blockquote name="9000" id="9000" class="graf graf--blockquote graf-after--blockquote">Moreover, if you have <strong class="markup--strong markup--blockquote-strong">many GPUs</strong> to train your model on, it is best to keep your dataset “agnostic” and assign the batches to different GPUs during training.</blockquote><p name="6578" id="6578" class="graf graf--p graf-after--blockquote">So far, we’ve focused on the <strong class="markup--strong markup--p-strong">training</strong> <strong class="markup--strong markup--p-strong">data</strong> only. We built a <em class="markup--em markup--p-em">dataset</em> and a <em class="markup--em markup--p-em">data loader</em> for it. We could do the same for the <strong class="markup--strong markup--p-strong">validation</strong> data, using the <strong class="markup--strong markup--p-strong">split</strong> we performed at the beginning of this post… or we could use <code class="markup--code markup--p-code">random_split</code> instead.</p><h4 name="82af" id="82af" class="graf graf--h4 graf-after--p">Random Split</h4><p name="46f8" id="46f8" class="graf graf--p graf-after--h4">PyTorch’s <code class="markup--code markup--p-code"><a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split" data-href="https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">random_split()</strong></a></code> method is an easy and familiar way of performing a <strong class="markup--strong markup--p-strong">training-validation split</strong>. Just keep in mind that, in our example, we need to apply it to the <strong class="markup--strong markup--p-strong">whole dataset</strong> (<em class="markup--em markup--p-em">not the training dataset</em> we built in two sections ago).</p><p name="e1a8" id="e1a8" class="graf graf--p graf-after--p">Then, for each subset of data, we build a corresponding <code class="markup--code markup--p-code">DataLoader</code>, so our code looks like this:</p><figure name="51f3" id="51f3" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 40.714%;"></div><div class="progressiveMedia js-progressiveMedia is-canvasLoaded is-imageLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/6effb811cf5f806031fec33c689852c3?postId=81fc5f8c4e8e" data-media-id="6effb811cf5f806031fec33c689852c3" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/6effb811cf5f806031fec33c689852c3.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/6effb811cf5f806031fec33c689852c3?postId=81fc5f8c4e8e" data-media-id="6effb811cf5f806031fec33c689852c3" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Splitting the dataset into training and validation sets, the PyTorch way!</figcaption></figure><p name="c182" id="c182" class="graf graf--p graf-after--figure">Now we have a <strong class="markup--strong markup--p-strong">data loader</strong> for our <strong class="markup--strong markup--p-strong">validation set</strong>, so, it makes sense to use it for the…</p><h3 name="5017" id="5017" class="graf graf--h3 graf-after--p">Evaluation</h3><p name="6d13" id="6d13" class="graf graf--p graf-after--h3">This is the <strong class="markup--strong markup--p-strong">last</strong> part of our journey — we need to change the training loop to include the <strong class="markup--strong markup--p-strong">evaluation of our model</strong>, that is, computing the <strong class="markup--strong markup--p-strong">validation loss</strong>. The first step is to include another inner loop to handle the <em class="markup--em markup--p-em">mini-batches</em> that come from the <em class="markup--em markup--p-em">validation loader</em>&nbsp;, sending them to the same <em class="markup--em markup--p-em">device</em> as our model. Next, we make <strong class="markup--strong markup--p-strong">predictions</strong> using our model (line 23) and compute the corresponding <strong class="markup--strong markup--p-strong">loss</strong> (line 24).</p><p name="fb1b" id="fb1b" class="graf graf--p graf-after--p">That’s pretty much it, but there are <strong class="markup--strong markup--p-strong">two small</strong>,<strong class="markup--strong markup--p-strong"> yet important</strong>, things to consider:</p><ul class="postList"><li name="c9f1" id="c9f1" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code"><a href="https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad" data-href="https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">torch.no_grad()</strong></a></code>: even though it won’t make a difference in our simple model, it is a <strong class="markup--strong markup--li-strong">good practice</strong> to <strong class="markup--strong markup--li-strong">wrap the validation</strong> inner loop with this <strong class="markup--strong markup--li-strong">context manager to disable any gradient calculation</strong> that you may inadvertently trigger — <strong class="markup--strong markup--li-strong">gradients belong in training</strong>, not in validation steps;</li><li name="2621" id="2621" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code"><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.eval" data-href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.eval" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">eval()</strong></a></code>: the only thing it does is <strong class="markup--strong markup--li-strong">setting the model to evaluation mode</strong> (just like its <code class="markup--code markup--li-code">train()</code> counterpart did), so the model can adjust its behavior regarding some operations, like <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout" data-href="https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">Dropout</strong></a>.</li></ul><p name="5345" id="5345" class="graf graf--p graf-after--li">Now, our training loop should look like this:</p><figure name="0cbd" id="0cbd" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 81.571%;"></div><div class="progressiveMedia js-progressiveMedia is-canvasLoaded is-imageLoaded" data-scroll="native"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/resize" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><div class="iframeContainer"><iframe width="700" height="250" data-src="/media/8edff7d6851e76ecc3acf44d545feb62?postId=81fc5f8c4e8e" data-media-id="8edff7d6851e76ecc3acf44d545feb62" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" class="progressiveMedia-iframe js-progressiveMedia-iframe" allowfullscreen="" frameborder="0" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/8edff7d6851e76ecc3acf44d545feb62.html"></iframe></div><noscript class="js-progressiveMedia-inner"><div class="iframeContainer"><IFRAME width="700" height="250" src="/media/8edff7d6851e76ecc3acf44d545feb62?postId=81fc5f8c4e8e" data-media-id="8edff7d6851e76ecc3acf44d545feb62" data-thumbnail="https://i.embed.ly/1/image?url=https%3A%2F%2Favatars3.githubusercontent.com%2Fu%2F5184020%3Fs%3D400%26v%3D4&amp;key=a19fcc184b9711e1b4764040d3dc5c07" allowfullscreen frameborder="0"></IFRAME></div></noscript></div></div><figcaption class="imageCaption">Computing validation loss</figcaption></figure><p name="1211" id="1211" class="graf graf--p graf-after--figure">Is there <strong class="markup--strong markup--p-strong">anything else</strong> we can improve or change? Sure, there is <strong class="markup--strong markup--p-strong">always something else</strong> to add to your model — using a <a href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate" data-href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">learning rate scheduler</strong></a>, for instance. But this post is already <em class="markup--em markup--p-em">waaaay too long</em>, so I will stop right here.</p><p name="8dcf" id="8dcf" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“<em class="markup--em markup--p-em">Where is the full working code with all bells and whistles?</em>”, you ask? You can find it <a href="https://gist.github.com/dvgodoy/1d818d86a6a0dc6e7c07610835b46fe4" data-href="https://gist.github.com/dvgodoy/1d818d86a6a0dc6e7c07610835b46fe4" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">here</strong></a>.</p><h3 name="36e3" id="36e3" class="graf graf--h3 graf-after--p">Final Thoughts</h3><p name="b4ac" id="b4ac" class="graf graf--p graf-after--h3">Although this post was <em class="markup--em markup--p-em">much longer</em> than I anticipated when I started writing it, I wouldn’t make it any different — I believe it has <strong class="markup--strong markup--p-strong">most of the necessary steps</strong> one needs go to trough in order to <strong class="markup--strong markup--p-strong">learn</strong>, in a <strong class="markup--strong markup--p-strong">structured</strong> and <strong class="markup--strong markup--p-strong">incremental</strong> way, how to <strong class="markup--strong markup--p-strong">develop Deep Learning models using PyTorch</strong>.</p><p name="1dd3" id="1dd3" class="graf graf--p graf-after--p">Hopefully, after finishing working through all code in this post, you’ll be able to better appreciate and more easily work your way through PyTorch’s official <a href="https://pytorch.org/tutorials/" data-href="https://pytorch.org/tutorials/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">tutorials</a>.</p><p name="d580" id="d580" class="graf graf--p graf-after--p graf--trailing"><em class="markup--em markup--p-em">If you have any thoughts, comments or questions, please leave a comment below or contact me on </em><a href="https://twitter.com/dvgodoy" data-href="https://twitter.com/dvgodoy" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">Twitter</em></a><em class="markup--em markup--p-em">.</em></p></div></div></section></div><footer class="u-paddingTop10"><div class="container u-maxWidth740"><div class="row"><div class="col u-size12of12"></div></div><div class="row"><div class="col u-size12of12 js-postTags"><div class="u-paddingBottom10"><ul class="tags tags--postTags tags--borderless"><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/machine-learning?source=post" data-action-source="post" data-collection-slug="towards-data-science">Machine Learning</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/deep-learning?source=post" data-action-source="post" data-collection-slug="towards-data-science">Deep Learning</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/pytorch?source=post" data-action-source="post" data-collection-slug="towards-data-science">Pytorch</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/towards-data-science?source=post" data-action-source="post" data-collection-slug="towards-data-science">Towards Data Science</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/tutorial?source=post" data-action-source="post" data-collection-slug="towards-data-science">Tutorial</a></li></ul></div></div></div><div class="postActions js-postActionsFooter "><div class="u-flexCenter"><div class="u-flex1"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="81fc5f8c4e8e" data-is-icon-29px="true" data-is-circle="true" data-has-recommend-list="true" data-source="post_actions_footer-----81fc5f8c4e8e---------------------clap_footer" data-clap-string-singular="clap" data-clap-string-plural="claps"><div class="u-relative u-foreground"><button class="button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal clap-onboardingcollection" data-action="multivote" data-action-value="81fc5f8c4e8e" data-action-type="long-press" data-action-source="post_actions_footer-----81fc5f8c4e8e---------------------clap_footer" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33"><path d="M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33"><g fill-rule="evenodd"><path d="M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z"></path><path d="M13.285.48l-1.916.881 2.37 2.837z"></path><path d="M21.719 1.361L19.79.501l-.44 3.697z"></path><path d="M16.502 3.298L15.481 0h2.043z"></path></g></svg></span></span></button><div class="clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Springu-backgroundGrayLighter js-clapUndo" style="top: 14px; padding: 2px;"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight" data-action="multivote-undo" data-action-value="81fc5f8c4e8e"><span class="svgIcon svgIcon--removeThin svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61" fill-rule="evenodd"></path></svg></span></button></div></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft16"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-textColorDarker" data-action="show-recommends" data-action-value="81fc5f8c4e8e">250 claps</button><span class="u-xs-hide"></span></span></div></div><div class="buttonSet u-flex0"><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless u-xs-hide u-marginRight12" href="https://medium.com/p/81fc5f8c4e8e/share/twitter" title="Share on Twitter" aria-label="Share on Twitter" target="_blank" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M22.053 7.54a4.474 4.474 0 0 0-3.31-1.455 4.526 4.526 0 0 0-4.526 4.524c0 .35.04.7.082 1.05a12.9 12.9 0 0 1-9.3-4.77c-.39.69-.61 1.46-.65 2.26.03 1.6.83 2.99 2.02 3.79-.72-.02-1.41-.22-2.02-.57-.01.02-.01.04 0 .08-.01 2.17 1.55 4 3.63 4.44-.39.08-.79.13-1.21.16-.28-.03-.57-.05-.81-.08.54 1.77 2.21 3.08 4.2 3.15a9.564 9.564 0 0 1-5.66 1.94c-.34-.03-.7-.06-1.05-.08 2 1.27 4.38 2.02 6.94 2.02 8.31 0 12.86-6.9 12.84-12.85.02-.24.01-.43 0-.65.89-.62 1.65-1.42 2.26-2.34-.82.38-1.69.62-2.59.72a4.37 4.37 0 0 0 1.94-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></span></span></a><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless u-xs-hide u-marginRight12" href="https://medium.com/p/81fc5f8c4e8e/share/facebook" title="Share on Facebook" aria-label="Share on Facebook" target="_blank" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--facebookSquare svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M23.209 5H5.792A.792.792 0 0 0 5 5.791V23.21c0 .437.354.791.792.791h9.303v-7.125H12.72v-2.968h2.375v-2.375c0-2.455 1.553-3.662 3.741-3.662 1.049 0 1.95.078 2.213.112v2.565h-1.517c-1.192 0-1.469.567-1.469 1.397v1.963h2.969l-.594 2.968h-2.375L18.11 24h5.099a.791.791 0 0 0 .791-.791V5.79a.791.791 0 0 0-.791-.79"></path></svg></span></span></a><button class="button button--large button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-show u-marginRight10" title="Share this story on Twitter or Facebook" aria-label="Share this story on Twitter or Facebook" data-action="show-share-popover" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--share svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M20.385 8H19a.5.5 0 1 0 .011 1h1.39c.43 0 .84.168 1.14.473.31.305.48.71.48 1.142v10.77c0 .43-.17.837-.47 1.142-.3.305-.71.473-1.14.473H8.62c-.43 0-.84-.168-1.144-.473a1.603 1.603 0 0 1-.473-1.142v-10.77c0-.43.17-.837.48-1.142A1.599 1.599 0 0 1 8.62 9H10a.502.502 0 0 0 0-1H8.615c-.67 0-1.338.255-1.85.766-.51.51-.765 1.18-.765 1.85v10.77c0 .668.255 1.337.766 1.848.51.51 1.18.766 1.85.766h11.77c.668 0 1.337-.255 1.848-.766.51-.51.766-1.18.766-1.85v-10.77c0-.668-.255-1.337-.766-1.848A2.61 2.61 0 0 0 20.384 8zm-8.67-2.508L14 3.207v8.362c0 .27.224.5.5.5s.5-.23.5-.5V3.2l2.285 2.285a.49.49 0 0 0 .704-.001.511.511 0 0 0 0-.708l-3.14-3.14a.504.504 0 0 0-.71 0L11 4.776a.501.501 0 0 0 .71.706" fill-rule="evenodd"></path></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" data-action="respond" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal u-marginRight12" data-action="scroll-to-responses">2</button><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="add-to-bookmarks" data-action-value="81fc5f8c4e8e" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px u-marginRight4"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px u-marginRight4"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"></path></svg></span></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon js-moreActionsButton" title="More actions" aria-label="More actions" data-action="more-actions"><span class="svgIcon svgIcon--more svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="-480.5 272.5 21 21"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></span></button></div></div></div></div><div class="u-maxWidth740 u-paddingTop20 u-marginTop20 u-borderTopLightest container u-paddingBottom20 u-xs-paddingBottom10 js-postAttributionFooterContainer"><div class="row js-postFooterInfo"><div class="col u-size6of12 u-xs-size12of12"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardUser"><div class="u-marginLeft20 u-floatRight"><span class="followState js-followState" data-user-id="c79695e37339"><button class="button button--small u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton" data-action="toggle-block-user" data-action-value="c79695e37339" data-action-source="footer_card"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton" data-action="toggle-subscribe-user" data-action-value="c79695e37339" data-action-source="footer_card-c79695e37339-------------------------follow_footer" data-subscribe-source="footer_card" data-follow-context-entity-id="81fc5f8c4e8e"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="u-tableCell"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@dvgodoy?source=footer_card" title="Go to the profile of Daniel Godoy" aria-label="Go to the profile of Daniel Godoy" data-action-source="footer_card" data-user-id="c79695e37339" data-collection-slug="towards-data-science" dir="auto"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_7kL4DitERABkDkP-caSAZA(1).png" class="avatar-image avatar-image--small" alt="Go to the profile of Daniel Godoy"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://towardsdatascience.com/@dvgodoy" property="cc:attributionName" title="Go to the profile of Daniel Godoy" aria-label="Go to the profile of Daniel Godoy" rel="author cc:attributionUrl" data-user-id="c79695e37339" data-collection-slug="towards-data-science" dir="auto">Daniel Godoy</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">Senior Data Scientist. Teacher @ Data Science Retreat</p></div></li></div><div class="col u-size6of12 u-xs-size12of12 u-xs-marginTop30"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardCollection"><div class="u-marginLeft20 u-floatRight"><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton" data-action="toggle-follow-collection" data-action-source="footer_card----7f60cf5620c9----------------------follow_footer" data-collection-id="7f60cf5620c9"><span class="button-label  js-buttonLabel">Follow</span></button></div><div class="u-tableCell "><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://towardsdatascience.com/?source=footer_card" title="Go to Towards Data Science" aria-label="Go to Towards Data Science" data-action-source="footer_card" data-collection-slug="towards-data-science"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_F0LADxTtsKOgmPa-_7iUEQ.jpeg" class="avatar-image u-size60x60" alt="Towards Data Science"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://towardsdatascience.com/?source=footer_card" rel="collection" data-action-source="footer_card" data-collection-slug="towards-data-science">Towards Data Science</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">Sharing concepts, ideas, and codes.</p><div class="buttonSet"></div></div></li></div></div></div><div class="js-postFooterPlacements" data-post-id="81fc5f8c4e8e" data-collection-id="7f60cf5620c9" data-scroll="native"><div class="streamItem streamItem--placementCardGrid js-streamItem"><div class="u-clearfix u-backgroundGrayLightest"><div class="row u-marginAuto u-maxWidth1032 u-paddingTop30 u-paddingBottom40"><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-width100pct u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackPostPresentation" data-post-id="a36cc186d570" data-source="placement_card_footer_grid---------0-41" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://towardsdatascience.com/data-scientists-are-thinkers-a36cc186d570?source=placement_card_footer_grid---------0-41" data-action-source="placement_card_footer_grid---------0-41"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-width100pct u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/800/240/1*lTH3uYF9zSyjUZ1WwLc4tg.png&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://towardsdatascience.com/data-scientists-are-thinkers-a36cc186d570?source=placement_card_footer_grid---------0-41" data-action-source="placement_card_footer_grid---------0-41"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from Towards Data Science</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Data Scientists Are Thinkers</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@conordewey3" data-action="show-user-card" data-action-value="ee856fa71ed0" data-action-type="hover" data-user-id="ee856fa71ed0" data-collection-slug="towards-data-science" dir="auto"><div class="u-relative u-inlineBlock u-flex0"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_1A18MmlW_Z04UdwIcXnMVg.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Conor Dewey"><div class="avatar-halo u-absolute u-textColorGreenNormal svgIcon" style="width: calc(100% + 10px); height: calc(100% + 10px); top:-5px; left:-5px"><svg viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M3.44615311,11.6601601 C6.57294867,5.47967718 12.9131553,1.5 19.9642857,1.5 C27.0154162,1.5 33.3556228,5.47967718 36.4824183,11.6601601 L37.3747245,11.2087295 C34.0793076,4.69494641 27.3961457,0.5 19.9642857,0.5 C12.5324257,0.5 5.84926381,4.69494641 2.55384689,11.2087295 L3.44615311,11.6601601 Z"></path><path d="M36.4824183,28.2564276 C33.3556228,34.4369105 27.0154162,38.4165876 19.9642857,38.4165876 C12.9131553,38.4165876 6.57294867,34.4369105 3.44615311,28.2564276 L2.55384689,28.7078582 C5.84926381,35.2216412 12.5324257,39.4165876 19.9642857,39.4165876 C27.3961457,39.4165876 34.0793076,35.2216412 37.3747245,28.7078582 L36.4824183,28.2564276 Z"></path></svg></div></div></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://towardsdatascience.com/@conordewey3?source=placement_card_footer_grid---------0-41" data-action="show-user-card" data-action-source="placement_card_footer_grid---------0-41" data-action-value="ee856fa71ed0" data-action-type="hover" data-user-id="ee856fa71ed0" data-collection-slug="towards-data-science" dir="auto">Conor Dewey</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://towardsdatascience.com/data-scientists-are-thinkers-a36cc186d570?source=placement_card_footer_grid---------0-41" data-action="open-post" data-action-value="https://towardsdatascience.com/data-scientists-are-thinkers-a36cc186d570?source=placement_card_footer_grid---------0-41" data-action-source="preview-listing"><time datetime="2019-05-12T02:42:34.811Z">May 12</time></a><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="4 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="a36cc186d570" data-is-label-padded="true" data-source="placement_card_footer_grid-----a36cc186d570----0-41----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="multivote" data-action-value="a36cc186d570" data-action-type="long-press" data-action-source="placement_card_footer_grid-----a36cc186d570----0-41----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="a36cc186d570">1K</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="add-to-bookmarks" data-action-value="a36cc186d570" data-action-source="placement_card_footer_grid-----a36cc186d570----0-41----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-width100pct u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackPostPresentation" data-post-id="a565b386f098" data-source="placement_card_footer_grid---------1-41" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://towardsdatascience.com/extreme-rare-event-classification-using-autoencoders-in-keras-a565b386f098?source=placement_card_footer_grid---------1-41" data-action-source="placement_card_footer_grid---------1-41"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-width100pct u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/800/240/1*S_OcBPkRTpKJo0iz5IaNbQ.png&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://towardsdatascience.com/extreme-rare-event-classification-using-autoencoders-in-keras-a565b386f098?source=placement_card_footer_grid---------1-41" data-action-source="placement_card_footer_grid---------1-41"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from Towards Data Science</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Extreme Rare Event Classification using Autoencoders in Keras</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@cran2367" data-action="show-user-card" data-action-value="1c9fae27a83" data-action-type="hover" data-user-id="1c9fae27a83" data-collection-slug="towards-data-science" dir="auto"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_RWPL3zHc1gcwdnl-RGgkZQ.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Chitta Ranjan"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://towardsdatascience.com/@cran2367?source=placement_card_footer_grid---------1-41" data-action="show-user-card" data-action-source="placement_card_footer_grid---------1-41" data-action-value="1c9fae27a83" data-action-type="hover" data-user-id="1c9fae27a83" data-collection-slug="towards-data-science" dir="auto">Chitta Ranjan</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://towardsdatascience.com/extreme-rare-event-classification-using-autoencoders-in-keras-a565b386f098?source=placement_card_footer_grid---------1-41" data-action="open-post" data-action-value="https://towardsdatascience.com/extreme-rare-event-classification-using-autoencoders-in-keras-a565b386f098?source=placement_card_footer_grid---------1-41" data-action-source="preview-listing"><time datetime="2019-05-03T19:10:19.306Z">May 4</time></a><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="9 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="a565b386f098" data-is-label-padded="true" data-source="placement_card_footer_grid-----a565b386f098----1-41----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="multivote" data-action-value="a565b386f098" data-action-type="long-press" data-action-source="placement_card_footer_grid-----a565b386f098----1-41----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="a565b386f098">2.4K</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="add-to-bookmarks" data-action-value="a565b386f098" data-action-source="placement_card_footer_grid-----a565b386f098----1-41----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-width100pct u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackPostPresentation" data-post-id="913c7d4118f" data-source="placement_card_footer_grid---------2-41" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://towardsdatascience.com/using-what-if-tool-to-investigate-machine-learning-models-913c7d4118f?source=placement_card_footer_grid---------2-41" data-action-source="placement_card_footer_grid---------2-41"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-width100pct u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/800/240/1*NBwHkeXoOu4fwA4dFdpyKw.jpeg&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://towardsdatascience.com/using-what-if-tool-to-investigate-machine-learning-models-913c7d4118f?source=placement_card_footer_grid---------2-41" data-action-source="placement_card_footer_grid---------2-41"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from Towards Data Science</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Using What-If Tool to investigate Machine Learning models.</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@parulnith" data-action="show-user-card" data-action-value="7053de462a28" data-action-type="hover" data-user-id="7053de462a28" data-collection-slug="towards-data-science" dir="auto"><div class="u-relative u-inlineBlock u-flex0"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_-ooorT2_5GQSfQoVFxJHXw.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Parul Pandey"><div class="avatar-halo u-absolute u-textColorGreenNormal svgIcon" style="width: calc(100% + 10px); height: calc(100% + 10px); top:-5px; left:-5px"><svg viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M3.44615311,11.6601601 C6.57294867,5.47967718 12.9131553,1.5 19.9642857,1.5 C27.0154162,1.5 33.3556228,5.47967718 36.4824183,11.6601601 L37.3747245,11.2087295 C34.0793076,4.69494641 27.3961457,0.5 19.9642857,0.5 C12.5324257,0.5 5.84926381,4.69494641 2.55384689,11.2087295 L3.44615311,11.6601601 Z"></path><path d="M36.4824183,28.2564276 C33.3556228,34.4369105 27.0154162,38.4165876 19.9642857,38.4165876 C12.9131553,38.4165876 6.57294867,34.4369105 3.44615311,28.2564276 L2.55384689,28.7078582 C5.84926381,35.2216412 12.5324257,39.4165876 19.9642857,39.4165876 C27.3961457,39.4165876 34.0793076,35.2216412 37.3747245,28.7078582 L36.4824183,28.2564276 Z"></path></svg></div></div></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://towardsdatascience.com/@parulnith?source=placement_card_footer_grid---------2-41" data-action="show-user-card" data-action-source="placement_card_footer_grid---------2-41" data-action-value="7053de462a28" data-action-type="hover" data-user-id="7053de462a28" data-collection-slug="towards-data-science" dir="auto">Parul Pandey</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://towardsdatascience.com/using-what-if-tool-to-investigate-machine-learning-models-913c7d4118f?source=placement_card_footer_grid---------2-41" data-action="open-post" data-action-value="https://towardsdatascience.com/using-what-if-tool-to-investigate-machine-learning-models-913c7d4118f?source=placement_card_footer_grid---------2-41" data-action-source="preview-listing"><time datetime="2019-05-03T13:40:31.603Z">May 3</time></a><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="9 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="913c7d4118f" data-is-label-padded="true" data-source="placement_card_footer_grid-----913c7d4118f----2-41----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="multivote" data-action-value="913c7d4118f" data-action-type="long-press" data-action-source="placement_card_footer_grid-----913c7d4118f----2-41----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="913c7d4118f">1.7K</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="add-to-bookmarks" data-action-value="913c7d4118f" data-action-source="placement_card_footer_grid-----913c7d4118f----2-41----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div></div></div></div></div><div class="u-padding0 u-clearfix u-backgroundGrayLightest u-print-hide supplementalPostContent js-responsesWrapper" data-action-scope="_actionscope_22"><div class="container u-maxWidth740"><div class="responsesStreamWrapper u-maxWidth640 js-responsesStreamWrapper"><div class="container responsesStream-title u-paddingTop15"><div class="row"><header class="heading"><div class="u-clearfix"><div class="heading-content u-floatLeft"><span class="heading-title heading-title--semibold">Responses</span></div></div></header></div></div><div class="responsesStream-editor cardChromeless u-marginBottom20 u-paddingLeft20 u-paddingRight20 js-responsesStreamEditor"><div class="inlineNewPostControl js-inlineNewPostControl" data-action-scope="_actionscope_28"><div class="inlineEditor is-collapsed is-postEditMode js-inlineEditor" data-action="focus-editor"><div class="u-paddingTop20 js-block js-inlineEditorContent"><div class="inlineEditor-header"><div class="inlineEditor-avatar u-paddingRight20"><div class="avatar u-inline"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/0_Mpgm7EXaTEICpUOi(1).jpg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Cheng-Jun Wang"></div></div><div class="inlineEditor-headerContent"><div class="inlineEditor-placeholder js-inlineEditorPrompt">Write a response…</div><div class="inlineEditor-author u-accentColor--textNormal">Cheng-Jun Wang</div></div></div></div></div></div></div><div class="responsesStream js-responsesStream"><div class="streamItem streamItem--conversation js-streamItem" data-action-scope="_actionscope_23"><div class="streamItemConversation"><div class="u-marginLeft20"><div class="streamItemConversation-divider"></div><header class="heading heading--light heading--simple"><div class="u-clearfix"><div class="heading-content u-floatLeft"><span class="heading-title">Conversation between <a class="link link--accent u-accentColor--textNormal u-baseColor--link" href="https://medium.com/@salilpradhan" data-action="show-user-card" data-action-value="6fb8049ba562" data-action-type="hover" data-user-id="6fb8049ba562" dir="auto">Salil Pradhan</a> and <a class="link link--accent u-accentColor--textNormal u-baseColor--link" href="https://medium.com/@dvgodoy" data-action="show-user-card" data-action-value="c79695e37339" data-action-type="hover" data-user-id="c79695e37339" dir="auto">Daniel Godoy</a>.</span></div></div></header></div><div class="streamItemConversation-inner cardChromeless"><div class="streamItemConversationItem streamItemConversationItem--preview"><div class="postArticle js-postArticle js-trackPostPresentation js-trackPostScrolls postArticle--short" data-post-id="8ff3a61c6df0" data-source="responses---------0---------------------" data-action-scope="_actionscope_24" data-scroll="native"><div class="u-clearfix u-marginBottom15 u-paddingTop5"><div class="postMetaInline u-floatLeft"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://medium.com/@salilpradhan" data-action="show-user-card" data-action-value="6fb8049ba562" data-action-type="hover" data-user-id="6fb8049ba562" dir="auto"><div class="u-relative u-inlineBlock u-flex0"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/0_NGYe8VAbVWqHZPVE.jpg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Salil Pradhan"><div class="avatar-halo u-absolute u-textColorGreenNormal svgIcon" style="width: calc(100% + 10px); height: calc(100% + 10px); top:-5px; left:-5px"><svg viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M3.44615311,11.6601601 C6.57294867,5.47967718 12.9131553,1.5 19.9642857,1.5 C27.0154162,1.5 33.3556228,5.47967718 36.4824183,11.6601601 L37.3747245,11.2087295 C34.0793076,4.69494641 27.3961457,0.5 19.9642857,0.5 C12.5324257,0.5 5.84926381,4.69494641 2.55384689,11.2087295 L3.44615311,11.6601601 Z"></path><path d="M36.4824183,28.2564276 C33.3556228,34.4369105 27.0154162,38.4165876 19.9642857,38.4165876 C12.9131553,38.4165876 6.57294867,34.4369105 3.44615311,28.2564276 L2.55384689,28.7078582 C5.84926381,35.2216412 12.5324257,39.4165876 19.9642857,39.4165876 C27.3961457,39.4165876 34.0793076,35.2216412 37.3747245,28.7078582 L36.4824183,28.2564276 Z"></path></svg></div></div></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--accent u-accentColor--textNormal u-accentColor--textDarken" href="https://medium.com/@salilpradhan?source=responses---------0---------------------" data-action="show-user-card" data-action-source="responses---------0---------------------" data-action-value="6fb8049ba562" data-action-type="hover" data-user-id="6fb8049ba562" dir="auto">Salil Pradhan</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://medium.com/@salilpradhan/probably-the-best-tutorial-on-pytorch-i-have-seen-will-you-do-a-part-2-8ff3a61c6df0?source=responses---------0---------------------" data-action="open-post" data-action-value="https://medium.com/@salilpradhan/probably-the-best-tutorial-on-pytorch-i-have-seen-will-you-do-a-part-2-8ff3a61c6df0?source=responses---------0---------------------" data-action-source="preview-listing"><time datetime="2019-05-09T16:42:52.126Z">May 10</time></a></div></div></div></div></div><div><a class="" href="https://medium.com/@salilpradhan/probably-the-best-tutorial-on-pytorch-i-have-seen-will-you-do-a-part-2-8ff3a61c6df0?source=responses---------0---------------------"><div class="postArticle-content js-postField"><section class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="d582" id="d582" class="graf graf--p graf--leading graf--trailing">Probably the best tutorial on pytorch I have seen. Will you do a part 2?</p></div></div></section></div></a></div><div class="u-clearfix u-paddingTop10"><div class="u-floatLeft"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="8ff3a61c6df0" data-is-flush-left="true" data-source="listing-----8ff3a61c6df0---------------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="multivote" data-action-value="8ff3a61c6df0" data-action-type="long-press" data-action-source="listing-----8ff3a61c6df0---------------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px is-flushLeft"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px is-flushLeft"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents" data-action="show-recommends" data-action-value="8ff3a61c6df0">5</button></span></div></div><div class="buttonSet u-floatRight"><a class="button button--chromeless u-baseColor--buttonNormal" href="https://medium.com/@salilpradhan/probably-the-best-tutorial-on-pytorch-i-have-seen-will-you-do-a-part-2-8ff3a61c6df0?source=responses---------0---------------------#--responses" data-action-source="responses---------0---------------------">1 response</a><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="add-to-bookmarks" data-action-value="8ff3a61c6df0" data-action-source="listing-----8ff3a61c6df0---------------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button><button class="button button--chromeless is-touchIconBlackPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon js-postActionsButton" data-action="post-actions" data-action-value="8ff3a61c6df0"><span class="svgIcon svgIcon--arrowDown svgIcon--19px is-flushRight"><svg class="svgIcon-use" width="19" height="19"><path d="M3.9 6.772l5.205 5.756.427.472.427-.472 5.155-5.698-.854-.772-4.728 5.254L4.753 6z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div><div class="streamItemConversationItem streamItemConversationItem--preview"><div class="postArticle js-postArticle js-trackPostPresentation js-trackPostScrolls postArticle--short" data-post-id="e608b019d36b" data-source="responses---------0---------------------" data-action-scope="_actionscope_25" data-scroll="native"><div class="u-clearfix u-marginBottom15 u-paddingTop5"><div class="postMetaInline u-floatLeft"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://medium.com/@dvgodoy" data-action="show-user-card" data-action-value="c79695e37339" data-action-type="hover" data-user-id="c79695e37339" dir="auto"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/1_7kL4DitERABkDkP-caSAZA(2).png" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Daniel Godoy"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--accent u-accentColor--textNormal u-accentColor--textDarken" href="https://medium.com/@dvgodoy?source=responses---------0---------------------" data-action="show-user-card" data-action-source="responses---------0---------------------" data-action-value="c79695e37339" data-action-type="hover" data-user-id="c79695e37339" dir="auto">Daniel Godoy</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://medium.com/@dvgodoy/thank-you-very-much-e608b019d36b?source=responses---------0---------------------" data-action="open-post" data-action-value="https://medium.com/@dvgodoy/thank-you-very-much-e608b019d36b?source=responses---------0---------------------" data-action-source="preview-listing"><time datetime="2019-05-11T09:45:20.680Z">May 11</time></a></div></div></div></div></div><div><a class="" href="https://medium.com/@dvgodoy/thank-you-very-much-e608b019d36b?source=responses---------0---------------------"><div class="postArticle-content js-postField"><section class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="2e4b" id="2e4b" class="graf graf--p graf--leading">Thank you very much!</p><p name="b0c9" id="b0c9" class="graf graf--p graf-after--p graf--trailing">Yes, I plan on writing another post to tackle new topic/concepts like: sampler, collate function, transformations for images, learning rate finder and more&nbsp;:-)</p></div></div></section></div></a></div><div class="u-clearfix u-paddingTop10"><div class="u-floatLeft"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="e608b019d36b" data-is-flush-left="true" data-source="listing-----e608b019d36b---------------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="multivote" data-action-value="e608b019d36b" data-action-type="long-press" data-action-source="listing-----e608b019d36b---------------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px is-flushLeft"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px is-flushLeft"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents" data-action="show-recommends" data-action-value="e608b019d36b">7</button></span></div></div><div class="buttonSet u-floatRight"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="add-to-bookmarks" data-action-value="e608b019d36b" data-action-source="listing-----e608b019d36b---------------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button><button class="button button--chromeless is-touchIconBlackPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon js-postActionsButton" data-action="post-actions" data-action-value="e608b019d36b"><span class="svgIcon svgIcon--arrowDown svgIcon--19px is-flushRight"><svg class="svgIcon-use" width="19" height="19"><path d="M3.9 6.772l5.205 5.756.427.472.427-.472 5.155-5.698-.854-.772-4.728 5.254L4.753 6z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div></div><div class="streamItem streamItem--postPreview js-streamItem" data-action-scope="_actionscope_26"><div class="cardChromeless u-marginTop20 u-paddingTop10 u-paddingBottom15 u-paddingLeft20 u-paddingRight20"><div class="postArticle postArticle--short js-postArticle js-trackPostPresentation js-trackPostScrolls" data-post-id="36d5a7ad1394" data-source="responses---------1-31--------------------" data-action-scope="_actionscope_27" data-scroll="native"><div class="u-marginBottom10"><div class="postMetaInline">Applause from <a class="link link--darken u-accentColor--textDarken u-baseColor--link" href="https://medium.com/@dvgodoy" data-action="show-user-card" data-action-value="c79695e37339" data-action-type="hover" data-user-id="c79695e37339" dir="auto">Daniel Godoy</a> (author)</div></div><div class="u-clearfix u-marginBottom15 u-paddingTop5"><div class="postMetaInline u-floatLeft"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://medium.com/@filipemflc" data-action="show-user-card" data-action-value="a286885c64af" data-action-type="hover" data-user-id="a286885c64af" dir="auto"><img src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/0_bTMq8fo4LJGB2E7G.jpg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Filipe Conceição"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--accent u-accentColor--textNormal u-accentColor--textDarken" href="https://medium.com/@filipemflc?source=responses---------1-31--------------------" data-action="show-user-card" data-action-source="responses---------1-31--------------------" data-action-value="a286885c64af" data-action-type="hover" data-user-id="a286885c64af" dir="auto">Filipe Conceição</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://medium.com/@filipemflc/excellent-tutorial-just-what-i-was-looking-for-36d5a7ad1394?source=responses---------1-31--------------------" data-action="open-post" data-action-value="https://medium.com/@filipemflc/excellent-tutorial-just-what-i-was-looking-for-36d5a7ad1394?source=responses---------1-31--------------------" data-action-source="preview-listing"><time datetime="2019-05-07T16:59:00.822Z">May 8</time></a></div></div></div></div></div><div><a class="" href="https://medium.com/@filipemflc/excellent-tutorial-just-what-i-was-looking-for-36d5a7ad1394?source=responses---------1-31--------------------" data-action-source="responses---------1-31--------------------"><div class="postArticle-content js-postField"><section class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="5634" id="5634" class="graf graf--p graf--leading graf--trailing">Excellent tutorial! Just what I was looking for.</p></div></div></section></div></a></div><div class="u-clearfix u-paddingTop10"><div class="u-floatLeft"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="36d5a7ad1394" data-is-flush-left="true" data-source="listing-----36d5a7ad1394---------------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="multivote" data-action-value="36d5a7ad1394" data-action-type="long-press" data-action-source="listing-----36d5a7ad1394---------------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px is-flushLeft"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px is-flushLeft"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents" data-action="show-recommends" data-action-value="36d5a7ad1394">5</button></span></div></div><div class="buttonSet u-floatRight"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="add-to-bookmarks" data-action-value="36d5a7ad1394" data-action-source="listing-----36d5a7ad1394---------------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button><button class="button button--chromeless is-touchIconBlackPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon js-postActionsButton" data-action="post-actions" data-action-value="36d5a7ad1394"><span class="svgIcon svgIcon--arrowDown svgIcon--19px is-flushRight"><svg class="svgIcon-use" width="19" height="19"><path d="M3.9 6.772l5.205 5.756.427.472.427-.472 5.155-5.698-.854-.772-4.728 5.254L4.753 6z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div></div></div><div class="container u-hide js-showOtherResponses"><div class="row"><button class="button button--primary button--withChrome u-accentColor--buttonNormal responsesStream-showOtherResponses cardChromeless u-width100pct u-marginVertical20 u-heightAuto" data-action="show-other-responses">Show all responses</button></div></div><div class="responsesStream js-responsesStreamOther"></div></div></div></div><div class="supplementalPostContent js-heroPromo"></div></footer></article></main><aside class="u-marginAuto u-maxWidth1032 js-postLeftSidebar"><div class="u-foreground u-top0 u-sm-hide js-postShareWidget u-fixed u-transition--fadeOut300" data-scroll="fixed" style="transform: translateY(150px);"><div class="u-breakWord u-md-hide u-width131"><div class="u-width131 collection-title u-fontWeightBold u-fontSize18 u-lineHeightTight"><a href="https://towardsdatascience.com/?source=logo-3751a3493996">Towards Data Science</a></div><div class="u-width131 u-multiline-clamp u-textColorNormal u-fontSize14 u-lineHeightTight u-paddingTop3">Sharing concepts, ideas, and codes.</div><div class="u-paddingTop15 u-paddingBottom30 u-borderBottomLight u-marginBottom30"><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton" data-action="toggle-follow-collection" data-action-source="post_sidebar----7f60cf5620c9----------------------post_sidebar" data-collection-id="7f60cf5620c9"><span class="button-label  js-buttonLabel">Follow</span></button></div></div><ul><li class="u-marginVertical10"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="81fc5f8c4e8e" data-is-icon-29px="true" data-has-recommend-list="true" data-source="post_share_widget-----81fc5f8c4e8e---------------------clap_sidebar"><div class="u-relative u-foreground"><button class="button button--primary button--large button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="multivote" data-action-value="81fc5f8c4e8e" data-action-type="long-press" data-action-source="post_share_widget-----81fc5f8c4e8e---------------------clap_sidebar" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><g fill-rule="evenodd"><path d="M13.739 1l.761 2.966L15.261 1z"></path><path d="M16.815 4.776l1.84-2.551-1.43-.471z"></path><path d="M10.378 2.224l1.84 2.551-.408-3.022z"></path><path d="M22.382 22.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L6.11 15.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L8.43 9.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L20.628 15c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM12.99 6.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><g fill-rule="evenodd"><path d="M13.738 1l.762 2.966L15.262 1z"></path><path d="M18.634 2.224l-1.432-.47-.408 3.022z"></path><path d="M11.79 1.754l-1.431.47 1.84 2.552z"></path><path d="M24.472 14.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M14.58 10.887c-.156-.83.096-1.569.692-2.142L12.78 6.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M17.812 10.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L9.2 7.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L7.046 9.54 5.802 8.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394l1.241 1.241 4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L4.89 11.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C21.74 20.8 22.271 18 20.62 14.982l-2.809-4.942z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton" data-action="show-recommends" data-action-value="81fc5f8c4e8e">250</button></span></div></li><li class="u-marginVertical10 u-marginLeft3"><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="add-to-bookmarks" data-action-value="81fc5f8c4e8e" data-action-source="post_share_widget-----81fc5f8c4e8e---------------------bookmark_sidebar"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"></path></svg></span></span></button></li><li class="u-marginVertical10 u-marginLeft3"><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless" href="https://medium.com/p/81fc5f8c4e8e/share/twitter" title="Share on Twitter" aria-label="Share on Twitter" target="_blank" data-action-source="post_share_widget"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M22.053 7.54a4.474 4.474 0 0 0-3.31-1.455 4.526 4.526 0 0 0-4.526 4.524c0 .35.04.7.082 1.05a12.9 12.9 0 0 1-9.3-4.77c-.39.69-.61 1.46-.65 2.26.03 1.6.83 2.99 2.02 3.79-.72-.02-1.41-.22-2.02-.57-.01.02-.01.04 0 .08-.01 2.17 1.55 4 3.63 4.44-.39.08-.79.13-1.21.16-.28-.03-.57-.05-.81-.08.54 1.77 2.21 3.08 4.2 3.15a9.564 9.564 0 0 1-5.66 1.94c-.34-.03-.7-.06-1.05-.08 2 1.27 4.38 2.02 6.94 2.02 8.31 0 12.86-6.9 12.84-12.85.02-.24.01-.43 0-.65.89-.62 1.65-1.42 2.26-2.34-.82.38-1.69.62-2.59.72a4.37 4.37 0 0 0 1.94-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></span></span></a></li><li class="u-marginVertical10 u-marginLeft3"><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless" href="https://medium.com/p/81fc5f8c4e8e/share/facebook" title="Share on Facebook" aria-label="Share on Facebook" target="_blank" data-action-source="post_share_widget"><span class="button-defaultState"><span class="svgIcon svgIcon--facebookSquare svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M23.209 5H5.792A.792.792 0 0 0 5 5.791V23.21c0 .437.354.791.792.791h9.303v-7.125H12.72v-2.968h2.375v-2.375c0-2.455 1.553-3.662 3.741-3.662 1.049 0 1.95.078 2.213.112v2.565h-1.517c-1.192 0-1.469.567-1.469 1.397v1.963h2.969l-.594 2.968h-2.375L18.11 24h5.099a.791.791 0 0 0 .791-.791V5.79a.791.791 0 0 0-.791-.79"></path></svg></span></span></a></li></ul></div></aside><style class="js-collectionStyle">
.u-accentColor--borderLight {border-color: #668AAA !important;}
.u-accentColor--borderNormal {border-color: #668AAA !important;}
.u-accentColor--borderDark {border-color: #5A7690 !important;}
.u-accentColor--iconLight .svgIcon,.u-accentColor--iconLight.svgIcon {fill: #668AAA !important;}
.u-accentColor--iconNormal .svgIcon,.u-accentColor--iconNormal.svgIcon {fill: #668AAA !important;}
.u-accentColor--iconDark .svgIcon,.u-accentColor--iconDark.svgIcon {fill: #5A7690 !important;}
.u-accentColor--textNormal {color: #5A7690 !important;}
.u-accentColor--hoverTextNormal:hover {color: #5A7690 !important;}
.u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #546C83 !important;}
.u-accentColor--textDark {color: #546C83 !important;}
.u-accentColor--backgroundLight {background-color: #668AAA !important;}
.u-accentColor--backgroundNormal {background-color: #668AAA !important;}
.u-accentColor--backgroundDark {background-color: #5A7690 !important;}
.u-accentColor--buttonDark {border-color: #5A7690 !important; color: #546C83 !important;}
.u-accentColor--buttonDark:hover {border-color: #546C83 !important;}
.u-accentColor--buttonDark .icon:before,.u-accentColor--buttonDark .svgIcon{color: #5A7690 !important; fill: #5A7690 !important;}
.u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #668AAA !important; color: #5A7690 !important;}
.u-accentColor--buttonNormal:hover {border-color: #5A7690 !important;}
.u-accentColor--buttonNormal .icon:before,.u-accentColor--buttonNormal .svgIcon{color: #668AAA !important; fill: #668AAA !important;}
.u-accentColor--buttonNormal.button--filled .icon:before,.u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonDark.button--filled,.u-accentColor--buttonDark.button--withChrome.is-active,.u-accentColor--fillWhenActive.is-active {background-color: #5A7690 !important; border-color: #5A7690 !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #668AAA !important; border-color: #668AAA !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.postArticle.is-withAccentColors .markup--user,.postArticle.is-withAccentColors .markup--query {color: #5A7690 !important;}.u-tintBgColor {background-color: rgba(53, 88, 118, 1) !important;}.u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(53, 88, 118, 1) 0%, rgba(53, 88, 118, 0) 100%) !important;}.u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(53, 88, 118, 0) 0%, rgba(53, 88, 118, 1) 100%) !important;}
.u-tintSpectrum .u-baseColor--borderLight {border-color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--borderNormal {border-color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--borderDark {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--iconLight .svgIcon,.u-tintSpectrum .u-baseColor--iconLight.svgIcon {fill: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--iconNormal .svgIcon,.u-tintSpectrum .u-baseColor--iconNormal.svgIcon {fill: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--iconDark .svgIcon,.u-tintSpectrum .u-baseColor--iconDark.svgIcon {fill: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--textNormal {color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--textDark {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--textDarker {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--backgroundLight {background-color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--backgroundNormal {background-color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--backgroundDark {background-color: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--buttonLight {border-color: #9FB3C6 !important; color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--buttonLight:hover {border-color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--buttonLight .icon:before,.u-tintSpectrum .u-baseColor--buttonLight .svgIcon {color: #9FB3C6 !important; fill: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--buttonDark {border-color: #E9F1FA !important; color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--buttonDark:hover {border-color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--buttonDark .icon:before,.u-tintSpectrum .u-baseColor--buttonDark .svgIcon {color: #E9F1FA !important; fill: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--buttonNormal {border-color: #C5D2E1 !important; color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--buttonNormal:hover {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--buttonNormal .icon:before,.u-tintSpectrum .u-baseColor--buttonNormal .svgIcon {color: #C5D2E1 !important; fill: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--buttonDark.button--filled,.u-tintSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: #E9F1FA !important; border-color: #E9F1FA !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-baseColor--buttonNormal.button--filled,.u-tintSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: #C5D2E1 !important; border-color: #C5D2E1 !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-baseColor--link {color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--darken:hover,.u-tintSpectrum .u-baseColor--link.link--darken:focus,.u-tintSpectrum .u-baseColor--link.link--darken:active {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--dark {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:active {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--darker {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: #9FB3C6;}
.u-tintSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: #9FB3C6;}
.u-tintSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: #9FB3C6;}
.u-tintSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: #FBFFFF !important;}
.u-tintSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: #FBFFFF !important;}
.u-tintSpectrum  .ui-h1,.u-tintSpectrum  .ui-h2,.u-tintSpectrum  .ui-h3,.u-tintSpectrum  .ui-h4,.u-tintSpectrum  .ui-brand1,.u-tintSpectrum  .ui-brand2,.u-tintSpectrum  .ui-captionStrong {color: #FBFFFF !important; fill: #FBFFFF !important;}
.u-tintSpectrum  .ui-body,.u-tintSpectrum  .ui-caps {color: #FBFFFF !important; fill: #FBFFFF !important;}
.u-tintSpectrum  .ui-summary,.u-tintSpectrum  .ui-caption {color: #9FB3C6 !important; fill: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--borderLight {border-color: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--borderNormal {border-color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--borderDark {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--iconLight .svgIcon,.u-tintSpectrum .u-accentColor--iconLight.svgIcon {fill: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--iconNormal .svgIcon,.u-tintSpectrum .u-accentColor--iconNormal.svgIcon {fill: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--iconDark .svgIcon,.u-tintSpectrum .u-accentColor--iconDark.svgIcon {fill: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--textNormal {color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--hoverTextNormal:hover {color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--textDark {color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--backgroundLight {background-color: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--backgroundNormal {background-color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--backgroundDark {background-color: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--buttonDark {border-color: #E9F1FA !important; color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--buttonDark:hover {border-color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--buttonDark .icon:before,.u-tintSpectrum .u-accentColor--buttonDark .svgIcon{color: #E9F1FA !important; fill: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #C5D2E1 !important; color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--buttonNormal:hover {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--buttonNormal .icon:before,.u-tintSpectrum .u-accentColor--buttonNormal .svgIcon{color: #C5D2E1 !important; fill: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-tintSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-accentColor--buttonDark.button--filled,.u-tintSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-tintSpectrum .u-accentColor--fillWhenActive.is-active {background-color: #E9F1FA !important; border-color: #E9F1FA !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-tintSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #C5D2E1 !important; border-color: #C5D2E1 !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .postArticle.is-withAccentColors .markup--user,.u-tintSpectrum .postArticle.is-withAccentColors .markup--query {color: #C5D2E1 !important;}
.u-accentColor--highlightFaint {background-color: rgba(233, 242, 253, 1) !important;}
.u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(200, 228, 255, 1) !important;}
.postArticle.is-withAccentColors .markup--quote.is-other {background-color: rgba(233, 242, 253, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(233, 242, 253, 1), rgba(233, 242, 253, 1));}
.postArticle.is-withAccentColors .markup--quote.is-me {background-color: rgba(215, 235, 254, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(215, 235, 254, 1), rgba(215, 235, 254, 1));}
.postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: rgba(200, 228, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}
.postArticle.is-withAccentColors .markup--quote.is-selected {background-color: rgba(200, 228, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}
.postArticle.is-withAccentColors .markup--highlight {background-color: rgba(200, 228, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}.u-baseColor--iconNormal.avatar-halo {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}</style><style class="js-collectionStyleConstant">.u-imageBgColor {background-color: rgba(0, 0, 0, 0.24705882352941178);}
.u-imageSpectrum .u-baseColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconLight .svgIcon,.u-imageSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--iconNormal .svgIcon,.u-imageSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconDark .svgIcon,.u-imageSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDarker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important; color: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--buttonLight .icon:before,.u-imageSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark .icon:before,.u-imageSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal .icon:before,.u-imageSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonDark.button--filled,.u-imageSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal.button--filled,.u-imageSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--link {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-h1,.u-imageSpectrum  .ui-h2,.u-imageSpectrum  .ui-h3,.u-imageSpectrum  .ui-h4,.u-imageSpectrum  .ui-brand1,.u-imageSpectrum  .ui-brand2,.u-imageSpectrum  .ui-captionStrong {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-body,.u-imageSpectrum  .ui-caps {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-summary,.u-imageSpectrum  .ui-caption {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconLight .svgIcon,.u-imageSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--iconNormal .svgIcon,.u-imageSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconDark .svgIcon,.u-imageSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark .icon:before,.u-imageSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonDark.button--filled,.u-imageSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-imageSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-imageSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .postArticle.is-withAccentColors .markup--user,.u-imageSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--highlightFaint {background-color: rgba(255, 255, 255, 0.2) !important;}
.u-imageSpectrum .u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(255, 255, 255, 0.6) !important;}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: rgba(255, 255, 255, 0.2) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 0.2));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: rgba(255, 255, 255, 0.4) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.4), rgba(255, 255, 255, 0.4));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}.u-resetSpectrum .u-tintBgColor {background-color: rgba(255, 255, 255, 1) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(255, 255, 255, 1) 0%, rgba(255, 255, 255, 0) 100%) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(255, 255, 255, 0) 0%, rgba(255, 255, 255, 1) 100%) !important;}
.u-resetSpectrum .u-baseColor--borderLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderDark {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--iconLight .svgIcon,.u-resetSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconNormal .svgIcon,.u-resetSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconDark .svgIcon,.u-resetSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textNormal {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDarker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--backgroundLight {background-color: rgba(0, 0, 0, 0.09803921568627451) !important;}
.u-resetSpectrum .u-baseColor--backgroundNormal {background-color: rgba(0, 0, 0, 0.2) !important;}
.u-resetSpectrum .u-baseColor--backgroundDark {background-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight .icon:before,.u-resetSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark {border-color: rgba(0, 0, 0, 0.6) !important; color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--buttonDark .icon:before,.u-resetSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important; color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal .icon:before,.u-resetSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(0, 0, 0, 0.4980392156862745) !important; fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark.button--filled,.u-resetSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2980392156862745) !important; border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal.button--filled,.u-resetSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2) !important; border-color: rgba(0, 0, 0, 0.2) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--link {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--darken:active {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--link.link--darker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-h1,.u-resetSpectrum  .ui-h2,.u-resetSpectrum  .ui-h3,.u-resetSpectrum  .ui-h4,.u-resetSpectrum  .ui-brand1,.u-resetSpectrum  .ui-brand2,.u-resetSpectrum  .ui-captionStrong {color: rgba(0, 0, 0, 0.8) !important; fill: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum  .ui-body,.u-resetSpectrum  .ui-caps {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-summary,.u-resetSpectrum  .ui-caption {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-accentColor--borderLight {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderNormal {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderDark {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconLight .svgIcon,.u-resetSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--iconNormal .svgIcon,.u-resetSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconDark .svgIcon,.u-resetSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textDark {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundLight {background-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundNormal {background-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundDark {background-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark {border-color: rgba(0, 171, 107, 1) !important; color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark .icon:before,.u-resetSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(28, 153, 99, 1) !important; fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(2, 184, 117, 1) !important; color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(0, 171, 107, 1) !important; fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark.button--filled,.u-resetSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-resetSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(28, 153, 99, 1) !important; border-color: rgba(28, 153, 99, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-resetSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(0, 171, 107, 1) !important; border-color: rgba(0, 171, 107, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .postArticle.is-withAccentColors .markup--user,.u-resetSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(0, 171, 107, 1) !important;}</style><div class="highlightMenu" data-action-scope="_actionscope_20"><div class="highlightMenu-inner"><div class="buttonSet"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu u-accentColor--highlightStrong js-highlightMenuQuoteButton" data-action="quote" data-action-source="quote_menu--------------------------highlight_text" data-skip-onboarding="true"><span class="svgIcon svgIcon--highlighter svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M13.7 15.964l5.204-9.387-4.726-2.62-5.204 9.387 4.726 2.62zm-.493.885l-1.313 2.37-1.252.54-.702 1.263-3.796-.865 1.228-2.213-.202-1.35 1.314-2.37 4.722 2.616z" fill-rule="evenodd"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="quote-respond" data-action-source="quote_menu--------------------------respond_text" data-skip-onboarding="true"><span class="svgIcon svgIcon--responseFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19.074 21.117c-1.244 0-2.432-.37-3.532-1.096a7.792 7.792 0 0 1-.703-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.662 0 8.457 3.5 8.457 7.803 0 2.058-.85 3.984-2.403 5.448.023.17.06.35.118.55.192.69.537 1.38 1.026 2.04.15.21.172.48.058.7a.686.686 0 0 1-.613.38h-.03z" fill-rule="evenodd"></path></svg></span></button><a class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--chromeless button--highlightMenu js-highlightMenuTwitterShare" href="https://medium.com/p/81fc5f8c4e8e/share/twitter" title="Share on Twitter" aria-label="Share on Twitter" target="_blank" data-action="twitter"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M21.725 5.338c-.744.47-1.605.804-2.513 1.006a3.978 3.978 0 0 0-2.942-1.293c-2.22 0-4.02 1.81-4.02 4.02 0 .32.034.63.07.94-3.31-.18-6.27-1.78-8.255-4.23a4.544 4.544 0 0 0-.574 2.01c.04 1.43.74 2.66 1.8 3.38-.63-.01-1.25-.19-1.79-.5v.08c0 1.93 1.38 3.56 3.23 3.95-.34.07-.7.12-1.07.14-.25-.02-.5-.04-.72-.07.49 1.58 1.97 2.74 3.74 2.8a8.49 8.49 0 0 1-5.02 1.72c-.3-.03-.62-.04-.93-.07A11.447 11.447 0 0 0 8.88 21c7.386 0 11.43-6.13 11.414-11.414.015-.21.01-.38 0-.578a7.604 7.604 0 0 0 2.01-2.08 7.27 7.27 0 0 1-2.297.645 3.856 3.856 0 0 0 1.72-2.23"></path></svg></span></span></a><div class="buttonSet-separator"></div><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="highlight" data-action-source="quote_menu--------------------------privatenote_text" data-skip-onboarding="true"><span class="svgIcon svgIcon--privatenoteFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M17.662 4.552H7.346A4.36 4.36 0 0 0 3 8.898v5.685c0 2.168 1.614 3.962 3.697 4.28v2.77c0 .303.35.476.59.29l3.904-2.994h6.48c2.39 0 4.35-1.96 4.35-4.35V8.9c0-2.39-1.95-4.346-4.34-4.346zM16 14.31a.99.99 0 0 1-1.003.99h-4.994C9.45 15.3 9 14.85 9 14.31v-3.02a.99.99 0 0 1 1-.99v-.782a2.5 2.5 0 0 1 2.5-2.51c1.38 0 2.5 1.13 2.5 2.51v.782c.552.002 1 .452 1 .99v3.02z"></path><path d="M14 9.81c0-.832-.674-1.68-1.5-1.68-.833 0-1.5.84-1.5 1.68v.49h3v-.49z"></path></g></svg></span></button></div></div><div class="highlightMenu-arrowClip"><span class="highlightMenu-arrow"></span></div></div></div></div></div><div class="loadingBar"></div><script>// <![CDATA[
window["obvInit"] = function (opt_embedded) {window["obvInit"]["embedded"] = opt_embedded; window["obvInit"]["ready"] = true;}
// ]]></script><script>// <![CDATA[
var GLOBALS = {"audioUrl":"https://d1fcbxp97j4nb2.cloudfront.net","baseUrl":"https://towardsdatascience.com","buildLabel":"37560-4dd4c62","currentUser":{"userId":"3751a3493996","username":"wangchj04","name":"Cheng-Jun Wang","email":"wangchj04@gmail.com","imageId":"0*Mpgm7EXaTEICpUOi.jpg","createdAt":1557477875037,"isVerified":true,"subscriberEmail":"","onboardingStatus":1,"googleAccountId":"108374965119894760200","googleEmail":"wangchj04@gmail.com","hasPastMemberships":false,"isEnrolledInHightower":false,"isEligibleForHightower":true,"hightowerLastLockedAt":0,"isWriterProgramEnrolled":true,"isWriterProgramInvited":true,"isWriterProgramOptedOut":false,"writerProgramVersion":5,"writerProgramEnrolledAt":1557477875037,"friendLinkOnboarding":0,"hasAdditionalUnlocks":false,"hasApiAccess":false,"isQuarantined":false,"writerProgramDistributionSettingOptedIn":true},"currentUserHasUnverifiedEmail":false,"isAuthenticated":true,"isCurrentUserVerified":true,"language":"zh-tw","miroUrl":"https://cdn-images-1.medium.com","moduleUrls":{"base":"https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.3zcQTeDFlV3HhQwoX8g-gg.js","common-async":"https://cdn-static-1.medium.com/_/fp/gen-js/main-common-async.bundle.AHOyO-i_kQOPVtd1D3V-Ag.js","hightower":"https://cdn-static-1.medium.com/_/fp/gen-js/main-hightower.bundle.unySA-1xBOKtS7EYNPGUSw.js","home-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-home-screens.bundle.4MkH9obDeQktpQXqwR8NzQ.js","misc-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-misc-screens.bundle.uSIdxZUQ14HRMlktssa7EQ.js","notes":"https://cdn-static-1.medium.com/_/fp/gen-js/main-notes.bundle.A5--rZtpdvaRMBwFRU9JAg.js","payments":"https://cdn-static-1.medium.com/_/fp/gen-js/main-payments.bundle.ZmtO7krtCnsilczCpHy8Rg.js","posters":"https://cdn-static-1.medium.com/_/fp/gen-js/main-posters.bundle.BMyWqVXPJKeA2XORrrvWoQ.js","power-readers":"https://cdn-static-1.medium.com/_/fp/gen-js/main-power-readers.bundle.ixLunhRsNrqwZtbZj7HnIQ.js","pubs":"https://cdn-static-1.medium.com/_/fp/gen-js/main-pubs.bundle.MwM21c8le0O7wmd1Uc7Mzg.js","stats":"https://cdn-static-1.medium.com/_/fp/gen-js/main-stats.bundle.kNiFRcL6W-81yiCd8v8Elw.js"},"previewConfig":{"weightThreshold":1,"weightImageParagraph":0.51,"weightIframeParagraph":0.8,"weightTextParagraph":0.08,"weightEmptyParagraph":0,"weightP":0.003,"weightH":0.005,"weightBq":0.003,"minPTextLength":60,"truncateBoundaryChars":20,"detectTitle":true,"detectTitleLevThreshold":0.15},"productName":"Medium","supportsEdit":true,"termsUrl":"//medium.com/policy/9db0094a1e0f","textshotHost":"textshot.medium.com","transactionId":"1558100579946:af4739aa941","useragent":{"browser":"chrome","family":"chrome","os":"mac","version":73,"supportsDesktopEdit":true,"supportsInteract":true,"supportsView":true,"isMobile":false,"isTablet":false,"isNative":false,"supportsFileAPI":true,"isTier1":true,"clientVersion":"","unknownParagraphsBad":false,"clientChannel":"","supportsRealScrollEvents":true,"supportsVhUnits":true,"ruinsViewportSections":false,"supportsHtml5Video":true,"supportsMagicUnderlines":true,"isWebView":false,"isFacebookWebView":false,"supportsProgressiveMedia":true,"supportsPromotedPosts":true,"isBot":false,"isNativeIphone":false,"supportsCssVariables":true,"supportsVideoSections":true,"emojiSupportLevel":1,"isSearchBot":false,"isSyndicationBot":false,"isNativeAndroid":false,"isNativeIos":false,"supportsScrollableMetabar":true},"variants":{"allow_access":true,"allow_signup":true,"allow_test_auth":"disallow","signin_services":"twitter,facebook,google,email,google-fastidv,google-one-tap","signup_services":"twitter,facebook,google,email,google-fastidv,google-one-tap","google_sign_in_android":true,"reengagement_notification_duration":3,"browsable_stream_config_bucket":"curated-topics","enable_dedicated_series_tab_api_ios":true,"enable_post_import":true,"available_monthly_plan":"60e220181034","available_annual_plan":"2c754bcc2995","disable_ios_resume_reading_toast":true,"is_not_medium_subscriber":true,"glyph_font_set":"m2","enable_branding":true,"enable_branding_fonts":true,"max_premium_content_per_user_under_metering":3,"enable_automated_mission_control_triggers":true,"enable_lite_profile":true,"enable_marketing_emails":true,"enable_topic_lifecycle_email":true,"enable_parsely":true,"enable_branch_io":true,"enable_ios_post_stats":true,"enable_lite_topics":true,"enable_lite_stories":true,"redis_read_write_splitting":true,"enable_tipalti_onboarding":true,"enable_international_tax_withholding_documentation":true,"enable_annual_renewal_reminder_email":true,"enable_janky_spam_rules":"users,posts","enable_new_collaborative_filtering_data":true,"android_rating_prompt_stories_read_threshold":2,"stripe_v3":true,"enable_google_one_tap":true,"enable_email_sign_in_captcha":true,"enable_rito_with_viewer_query":true,"enable_rito_with_flag_query":true,"enable_rito_post_handler":true,"enable_rito_sequence_post_recirc_query":true,"enable_rito_post_recirc_query":true,"enable_rito_topic_handler":true,"enable_rito_stats_post_handler":true,"enable_rito_stats_post_chart":true,"enable_rito_lifetime_earnings_tooltip":true,"enable_rito_stats_post_referrers_container":true,"enable_rito_post_feature_mutation":true,"enable_rito_post_unfeature_mutation":true,"enable_rito_quote_delete_mutation":true,"enable_rito_user_block_mutation":true,"enable_rito_user_unblock_mutation":true,"enable_rito_report_user_link":true,"enable_rito_bookmark_post_default":true,"enable_rito_unbookmark_post_default":true,"enable_rito_archive_post_default":true,"enable_rito_unarchive_post_default":true,"enable_rito_clap":true,"enable_rito_subscribe_series":true,"enable_rito_unsubscribe_series":true,"enable_rito_follow_topic":true,"enable_rito_unfollow_topic":true,"enable_rito_follow_user":true,"enable_rito_unfollow_user":true,"enable_rito_your_story_delete_mutation":true,"enable_rito_update_last_read_section":true,"enable_primary_topic_for_mobile":true,"enable_rito_sequence_post_handler":true,"enable_todays_highlights_ios":true,"enable_logged_out_homepage_signup":true,"use_new_admin_topic_backend":true,"enable_quarantine_rules":true,"enable_lite_privacy_banner":true,"enable_patronus_on_kubernetes":true,"pub_sidebar":true,"disable_mobile_featured_chunk":true,"enable_rito_user_profile_overview_handler":true,"enable_rito_user_stream_overview":true,"enable_rito_user_profile_latest_handler":true,"enable_rito_user_stream_latest":true,"enable_rito_user_profile_actions":true,"enable_rito_post_actions":true,"enable_rito_user_profile_highlights_handler":true,"enable_rito_user_stream_highlights":true,"enable_rito_user_profile_series_handler":true,"enable_rito_user_stream_series":true,"enable_rito_user_profile_claps_handler":true,"enable_rito_user_stream_claps":true,"enable_rito_user_profile_responses_handler":true,"enable_rito_user_stream_responses":true,"enable_rito_billing_history_handler":true,"enable_rito_your_stories_handler":true,"enable_rito_sequence_library_handler":true,"enable_rito_series_handler":true,"enable_rito_amppost_handler":true,"enable_rito_follow_collection_mutation":true,"enable_rito_unfollow_collection_mutation":true,"enable_pub_newsletters":true,"enable_new_user_avatar_dropdown_menu":true,"enable_mobile_pubcrawl_home_feed":true,"enable_send_pub_digest":true,"enable_draft_in_post_cotent":true,"enable_paypal_cancel_webhook":true,"enable_retrained_ranking_model_digest":true,"enable_retrained_ranking_model_homepage":true,"disable_ensure_featured_distro_processor":true},"xsrfToken":"ybUFuWCAStiXkZFY","iosAppId":"828256236","supportEmail":"yourfriends@medium.com","fp":{"/icons/monogram-mask.svg":"https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg","/icons/favicon-dev-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-dev-editor.YKKRxBO8EMvIqhyCwIiJeQ.ico","/icons/favicon-hatch-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-hatch-editor.BuEyHIqlyh2s_XEk4Rl32Q.ico","/icons/favicon-medium-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-medium-editor.PiakrZWB7Yb80quUVQWM6g.ico"},"authBaseUrl":"https://medium.com","imageUploadSizeMb":25,"isAuthDomainRequest":false,"domainCollectionSlug":"towards-data-science","algoliaApiEndpoint":"https://MQ57UUUQZ2-dsn.algolia.net","algoliaAppId":"MQ57UUUQZ2","algoliaSearchOnlyApiKey":"394474ced050e3911ae2249ecc774921","iosAppStoreUrl":"https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8","iosAppLinkBaseUrl":"medium:","algoliaIndexPrefix":"medium_","androidPlayStoreUrl":"https://play.google.com/store/apps/details?id=com.medium.reader","googleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","androidPackage":"com.medium.reader","androidPlayStoreMarketScheme":"market://details?id=com.medium.reader","googleAuthUri":"https://accounts.google.com/o/oauth2/auth","androidScheme":"medium","layoutData":{"useDynamicScripts":false,"googleAnalyticsTrackingCode":"UA-24232453-2","jsShivUrl":"https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js","useDynamicCss":false,"faviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico","faviconImageId":"1*8I-HPL0bfoIzGied-dzOvA.png","fontSets":[{"id":8,"url":"https://glyph.medium.com/css/e/sr/latin/e/ssr/latin/e/ssb/latin/m2.css"},{"id":11,"url":"https://glyph.medium.com/css/m2.css"},{"id":9,"url":"https://glyph.medium.com/css/mkt.css"}],"editorFaviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium-editor.3Y6xpZ-0FSdWDnPM3hSBIA.ico","glyphUrl":"https://glyph.medium.com"},"authBaseUrlRev":"moc.muidem//:sptth","isDnt":false,"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","archiveUploadSizeMb":100,"paymentData":{"currencies":{"1":{"label":"US Dollar","external":"usd"}},"countries":{"1":{"label":"United States of America","external":"US"}},"accountTypes":{"1":{"label":"Individual","external":"individual"},"2":{"label":"Company","external":"company"}}},"previewConfig2":{"weightThreshold":1,"weightImageParagraph":0.05,"raiseImage":true,"enforceHeaderHierarchy":true,"isImageInsetRight":true},"isAmp":false,"iosScheme":"medium","isSwBoot":false,"lightstep":{"accessToken":"ce5be895bef60919541332990ac9fef2","carrier":"{\"ot-tracer-spanid\":\"5b3c2ba5000e303d\",\"ot-tracer-traceid\":\"51f4923c7d558250\",\"ot-tracer-sampled\":\"true\"}","host":"collector-medium.lightstep.com"},"facebook":{"key":"542599432471018","namespace":"medium-com","scope":{"default":["public_profile","email"],"connect":["public_profile","email"],"login":["public_profile","email"],"share":["public_profile","email"]}},"editorsPicksTopicId":"3985d2a191c5","popularOnMediumTopicId":"9d34e48ecf94","memberContentTopicId":"13d7efd82fb2","audioContentTopicId":"3792abbd134","brandedSequenceId":"7d337ddf1941","isDoNotAuth":false,"buggle":{"url":"https://buggle.medium.com","videoUrl":"https://cdn-videos-1.medium.com","audioUrl":"https://cdn-audio-1.medium.com"},"referrerType":5,"isMeteredOut":false,"meterConfig":{"maxUnlockCount":3,"windowLength":"MONTHLY"},"partnerProgramEmail":"partnerprogram@medium.com","userResearchPrompts":[{"promptId":"li_post_page","type":0,"url":"www.calendly.com"},{"promptId":"li_home_page","type":1,"url":"mediumuserfeedback.typeform.com/to/GcFjEO"},{"promptId":"li_profile_page","type":2,"url":"www.calendly.com"}],"recaptchaKey":"6LdAokEUAAAAAC7seICd4vtC8chDb3jIXDQulyUJ","signinWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"countryCode":"US","bypassMeter":false,"branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","paypal":{"clientMode":"production","oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com/redeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"}},"collectionConfig":{"mediumOwnedAndOperatedCollectionIds":["544c7006046e","bcc38c8f6edf","444d13b52878","8d6b8a439e32","92d2092dc598","1285ba81cada","cb8577c9149e"]}}
// ]]></script><script charset="UTF-8" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/main-base.bundle.3zcQTeDFlV3HhQwoX8g-gg.js" async=""></script><script>// <![CDATA[
window["obvInit"]({"references":{"Collection":{"7f60cf5620c9":{"id":"7f60cf5620c9","name":"Towards Data Science","slug":"towards-data-science","tags":["DATA SCIENCE","MACHINE LEARNING","ARTIFICIAL INTELLIGENCE","ANALYTICS","PROGRAMMING"],"creatorId":"895063a310f4","description":"Sharing concepts, ideas, and codes.","shortDescription":"Sharing concepts, ideas, and codes.","image":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":216483,"activeAt":1558099624520},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"1*5EUO1kUYBthpOCPzRj_l2g.png","filter":"","backgroundSize":"","originalWidth":1010,"originalHeight":376,"strategy":"resample","height":0,"width":0},"twitterUsername":"TDataScience","facebookPageName":"towardsdatascience","collectionMastheadId":"8b6aceffde6","domain":"towardsdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["1995d56e4208","dd515a628896"]}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["e8a6d5639781","9ad95baa6bfe","edec1e9ad8c"],"sectionHeader":"Featured "}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":6,"postIds":[],"sectionHeader":"Latest"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["ae4a955e515f","11e7b1ad12f3"],"sectionHeader":"Our Letters"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"897911940e9a"}},{"type":1,"postListMetadata":{"source":2,"layout":4,"number":6,"postIds":[],"sectionHeader":"Trending"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["3bf37f75a345","3920888f831c"],"sectionHeader":"Our Readers’ Guide"}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":9,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Editors' Picks"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["96667b06af5","d691af11cc2f"],"sectionHeader":"Contribute"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["eea5e903499c","766cdd74d13e"]}},{"type":1,"postListMetadata":{"source":4,"layout":5,"number":3,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Last Chance To Read"}}],"tintColor":"#FF355876","lightText":true,"favicon":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF668AAA","point":0},{"color":"#FF61809D","point":0.1},{"color":"#FF5A7690","point":0.2},{"color":"#FF546C83","point":0.3},{"color":"#FF4D6275","point":0.4},{"color":"#FF455768","point":0.5},{"color":"#FF3D4C5A","point":0.6},{"color":"#FF34414C","point":0.7},{"color":"#FF2B353E","point":0.8},{"color":"#FF21282F","point":0.9},{"color":"#FF161B1F","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF355876","point":0},{"color":"#FF4D6C88","point":0.1},{"color":"#FF637F99","point":0.2},{"color":"#FF7791A8","point":0.3},{"color":"#FF8CA2B7","point":0.4},{"color":"#FF9FB3C6","point":0.5},{"color":"#FFB2C3D4","point":0.6},{"color":"#FFC5D2E1","point":0.7},{"color":"#FFD7E2EE","point":0.8},{"color":"#FFE9F1FA","point":0.9},{"color":"#FFFBFFFF","point":1}],"backgroundColor":"#FF355876"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEDF4FC","point":0},{"color":"#FFE9F2FD","point":0.1},{"color":"#FFE6F1FD","point":0.2},{"color":"#FFE2EFFD","point":0.3},{"color":"#FFDFEEFD","point":0.4},{"color":"#FFDBECFE","point":0.5},{"color":"#FFD7EBFE","point":0.6},{"color":"#FFD4E9FE","point":0.7},{"color":"#FFD0E7FF","point":0.8},{"color":"#FFCCE6FF","point":0.9},{"color":"#FFC8E4FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":4,"title":"Data Science","url":"https://towardsdatascience.com/data-science/home","topicId":"cf416843aadc","source":"topicId"},{"type":4,"title":"Machine Learning","url":"https://towardsdatascience.com/machine-learning/home","topicId":"a5c9b2f1cb6b","source":"topicId"},{"type":4,"title":"Programming","url":"https://towardsdatascience.com/programming/home","topicId":"41533a1dc73c","source":"topicId"},{"type":4,"title":"Visualization","url":"https://towardsdatascience.com/data-visualization/home","topicId":"825e6cb8b9ce","source":"topicId"},{"type":4,"title":"AI","url":"https://towardsdatascience.com/artificial-intelligence/home","topicId":"7f029b17bf96","source":"topicId"},{"type":4,"title":"Journalism","url":"https://towardsdatascience.com/data-journalism/home","topicId":"27a6ac3980c6","source":"topicId"},{"type":4,"title":"Picks","url":"https://towardsdatascience.com/editors-picks/home","topicId":"e81f4fc5ee6b","source":"topicId"},{"type":3,"title":"Contribute","url":"https://towardsdatascience.com/contribute/home"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-19707169-24","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5},"paidForDomainAt":1509037374118,"type":"Collection"},"9d9d52805eca":{"id":"9d9d52805eca","name":"Ensina.AI","slug":"ensina-ai","tags":["INTELIGENCIA ARTIFICIAL","DATA SCIENCE","MACHINE LEARNING","ARTIFICIAL INTELLIGENCE","DEEP LEARNING"],"creatorId":"e3736241dd36","description":"Tudo sobre Inteligência Artificial em Português","shortDescription":"Tudo sobre Inteligência Artificial em Português","image":{"imageId":"1*o6mVU1EAJoVtYVqKg-Go5w.png","filter":"","backgroundSize":"","originalWidth":136,"originalHeight":136,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":732,"activeAt":1557393486305},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"1*i4ihC7aWGRtm2tv1xJv30w.png","filter":"","backgroundSize":"","originalWidth":324,"originalHeight":68,"strategy":"resample","height":0,"width":0},"sections":[{"type":2,"collectionHeaderMetadata":{"backgroundImage":{},"logoImage":{"id":"1*i4ihC7aWGRtm2tv1xJv30w@2x.png","originalWidth":324,"originalHeight":68,"alt":"Ensina.AI"},"alignment":2,"layout":4}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":1,"postIds":["3972cac5e9b5"]}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":3,"postIds":[],"tagSlug":"Data Science","sectionHeader":"Novidades em Ciência de Dados"}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":3,"postIds":[],"tagSlug":"Tutorial","sectionHeader":"Novidades em Tutoriais"}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":3,"postIds":[],"tagSlug":"Case Study","sectionHeader":"Novidades em Cases Brasileiros"}},{"type":1,"postListMetadata":{"source":4,"layout":6,"number":3,"postIds":[],"tagSlug":"Vagas De Emprego","sectionHeader":"Vagas De Emprego"}}],"tintColor":"#FF3D8BAC","lightText":true,"favicon":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF4390B2","point":0},{"color":"#FF4286A4","point":0.1},{"color":"#FF407B96","point":0.2},{"color":"#FF3D7188","point":0.3},{"color":"#FF3A667A","point":0.4},{"color":"#FF365B6C","point":0.5},{"color":"#FF314F5D","point":0.6},{"color":"#FF2B434F","point":0.7},{"color":"#FF243740","point":0.8},{"color":"#FF1C2A31","point":0.9},{"color":"#FF121C21","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF3D8BAC","point":0},{"color":"#FF5598B7","point":0.1},{"color":"#FF6BA5C1","point":0.2},{"color":"#FF7EB2CB","point":0.3},{"color":"#FF91BED4","point":0.4},{"color":"#FFA3CADE","point":0.5},{"color":"#FFB4D5E7","point":0.6},{"color":"#FFC5E1EF","point":0.7},{"color":"#FFD6ECF8","point":0.8},{"color":"#FFE6F7FF","point":0.9},{"color":"#FFF6FFFF","point":1}],"backgroundColor":"#FF3D8BAC"},"highlightSpectrum":{"colorPoints":[{"color":"#FFE7F6FE","point":0},{"color":"#FFE2F5FF","point":0.1},{"color":"#FFDDF3FF","point":0.2},{"color":"#FFD8F2FF","point":0.3},{"color":"#FFD3F1FF","point":0.4},{"color":"#FFCEF0FF","point":0.5},{"color":"#FFC9EFFF","point":0.6},{"color":"#FFC4EEFF","point":0.7},{"color":"#FFBEECFF","point":0.8},{"color":"#FFB9EBFF","point":0.9},{"color":"#FFB3EAFF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":4,"title":"Ciência de Dados","url":"https://medium.com/ensina-ai/ciencia-de-dados/home","topicId":"b4f8997928ce","source":"topicId"},{"type":4,"title":"Tutoriais","url":"https://medium.com/ensina-ai/tutoriais/home","topicId":"851ea45c6387","source":"topicId"},{"type":4,"title":"Visualização","url":"https://medium.com/ensina-ai/visualizacao/home","topicId":"4c3a5bcb5f0e","source":"topicId"},{"type":4,"title":"Cases Brasileiros","url":"https://medium.com/ensina-ai/cases-brasileiros/home","topicId":"6c47c40cab0f","source":"topicId"},{"type":4,"title":"Vagas","url":"https://medium.com/ensina-ai/vagas/home","topicId":"e03be07c3155","source":"topicId"},{"type":4,"title":"Contribua","url":"https://medium.com/ensina-ai/contribua/home","topicId":"ef4f8ee9e7ac","source":"topicId"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"backgroundImage":{},"logoImage":{"id":"1*i4ihC7aWGRtm2tv1xJv30w@2x.png","originalWidth":324,"originalHeight":68,"alt":"Ensina.AI"},"alignment":2,"layout":4},"type":"Collection"},"34c9bdb05ea2":{"id":"34c9bdb05ea2","name":"DataGnosis","slug":"datagnosis","tags":["MACHINE LEARNING","DEEP LEARNING","DATA VISUALIZATION","DATA SCIENCE","DATAGNOSIS"],"creatorId":"c79695e37339","description":"Ciência de Dados em Português","shortDescription":"Ciência de Dados em Português","image":{"imageId":"1*AHJ5aTPC4G4xGolhvmXANw.png","filter":"","backgroundSize":"","originalWidth":480,"originalHeight":480,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":4,"activeAt":1525600271649},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"twitterUsername":"datagnosis","facebookPageName":"DataGnosisCursos","publicEmail":"publicacao@datagnosis.ml","sections":[{"type":2,"collectionHeaderMetadata":{"title":"DataGnosis","description":"Ciência de Dados em Português","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":3,"layout":2,"number":1,"postIds":["4baa801ccf"]}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":6,"postIds":[]}}],"tintColor":"#FF53875F","lightText":true,"favicon":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF5E9269","point":0},{"color":"#FF598863","point":0.1},{"color":"#FF537D5C","point":0.2},{"color":"#FF4D7255","point":0.3},{"color":"#FF47674D","point":0.4},{"color":"#FF405C46","point":0.5},{"color":"#FF39503D","point":0.6},{"color":"#FF314434","point":0.7},{"color":"#FF29372B","point":0.8},{"color":"#FF1F2A21","point":0.9},{"color":"#FF141C16","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF53875F","point":0},{"color":"#FF65956F","point":0.1},{"color":"#FF77A37F","point":0.2},{"color":"#FF88B08F","point":0.3},{"color":"#FF99BC9E","point":0.4},{"color":"#FFAAC9AD","point":0.5},{"color":"#FFBAD5BC","point":0.6},{"color":"#FFCAE1CB","point":0.7},{"color":"#FFDAECDA","point":0.8},{"color":"#FFE9F7E8","point":0.9},{"color":"#FFF9FFF7","point":1}],"backgroundColor":"#FF53875F"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEAF7E9","point":0},{"color":"#FFE6F6E6","point":0.1},{"color":"#FFE2F5E2","point":0.2},{"color":"#FFDEF4DF","point":0.3},{"color":"#FFDAF3DC","point":0.4},{"color":"#FFD6F2D8","point":0.5},{"color":"#FFD2F1D5","point":0.6},{"color":"#FFCEF0D1","point":0.7},{"color":"#FFC9EFCE","point":0.8},{"color":"#FFC5EDCA","point":0.9},{"color":"#FFC1ECC7","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":4,"title":"Ciência de Dados","url":"https://medium.com/datagnosis/ciencia-de-dados/home","topicId":"9d6bb179b280","source":"topicId"},{"type":4,"title":"Machine Learning","url":"https://medium.com/datagnosis/machine-learning/home","topicId":"be7c9be6da50","source":"topicId"},{"type":4,"title":"Deep Learning","url":"https://medium.com/datagnosis/deep-learning/home","topicId":"f82e351d26a9","source":"topicId"},{"type":4,"title":"Visualização de Dados","url":"https://medium.com/datagnosis/visualizacao-de-dados/home","topicId":"931d891ee3ed","source":"topicId"},{"type":4,"title":"Contribua","url":"https://medium.com/datagnosis/contribua/home","topicId":"41e8fa3089b8","source":"topicId"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"DataGnosis","description":"Ciência de Dados em Português","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5},"type":"Collection"}},"User":{"c79695e37339":{"userId":"c79695e37339","name":"Daniel Godoy","username":"dvgodoy","createdAt":1521582859830,"imageId":"1*7kL4DitERABkDkP-caSAZA.png","backgroundImageId":"","bio":"Senior Data Scientist. Teacher @ Data Science Retreat","twitterScreenName":"dvgodoy","facebookAccountId":"1714299755315485","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"isWriterProgramEnrolled":true,"isQuarantined":false,"type":"User"}},"Post":{"81fc5f8c4e8e":{"id":"81fc5f8c4e8e","versionId":"91f98d1fd9a0","creatorId":"c79695e37339","homeCollectionId":"7f60cf5620c9","title":"Understanding PyTorch with an example: a step-by-step tutorial","detectedLanguage":"en","latestVersion":"91f98d1fd9a0","latestPublishedVersion":"91f98d1fd9a0","hasUnpublishedEdits":false,"latestRev":1812,"createdAt":1556719316387,"updatedAt":1557235675247,"acceptedAt":0,"firstPublishedAt":1557235674860,"latestPublishedAt":1557235674860,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"A structured, incremental and from first principles approach.","postDisplay":{"coverless":true},"metaDescription":"This tutorial will guide you through the main reasons why it’s easier and more intuitive to build a Deep Learning model in PyTorch, while also showing you how to avoid some common pitfalls and errors."},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"0*DG_jU1dr2RG2R1SF","filter":"","backgroundSize":"","originalWidth":5339,"originalHeight":3559,"strategy":"resample","height":0,"width":0},"wordCount":5087,"imageCount":10,"readingTime":20.44622641509434,"subtitle":"A structured, incremental and from first principles approach.","publishedInCount":1,"usersBySocialRecommends":[],"noIndex":false,"recommends":61,"isBookmarked":false,"tags":[{"slug":"machine-learning","name":"Machine Learning","postCount":70488,"metadata":{"postCount":70488,"coverImage":{"id":"1*p9A1742mTraDjk1YufM8Bw.png","originalWidth":1366,"originalHeight":922,"isFeatured":true}},"type":"Tag"},{"slug":"deep-learning","name":"Deep Learning","postCount":17387,"metadata":{"postCount":17387,"coverImage":{"id":"1*S_OcBPkRTpKJo0iz5IaNbQ.png","originalWidth":967,"originalHeight":570,"isFeatured":true}},"type":"Tag"},{"slug":"pytorch","name":"Pytorch","postCount":649,"metadata":{"postCount":649,"coverImage":{"id":"1*ytjIHXnlUOS6dKlCk1nNrA.png","originalWidth":4727,"originalHeight":2773,"isFeatured":true}},"type":"Tag"},{"slug":"towards-data-science","name":"Towards Data Science","postCount":2159,"metadata":{"postCount":2159,"coverImage":{"id":"1*mWV37dTAOl6WxxJc37ssjg.jpeg","originalWidth":3000,"originalHeight":1994,"isFeatured":true}},"type":"Tag"},{"slug":"tutorial","name":"Tutorial","postCount":14346,"metadata":{"postCount":14346,"coverImage":{"id":"1*mtho0xL9Qu-cXu61XeLrdA.jpeg","originalWidth":4912,"originalHeight":2760,"isFeatured":true}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":2,"links":{"entries":[{"url":"https://pytorch.org/docs/stable/autograd.html#torch.autograd.backward","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/tensors.html?highlight=numpy#torch.Tensor.numpy","alts":[],"httpStatus":200},{"url":"https://pytorch.org/tutorials/","alts":[],"httpStatus":200},{"url":"https://course.fast.ai/","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/nn.html#torch.nn.Module.parameters","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset","alts":[],"httpStatus":200},{"url":"https://twitter.com/karpathy/status/868178954032513024","alts":[{"type":2,"url":"twitter://status?id=868178954032513024"},{"type":3,"url":"twitter://status?status_id=868178954032513024"}],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/tensors.html#torch.Tensor.float","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/tensors.html#torch.Tensor.requires_grad_","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/tensors.html#torch.Tensor.to","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/optim.html#torch.optim.SGD","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer.step","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout","alts":[],"httpStatus":200},{"url":"https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@aycai?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/cuda.html?highlight=is_available#torch.cuda.is_available","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/tensors.html#torch.Tensor.cpu","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer.zero_grad","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Chain_rule","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split","alts":[],"httpStatus":200},{"url":"https://docs.fast.ai/","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Answer_to_the_Ultimate_Question_of_Life,_the_Universe,_and_Everything_%2842%29","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/tensors.html#torch.Tensor.zero_","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/optim.html#torch.optim.Adam","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/autograd.html#torch.Tensor.grad","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/nn.html#torch.nn.Module.train","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/nn.html#torch.nn.Module.eval","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/nn.html#torch.nn.Linear","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/nn.html#torch.nn.Module.state_dict","alts":[],"httpStatus":200},{"url":"http://karlstratos.com/drawings/drawings.html","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad","alts":[],"httpStatus":200},{"url":"https://unsplash.com?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/nn.html#torch.nn.Parameter","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/torch.html#torch.from_numpy","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/nn.html#torch.nn.Module","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/nn.html#loss-functions","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/nn.html#torch.nn.Module.forward","alts":[],"httpStatus":200},{"url":"https://pytorch.org/docs/stable/nn.html#torch.nn.MSELoss","alts":[],"httpStatus":200},{"url":"https://twitter.com/dvgodoy","alts":[{"type":2,"url":"twitter://user?screen_name=dvgodoy"},{"type":3,"url":"twitter://user?screen_name=dvgodoy"}],"httpStatus":200},{"url":"https://github.com/szagoruyko/pytorchviz","alts":[],"httpStatus":200},{"url":"https://medium.com/p/81fc5f8c4e8e#3a3f","alts":[{"type":2,"url":"medium://p/81fc5f8c4e8e"},{"type":3,"url":"medium://p/81fc5f8c4e8e"}],"httpStatus":200},{"url":"https://medium.com/p/81fc5f8c4e8e#8877","alts":[{"type":2,"url":"medium://p/81fc5f8c4e8e"},{"type":3,"url":"medium://p/81fc5f8c4e8e"}],"httpStatus":200},{"url":"https://medium.com/p/81fc5f8c4e8e#58f2","alts":[{"type":2,"url":"medium://p/81fc5f8c4e8e"},{"type":3,"url":"medium://p/81fc5f8c4e8e"}],"httpStatus":200},{"url":"https://medium.com/p/81fc5f8c4e8e#6208","alts":[{"type":2,"url":"medium://p/81fc5f8c4e8e"},{"type":3,"url":"medium://p/81fc5f8c4e8e"}],"httpStatus":200},{"url":"https://medium.com/p/81fc5f8c4e8e#dc96","alts":[{"type":2,"url":"medium://p/81fc5f8c4e8e"},{"type":3,"url":"medium://p/81fc5f8c4e8e"}],"httpStatus":200},{"url":"https://medium.com/p/81fc5f8c4e8e#3806","alts":[{"type":2,"url":"medium://p/81fc5f8c4e8e"},{"type":3,"url":"medium://p/81fc5f8c4e8e"}],"httpStatus":200},{"url":"https://medium.com/p/81fc5f8c4e8e#a657","alts":[{"type":3,"url":"medium://p/81fc5f8c4e8e"},{"type":2,"url":"medium://p/81fc5f8c4e8e"}],"httpStatus":200},{"url":"https://medium.com/p/81fc5f8c4e8e#2e24","alts":[{"type":2,"url":"medium://p/81fc5f8c4e8e"},{"type":3,"url":"medium://p/81fc5f8c4e8e"}],"httpStatus":200},{"url":"https://medium.com/p/81fc5f8c4e8e#5017","alts":[{"type":2,"url":"medium://p/81fc5f8c4e8e"},{"type":3,"url":"medium://p/81fc5f8c4e8e"}],"httpStatus":200},{"url":"https://medium.com/p/81fc5f8c4e8e#ea0d","alts":[{"type":2,"url":"medium://p/81fc5f8c4e8e"},{"type":3,"url":"medium://p/81fc5f8c4e8e"}],"httpStatus":200},{"url":"https://medium.com/p/81fc5f8c4e8e#cf51","alts":[{"type":2,"url":"medium://p/81fc5f8c4e8e"},{"type":3,"url":"medium://p/81fc5f8c4e8e"}],"httpStatus":200},{"url":"https://medium.com/p/81fc5f8c4e8e#40de","alts":[{"type":2,"url":"medium://p/81fc5f8c4e8e"},{"type":3,"url":"medium://p/81fc5f8c4e8e"}],"httpStatus":200},{"url":"https://gist.github.com/dvgodoy/1d818d86a6a0dc6e7c07610835b46fe4","alts":[],"httpStatus":200}],"version":"0.3","generatedAt":1557235678811},"isLockedPreviewOnly":false,"metaDescription":"This tutorial will guide you through the main reasons why it’s easier and more intuitive to build a Deep Learning model in PyTorch, while also showing you how to avoid some common pitfalls and errors.","totalClapCount":250,"sectionCount":1,"readingList":0,"topics":[]},"coverless":true,"slug":"understanding-pytorch-with-an-example-a-step-by-step-tutorial","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":false,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewImage","type":4,"text":"","layout":10,"metadata":{"id":"0*DG_jU1dr2RG2R1SF","originalWidth":5339,"originalHeight":3559,"isFeatured":true,"unsplashPhotoId":"Y4RxCIaYaSk"}},{"name":"previewTitle","type":3,"text":"Understanding PyTorch with an example: a step-by-step tutorial","alignment":1},{"name":"previewSubtitle","type":13,"text":"A structured, incremental and from…","alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false,"subtitle":"A structured, incremental and from first principles approach."},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"","approvedHomeCollectionId":"7f60cf5620c9","newsletterId":"","webCanonicalUrl":"","mediumUrl":"","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"mongerRequestType":1,"layerCake":0,"socialTitle":"","socialDek":"","editorialPreviewTitle":"","editorialPreviewDek":"","curationEligibleAt":0,"type":"Post"},"3b1e69c12b4f":{"id":"3b1e69c12b4f","versionId":"8191f327f638","creatorId":"c79695e37339","homeCollectionId":"7f60cf5620c9","title":"Binary Classifier Evaluation made easy with HandySpark","detectedLanguage":"en","latestVersion":"8191f327f638","latestPublishedVersion":"8191f327f638","hasUnpublishedEdits":false,"latestRev":1429,"createdAt":1552083003836,"updatedAt":1552313183163,"acceptedAt":0,"firstPublishedAt":1552313165726,"latestPublishedAt":1552313165726,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"Extended evaluation metrics and plotting of ROC and PR curves in PySpark","postDisplay":{"coverless":true},"metaDescription":"HandySpark is designed to improve PySpark user experience, especially when it comes to exploratory data analysis,visualization capabilities and extended evaluation metrics."},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"0*8E8uKv-BMEzXPt3h","filter":"","backgroundSize":"","originalWidth":6000,"originalHeight":4000,"strategy":"resample","height":0,"width":0},"wordCount":1290,"imageCount":5,"readingTime":5.70125786163522,"subtitle":"Extended evaluation metrics and plotting of ROC and PR curves in PySpark","publishedInCount":1,"usersBySocialRecommends":[],"noIndex":false,"recommends":15,"isBookmarked":false,"tags":[{"slug":"machine-learning","name":"Machine Learning","postCount":70488,"metadata":{"postCount":70488,"coverImage":{"id":"1*p9A1742mTraDjk1YufM8Bw.png","originalWidth":1366,"originalHeight":922,"isFeatured":true}},"type":"Tag"},{"slug":"apache-spark","name":"Apache Spark","postCount":1125,"metadata":{"postCount":1125,"coverImage":{"id":"0*HwnSXuF99iFBtNYT","originalWidth":3862,"originalHeight":2578,"isFeatured":true,"unsplashPhotoId":"_Ch_onWf38o"}},"type":"Tag"},{"slug":"pyspark","name":"Pyspark","postCount":235,"metadata":{"postCount":235,"coverImage":{"id":"1*3PaATZRAXVWv6Rbu7lPLJg.png","originalWidth":881,"originalHeight":585,"isFeatured":true}},"type":"Tag"},{"slug":"evaluation","name":"Evaluation","postCount":807,"metadata":{"postCount":807,"coverImage":{"id":"1*pLd-nWflD8ffj5FMu7EEYA.png","originalWidth":700,"originalHeight":441,"isFeatured":true}},"type":"Tag"},{"slug":"towards-data-science","name":"Towards Data Science","postCount":2159,"metadata":{"postCount":2159,"coverImage":{"id":"1*mWV37dTAOl6WxxJc37ssjg.jpeg","originalWidth":3000,"originalHeight":1994,"isFeatured":true}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":0,"links":{"entries":[{"url":"https://unsplash.com?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://dvgodoy.github.io/handyspark/handyspark.html#handyspark.HandyFrame.isnull","alts":[],"httpStatus":200},{"url":"https://dvgodoy.github.io/handyspark/handyspark.sql.html#handyspark.sql.dataframe.HandyFrame.stratify","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Outlier#Tukey%27s_fences","alts":[],"httpStatus":200},{"url":"http://www.navan.name/roc/","alts":[],"httpStatus":200},{"url":"https://github.com/dvgodoy/handyspark/releases/tag/v0.2.0a1","alts":[],"httpStatus":200},{"url":"https://github.com/dvgodoy/handyspark","alts":[],"httpStatus":200},{"url":"https://colab.research.google.com/github/dvgodoy/handyspark/blob/master/notebooks/Exploring_Titanic.ipynb","alts":[],"httpStatus":200},{"url":"https://towardsdatascience.com/confused-by-the-confusion-matrix-e26d5e1d74eb","alts":[{"type":3,"url":"medium://p/e26d5e1d74eb"},{"type":2,"url":"medium://p/e26d5e1d74eb"}],"httpStatus":200},{"url":"https://twitter.com/dvgodoy","alts":[{"type":2,"url":"twitter://user?screen_name=dvgodoy"},{"type":3,"url":"twitter://user?screen_name=dvgodoy"}],"httpStatus":200},{"url":"https://unsplash.com/@sjbaren?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://towardsdatascience.com/receiver-operating-characteristic-curves-demystified-in-python-bd531a4364d0","alts":[{"type":2,"url":"medium://p/bd531a4364d0"},{"type":3,"url":"medium://p/bd531a4364d0"}],"httpStatus":200},{"url":"https://towardsdatascience.com/handyspark-bringing-pandas-like-capabilities-to-spark-dataframes-5f1bcea9039e","alts":[{"type":3,"url":"medium://p/5f1bcea9039e"},{"type":2,"url":"medium://p/5f1bcea9039e"}],"httpStatus":200},{"url":"https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5","alts":[{"type":2,"url":"medium://p/68b2303cc9c5"},{"type":3,"url":"medium://p/68b2303cc9c5"}],"httpStatus":200}],"version":"0.3","generatedAt":1552313166441},"isLockedPreviewOnly":false,"metaDescription":"HandySpark is designed to improve PySpark user experience, especially when it comes to exploratory data analysis,visualization capabilities and extended evaluation metrics.","totalClapCount":26,"sectionCount":1,"readingList":0,"topics":[{"topicId":"1eca0103fff3","slug":"machine-learning","createdAt":1534449726145,"deletedAt":0,"image":{"id":"1*gFJS3amhZEg_z39D5EErVg@2x.png","originalWidth":2800,"originalHeight":1750},"name":"Machine Learning","description":"Teaching the learners.","relatedTopics":[],"visibility":1,"relatedTags":[],"relatedTopicIds":[],"type":"Topic"},{"topicId":"ae5d4995e225","slug":"data-science","createdAt":1493923906289,"deletedAt":0,"image":{"id":"1*NHWOEki_ncCX-xzbKtkEWw@2x.jpeg","originalWidth":5760,"originalHeight":3840},"name":"Data Science","description":"Query this.","relatedTopics":[],"visibility":1,"relatedTags":[],"relatedTopicIds":[],"type":"Topic"}]},"coverless":true,"slug":"binary-classifier-evaluation-made-easy-with-handyspark","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":false,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"binary-classifier-evaluation-made-easy-with-handyspark-3b1e69c12b4f","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewImage","type":4,"text":"","layout":10,"metadata":{"id":"0*8E8uKv-BMEzXPt3h","originalWidth":6000,"originalHeight":4000,"isFeatured":true,"unsplashPhotoId":"9ZU-vkfCUEo"}},{"name":"previewTitle","type":3,"text":"Binary Classifier Evaluation made easy with HandySpark","alignment":1},{"name":"previewSubtitle","type":13,"text":"Extended evaluation metrics and plotting of ROC…","alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false,"subtitle":"Extended evaluation metrics and plotting of ROC and PR curves in PySpark"},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"","approvedHomeCollectionId":"7f60cf5620c9","newsletterId":"","webCanonicalUrl":"","mediumUrl":"","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"mongerRequestType":1,"layerCake":3,"socialTitle":"","socialDek":"","editorialPreviewTitle":"","editorialPreviewDek":"","curationEligibleAt":0,"primaryTopicId":"1eca0103fff3","type":"Post"},"690ddad7803":{"id":"690ddad7803","versionId":"332565326da6","creatorId":"c79695e37339","homeCollectionId":"7f60cf5620c9","title":"Understanding a Machine Learning workflow through food","detectedLanguage":"en","latestVersion":"332565326da6","latestPublishedVersion":"332565326da6","hasUnpublishedEdits":false,"latestRev":1992,"createdAt":1542997851651,"updatedAt":1543822682276,"acceptedAt":0,"firstPublishedAt":1543242842568,"latestPublishedAt":1543822682276,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"Through food?! Yes, you got that right, through food! :-)","postDisplay":{"coverless":true},"metaDescription":"Have you ever wondered the workflow behind getting a pizza delivered to your home? It turns out, it’s not so different from a Machine Learning workflow. Really! Let’s check it out!"},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"0*Ubjf3Wi8RH6YsYir","filter":"","backgroundSize":"","originalWidth":3582,"originalHeight":2149,"strategy":"resample","height":0,"width":0},"wordCount":1267,"imageCount":11,"readingTime":6.0811320754716975,"subtitle":"Through food?! Yes, you got that right, through food! :-)","publishedInCount":1,"usersBySocialRecommends":[],"noIndex":false,"recommends":28,"isBookmarked":false,"tags":[{"slug":"food","name":"Food","postCount":119311,"metadata":{"postCount":119311,"coverImage":{"id":"1*jv_5N8d2VvmOzd8uROiuaw.jpeg"}},"type":"Tag"},{"slug":"machine-learning","name":"Machine Learning","postCount":70488,"metadata":{"postCount":70488,"coverImage":{"id":"1*p9A1742mTraDjk1YufM8Bw.png","originalWidth":1366,"originalHeight":922,"isFeatured":true}},"type":"Tag"},{"slug":"data-science","name":"Data Science","postCount":46553,"metadata":{"postCount":46553,"coverImage":{"id":"1*lTH3uYF9zSyjUZ1WwLc4tg.png","originalWidth":1200,"originalHeight":578,"isFeatured":true}},"type":"Tag"},{"slug":"towards-data-science","name":"Towards Data Science","postCount":2159,"metadata":{"postCount":2159,"coverImage":{"id":"1*mWV37dTAOl6WxxJc37ssjg.jpeg","originalWidth":3000,"originalHeight":1994,"isFeatured":true}},"type":"Tag"},{"slug":"project-management","name":"Project Management","postCount":15760,"metadata":{"postCount":15760,"coverImage":{"id":"1*bn3akymtDup8OCILlYv8nA.jpeg","originalWidth":3456,"originalHeight":2304,"isFeatured":true}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":2,"links":{"entries":[{"url":"https://unsplash.com/@no_one_cares?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@icons8?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@socialcut?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://unsplash.com?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@carolineattwood?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@matthew_t_rader?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://twitter.com/dvgodoy","alts":[{"type":2,"url":"twitter://user?screen_name=dvgodoy"},{"type":3,"url":"twitter://user?screen_name=dvgodoy"}],"httpStatus":200},{"url":"https://unsplash.com/@kaip?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@clemono2?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@momentance?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@bonniekdesign?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@armgd?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@cellisboa?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://datanatives.io/speakers/#speaker-1151","alts":[],"httpStatus":200}],"version":"0.3","generatedAt":1543822683989},"isLockedPreviewOnly":false,"metaDescription":"Have you ever wondered the workflow behind getting a pizza delivered to your home? It turns out, it’s not so different from a Machine Learning workflow. Really! Let’s check it out!","totalClapCount":71,"sectionCount":2,"readingList":0,"topics":[]},"coverless":true,"slug":"understanding-a-machine-learning-workflow-through-food","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":false,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"understanding-a-machine-learning-workflow-through-food-690ddad7803","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewImage","type":4,"text":"","layout":10,"metadata":{"id":"0*Ubjf3Wi8RH6YsYir","originalWidth":3582,"originalHeight":2149,"isFeatured":true,"unsplashPhotoId":"YJSOou0wt8c"}},{"name":"f41f","type":3,"text":"Understanding a Machine Learning workflow through food","markups":[],"alignment":1},{"name":"937e","type":13,"text":"Through food?!","markups":[{"type":1,"start":8,"end":12}],"alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false,"subtitle":"Through food?! Yes, you got that right, through food! :-)"},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"","approvedHomeCollectionId":"7f60cf5620c9","newsletterId":"","webCanonicalUrl":"","mediumUrl":"","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"mongerRequestType":1,"layerCake":4,"socialTitle":"","socialDek":"","editorialPreviewTitle":"","editorialPreviewDek":"","curationEligibleAt":1543217235112,"type":"Post"},"a3ac6025181a":{"id":"a3ac6025181a","versionId":"315e5844be87","creatorId":"c79695e37339","homeCollectionId":"7f60cf5620c9","title":"Understanding binary cross-entropy / log loss: a visual explanation","detectedLanguage":"en","latestVersion":"315e5844be87","latestPublishedVersion":"315e5844be87","hasUnpublishedEdits":false,"latestRev":2635,"createdAt":1542552103173,"updatedAt":1549567973021,"acceptedAt":0,"firstPublishedAt":1542824241901,"latestPublishedAt":1549567973021,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"Have you ever thought about what exactly does it mean to use this loss function?","postDisplay":{"coverless":true},"metaDescription":"Find the concepts behind binary cross-entropy / log loss explained in a visually clear and concise manner."},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"0*BJZqDD5ieVE6XxdD","filter":"","backgroundSize":"","originalWidth":4000,"originalHeight":2667,"strategy":"resample","height":0,"width":0},"wordCount":1676,"imageCount":23,"readingTime":8.224528301886792,"subtitle":"Have you ever thought about what exactly does it mean to use this loss function?","publishedInCount":1,"usersBySocialRecommends":[],"noIndex":false,"recommends":338,"isBookmarked":false,"tags":[{"slug":"machine-learning","name":"Machine Learning","postCount":70488,"metadata":{"postCount":70488,"coverImage":{"id":"1*p9A1742mTraDjk1YufM8Bw.png","originalWidth":1366,"originalHeight":922,"isFeatured":true}},"type":"Tag"},{"slug":"classification","name":"Classification","postCount":818,"metadata":{"postCount":818,"coverImage":{"id":"1*S_OcBPkRTpKJo0iz5IaNbQ.png","originalWidth":967,"originalHeight":570,"isFeatured":true}},"type":"Tag"},{"slug":"entropy","name":"Entropy","postCount":324,"metadata":{"postCount":324,"coverImage":{"id":"1*z-4Jf9apbzR8pGb21zp4Yg.jpeg","originalWidth":1149,"originalHeight":791,"isFeatured":true}},"type":"Tag"},{"slug":"loss-function","name":"Loss Function","postCount":68,"metadata":{"postCount":68,"coverImage":{"id":"0*BJZqDD5ieVE6XxdD","originalWidth":4000,"originalHeight":2667,"isFeatured":true,"unsplashPhotoId":"uCMKx2H1Y38"}},"type":"Tag"},{"slug":"towards-data-science","name":"Towards Data Science","postCount":2159,"metadata":{"postCount":2159,"coverImage":{"id":"1*mWV37dTAOl6WxxJc37ssjg.jpeg","originalWidth":3000,"originalHeight":1994,"isFeatured":true}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":18,"links":{"entries":[{"url":"https://unsplash.com?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"http://colah.github.io/posts/2015-09-Visual-Information/","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@freegraphictoday?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://twitter.com/dvgodoy","alts":[{"type":2,"url":"twitter://user?screen_name=dvgodoy"},{"type":3,"url":"twitter://user?screen_name=dvgodoy"}],"httpStatus":200},{"url":"https://www.datascienceretreat.com/","alts":[],"httpStatus":200}],"version":"0.3","generatedAt":1549567974487},"isLockedPreviewOnly":false,"metaDescription":"Find the concepts behind binary cross-entropy / log loss explained in a visually clear and concise manner.","totalClapCount":1931,"sectionCount":1,"readingList":0,"topics":[]},"coverless":true,"slug":"understanding-binary-cross-entropy-log-loss-a-visual-explanation","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":false,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewImage","type":4,"text":"","layout":10,"metadata":{"id":"0*BJZqDD5ieVE6XxdD","originalWidth":4000,"originalHeight":2667,"isFeatured":true,"unsplashPhotoId":"uCMKx2H1Y38"}},{"name":"previewTitle","type":3,"text":"Understanding binary cross-entropy / log loss: a visual explanation","alignment":1},{"name":"previewSubtitle","type":13,"text":"Have you ever thought about what…","alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false,"subtitle":"Have you ever thought about what exactly does it mean to use this loss function?"},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"","approvedHomeCollectionId":"7f60cf5620c9","newsletterId":"","webCanonicalUrl":"","mediumUrl":"","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"mongerRequestType":1,"layerCake":4,"socialTitle":"","socialDek":"","editorialPreviewTitle":"","editorialPreviewDek":"","curationEligibleAt":1542822680548,"type":"Post"},"5f1bcea9039e":{"id":"5f1bcea9039e","versionId":"83c9f33f39bc","creatorId":"c79695e37339","homeCollectionId":"7f60cf5620c9","title":"HandySpark: bringing pandas-like capabilities to Spark DataFrames","detectedLanguage":"en","latestVersion":"83c9f33f39bc","latestPublishedVersion":"83c9f33f39bc","hasUnpublishedEdits":false,"latestRev":1877,"createdAt":1541333116350,"updatedAt":1552238511153,"acceptedAt":0,"firstPublishedAt":1542030992695,"latestPublishedAt":1552238511153,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"Exploratory Data Analysis and Visualization in PySpark","postDisplay":{"coverless":true},"metaDescription":"HandySpark is a new Python package designed to improve PySpark user experience, especially when it comes to exploratory data analysis, including visualization capabilities."},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"0*0fke2VC1RszzYaVu","filter":"","backgroundSize":"","originalWidth":3264,"originalHeight":2448,"strategy":"resample","height":0,"width":0},"wordCount":1833,"imageCount":6,"readingTime":7.8669811320754715,"subtitle":"Exploratory Data Analysis and Visualization in PySpark","publishedInCount":1,"usersBySocialRecommends":[],"noIndex":false,"recommends":78,"isBookmarked":false,"tags":[{"slug":"apache-spark","name":"Apache Spark","postCount":1125,"metadata":{"postCount":1125,"coverImage":{"id":"0*HwnSXuF99iFBtNYT","originalWidth":3862,"originalHeight":2578,"isFeatured":true,"unsplashPhotoId":"_Ch_onWf38o"}},"type":"Tag"},{"slug":"visualization","name":"Visualization","postCount":2569,"metadata":{"postCount":2569,"coverImage":{"id":"1*GZR28slKCtV8LfYeFd9FbA.png","originalWidth":1866,"originalHeight":1224,"isFeatured":true}},"type":"Tag"},{"slug":"exploratory-data-analysis","name":"Exploratory Data Analysis","postCount":258,"metadata":{"postCount":258,"coverImage":{"id":"0*N8BVwsKl505JGGZu","originalWidth":1000,"originalHeight":667,"isFeatured":true}},"type":"Tag"},{"slug":"towards-data-science","name":"Towards Data Science","postCount":2159,"metadata":{"postCount":2159,"coverImage":{"id":"1*mWV37dTAOl6WxxJc37ssjg.jpeg","originalWidth":3000,"originalHeight":1994,"isFeatured":true}},"type":"Tag"},{"slug":"pandas","name":"Pandas","postCount":1189,"metadata":{"postCount":1189,"coverImage":{"id":"1*e_QOu6jsHfDuyOEW7wG3BQ.png","originalWidth":810,"originalHeight":451,"isFeatured":true}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":3,"links":{"entries":[{"url":"https://unsplash.com?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Outlier#Tukey%27s_fences","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@chuttersnap?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isin.html","alts":[],"httpStatus":200},{"url":"https://github.com/dvgodoy/handyspark/releases/tag/v0.2.0a1","alts":[],"httpStatus":200},{"url":"https://towardsdatascience.com/the-most-in-demand-skills-for-data-scientists-4a4a8db896db","alts":[{"type":2,"url":"medium://p/4a4a8db896db"},{"type":3,"url":"medium://p/4a4a8db896db"}],"httpStatus":200},{"url":"https://github.com/dvgodoy/handyspark","alts":[],"httpStatus":200},{"url":"https://twitter.com/dvgodoy","alts":[{"type":2,"url":"twitter://user?screen_name=dvgodoy"},{"type":3,"url":"twitter://user?screen_name=dvgodoy"}],"httpStatus":200},{"url":"https://colab.research.google.com/github/dvgodoy/handyspark/blob/master/notebooks/Exploring_Titanic.ipynb","alts":[],"httpStatus":200},{"url":"http://spark.apache.org/docs/2.3.2/api/python/pyspark.ml.html#pyspark.ml.feature.Imputer","alts":[],"httpStatus":200},{"url":"https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html","alts":[],"httpStatus":200},{"url":"https://www.datascienceretreat.com/teachers/daniel-voigt-godoy","alts":[],"httpStatus":200}],"version":"0.3","generatedAt":1552238515442},"isLockedPreviewOnly":false,"metaDescription":"HandySpark is a new Python package designed to improve PySpark user experience, especially when it comes to exploratory data analysis, including visualization capabilities.","totalClapCount":339,"sectionCount":1,"readingList":0,"topics":[{"topicId":"ae5d4995e225","slug":"data-science","createdAt":1493923906289,"deletedAt":0,"image":{"id":"1*NHWOEki_ncCX-xzbKtkEWw@2x.jpeg","originalWidth":5760,"originalHeight":3840},"name":"Data Science","description":"Query this.","relatedTopics":[],"visibility":1,"relatedTags":[],"relatedTopicIds":[],"type":"Topic"}]},"coverless":true,"slug":"handyspark-bringing-pandas-like-capabilities-to-spark-dataframes","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":false,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"handyspark-bringing-pandas-like-capabilities-to-spark-dataframes-5f1bcea9039e","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewImage","type":4,"text":"","layout":10,"metadata":{"id":"0*0fke2VC1RszzYaVu","originalWidth":3264,"originalHeight":2448,"isFeatured":true,"unsplashPhotoId":"c9mlIOlNzj4"}},{"name":"previewTitle","type":3,"text":"HandySpark: bringing pandas-like capabilities to Spark DataFrames","alignment":1},{"name":"previewSubtitle","type":13,"text":"Exploratory Data Analysis and…","alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false,"subtitle":"Exploratory Data Analysis and Visualization in PySpark"},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"","approvedHomeCollectionId":"7f60cf5620c9","newsletterId":"","webCanonicalUrl":"","mediumUrl":"","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"mongerRequestType":1,"layerCake":3,"socialTitle":"","socialDek":"","editorialPreviewTitle":"","editorialPreviewDek":"","curationEligibleAt":0,"primaryTopicId":"ae5d4995e225","type":"Post"},"35aee1a28404":{"id":"35aee1a28404","versionId":"121a1d7814dd","creatorId":"c79695e37339","homeCollectionId":"7f60cf5620c9","title":"Hyper-parameters in Action! Part II - Weight Initializers","detectedLanguage":"en","latestVersion":"121a1d7814dd","latestPublishedVersion":"121a1d7814dd","hasUnpublishedEdits":false,"latestRev":5566,"createdAt":1528557278114,"updatedAt":1543845580555,"acceptedAt":0,"firstPublishedAt":1529341450841,"latestPublishedAt":1543845580555,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"In this post, I will show you the importance of properly initializing the weights of your deep neural network.","postDisplay":{"coverless":true},"metaDescription":"This is the second post of my series on hyper-parameters. In this post, I will show you the importance of properly initializing the weights of your deep neural network. We will start with a naive…"},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"0*bXkY3UaSDaXKyMqE","filter":"","backgroundSize":"","originalWidth":4928,"originalHeight":3264,"strategy":"resample","height":0,"width":0},"wordCount":3720,"imageCount":36,"readingTime":16.587735849056603,"subtitle":"In this post, I will show you the importance of properly initializing the weights of your deep neural network.","publishedInCount":1,"usersBySocialRecommends":[],"noIndex":false,"recommends":94,"isBookmarked":false,"tags":[{"slug":"machine-learning","name":"Machine Learning","postCount":70488,"metadata":{"postCount":70488,"coverImage":{"id":"1*p9A1742mTraDjk1YufM8Bw.png","originalWidth":1366,"originalHeight":922,"isFeatured":true}},"type":"Tag"},{"slug":"visualization","name":"Visualization","postCount":2569,"metadata":{"postCount":2569,"coverImage":{"id":"1*GZR28slKCtV8LfYeFd9FbA.png","originalWidth":1866,"originalHeight":1224,"isFeatured":true}},"type":"Tag"},{"slug":"deep-learning","name":"Deep Learning","postCount":17387,"metadata":{"postCount":17387,"coverImage":{"id":"1*S_OcBPkRTpKJo0iz5IaNbQ.png","originalWidth":967,"originalHeight":570,"isFeatured":true}},"type":"Tag"},{"slug":"keras","name":"Keras","postCount":1112,"metadata":{"postCount":1112,"coverImage":{"id":"1*gTPr4LyZTCC0dsnnE1hCAA.png","originalWidth":1204,"originalHeight":727,"isFeatured":true}},"type":"Tag"},{"slug":"towards-data-science","name":"Towards Data Science","postCount":2159,"metadata":{"postCount":2159,"coverImage":{"id":"1*mWV37dTAOl6WxxJc37ssjg.jpeg","originalWidth":3000,"originalHeight":1994,"isFeatured":true}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":5,"links":{"entries":[{"url":"https://keras.io/initializers/#variancescaling","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@aggergakker?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://unsplash.com?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://towardsdatascience.com/hyper-parameters-in-action-a524bf5bf1c","alts":[{"type":2,"url":"medium://p/a524bf5bf1c"},{"type":3,"url":"medium://p/a524bf5bf1c"}],"httpStatus":200},{"url":"http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf","alts":[],"httpStatus":200},{"url":"https://intoli.com/blog/neural-network-initialization/","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Variance#Product_of_independent_variables","alts":[],"httpStatus":200},{"url":"https://github.com/dvgodoy/deepreplay","alts":[],"httpStatus":200},{"url":"https://towardsdatascience.com/hyper-parameters-in-action-introducing-deepreplay-31132a7b9631","alts":[{"type":2,"url":"medium://p/31132a7b9631"},{"type":3,"url":"medium://p/31132a7b9631"}],"httpStatus":200},{"url":"https://mnsgrg.com/2017/12/21/xavier-initialization/#logistic-activation","alts":[],"httpStatus":200},{"url":"https://twitter.com/dvgodoy","alts":[{"type":2,"url":"twitter://user?screen_name=dvgodoy"},{"type":3,"url":"twitter://user?screen_name=dvgodoy"}],"httpStatus":200},{"url":"https://arxiv.org/pdf/1502.01852.pdf","alts":[],"httpStatus":200}],"version":"0.3","generatedAt":1543845582092},"isLockedPreviewOnly":false,"metaDescription":"This is the second post of my series on hyper-parameters. In this post, I will show you the importance of properly initializing the weights of your deep neural network. We will start with a naive…","totalClapCount":705,"sectionCount":1,"readingList":0,"topics":[]},"coverless":true,"slug":"hyper-parameters-in-action-part-ii-weight-initializers","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":false,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewImage","type":4,"text":"","layout":10,"metadata":{"id":"0*bXkY3UaSDaXKyMqE","originalWidth":4928,"originalHeight":3264}},{"name":"previewTitle","type":3,"text":"Hyper-parameters in Action! Part II - Weight Initializers","alignment":1},{"name":"previewSubtitle","type":13,"text":"In this post, I will show you the importance…","alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false,"subtitle":"In this post, I will show you the importance of properly initializing the weights of your deep neural network."},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"","approvedHomeCollectionId":"7f60cf5620c9","newsletterId":"","webCanonicalUrl":"","mediumUrl":"","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"mongerRequestType":1,"layerCake":4,"socialTitle":"","socialDek":"","editorialPreviewTitle":"","editorialPreviewDek":"","curationEligibleAt":0,"type":"Post"},"31132a7b9631":{"id":"31132a7b9631","versionId":"5d5ecf5201b9","creatorId":"c79695e37339","homeCollectionId":"7f60cf5620c9","title":"Hyper-parameters in Action! Introducing DeepReplay","detectedLanguage":"en","latestVersion":"5d5ecf5201b9","latestPublishedVersion":"5d5ecf5201b9","hasUnpublishedEdits":false,"latestRev":2084,"createdAt":1525035662880,"updatedAt":1543845564138,"acceptedAt":0,"firstPublishedAt":1525383675155,"latestPublishedAt":1543845564138,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"Introduction","postDisplay":{"coverless":true}},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"0*ZB4D380Kh2Y33925.","filter":"","backgroundSize":"","originalWidth":4928,"originalHeight":3264,"strategy":"resample","height":0,"width":0},"wordCount":1544,"imageCount":8,"readingTime":6.959748427672956,"subtitle":"Introduction","publishedInCount":1,"usersBySocialRecommends":[],"noIndex":false,"recommends":271,"isBookmarked":false,"tags":[{"slug":"machine-learning","name":"Machine Learning","postCount":70488,"metadata":{"postCount":70488,"coverImage":{"id":"1*p9A1742mTraDjk1YufM8Bw.png","originalWidth":1366,"originalHeight":922,"isFeatured":true}},"type":"Tag"},{"slug":"deep-learning","name":"Deep Learning","postCount":17387,"metadata":{"postCount":17387,"coverImage":{"id":"1*S_OcBPkRTpKJo0iz5IaNbQ.png","originalWidth":967,"originalHeight":570,"isFeatured":true}},"type":"Tag"},{"slug":"data-visualization","name":"Data Visualization","postCount":14413,"metadata":{"postCount":14413,"coverImage":{"id":"1*Aom0Yz2zVQZdBiiByborCA.png","originalWidth":1536,"originalHeight":392,"isFeatured":true}},"type":"Tag"},{"slug":"python","name":"Python","postCount":27861,"metadata":{"postCount":27861,"coverImage":{"id":"0*Q4I1Iczn-0LcZhIl","originalWidth":400,"originalHeight":313,"isFeatured":true}},"type":"Tag"},{"slug":"towards-data-science","name":"Towards Data Science","postCount":2159,"metadata":{"postCount":2159,"coverImage":{"id":"1*mWV37dTAOl6WxxJc37ssjg.jpeg","originalWidth":3000,"originalHeight":1994,"isFeatured":true}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":1,"links":{"entries":[{"url":"https://twitter.com/dvgodoy","alts":[{"type":2,"url":"twitter://user?screen_name=dvgodoy"},{"type":3,"url":"twitter://user?screen_name=dvgodoy"}],"httpStatus":200},{"url":"https://unsplash.com?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":200},{"url":"https://medium.com/hipster-color-science/computing-2d-affine-transformations-using-only-matrix-multiplication-2ccb31b52181","alts":[{"type":2,"url":"medium://p/2ccb31b52181"},{"type":3,"url":"medium://p/2ccb31b52181"}],"httpStatus":200},{"url":"https://github.com/dvgodoy/deepreplay","alts":[],"httpStatus":200},{"url":"https://unsplash.com/@makroman?utm_source=medium&utm_medium=referral","alts":[],"httpStatus":404},{"url":"https://matplotlib.org/users/gridspec.html","alts":[],"httpStatus":200},{"url":"http://deepreplay.readthedocs.io/en/latest/deepreplay.html#deepreplay.plot.compose_plots","alts":[],"httpStatus":200},{"url":"http://deepreplay.readthedocs.io/en/latest/deepreplay.html#deepreplay.callbacks.ReplayData","alts":[],"httpStatus":200},{"url":"http://deepreplay.readthedocs.io/en/latest/deepreplay.html#deepreplay.replay.Replay.build_probability_histogram","alts":[],"httpStatus":200},{"url":"http://deepreplay.readthedocs.io/en/latest/deepreplay.html#deepreplay.replay.Replay.build_loss_histogram","alts":[],"httpStatus":200},{"url":"http://deepreplay.readthedocs.io/en/latest/deepreplay.html#deepreplay.replay.Replay.build_loss_and_metric","alts":[],"httpStatus":200},{"url":"http://deepreplay.readthedocs.io/en/latest/deepreplay.html#deepreplay.replay.Replay","alts":[],"httpStatus":200},{"url":"http://deepreplay.readthedocs.io/en/latest/deepreplay.html#deepreplay.plot.compose_animations","alts":[],"httpStatus":200},{"url":"http://deepreplay.readthedocs.io/en/latest/deepreplay.html#deepreplay.replay.Replay.build_feature_space","alts":[],"httpStatus":200},{"url":"http://deepreplay.readthedocs.io/en/latest/deepreplay.html#deepreplay.replay.Replay.build_decision_boundary","alts":[],"httpStatus":200},{"url":"https://github.com/dvgodoy/deepreplay/blob/master/examples/part1_activation_functions.py","alts":[],"httpStatus":200},{"url":"https://towardsdatascience.com/hyper-parameters-in-action-a524bf5bf1c","alts":[{"type":2,"url":"medium://p/a524bf5bf1c"},{"type":3,"url":"medium://p/a524bf5bf1c"}],"httpStatus":200},{"url":"https://towardsdatascience.com/deep-inside-autoencoders-7e41f319999f","alts":[{"type":2,"url":"medium://p/7e41f319999f"},{"type":3,"url":"medium://p/7e41f319999f"}],"httpStatus":200},{"url":"https://github.com/dvgodoy/deepreplay/blob/master/notebooks/circles_dataset.ipynb","alts":[],"httpStatus":200},{"url":"https://github.com/dvgodoy/deepreplay/blob/master/notebooks/UCI_spambase_dataset.ipynb","alts":[],"httpStatus":200},{"url":"https://github.com/dvgodoy/deepreplay/blob/master/notebooks/moons_dataset.ipynb","alts":[],"httpStatus":200},{"url":"https://github.com/dvgodoy/deepreplay/blob/master/notebooks/part1_activation_functions.ipynb","alts":[],"httpStatus":200}],"version":"0.3","generatedAt":1543845565507},"isLockedPreviewOnly":false,"metaDescription":"","totalClapCount":1793,"sectionCount":1,"readingList":0,"topics":[{"topicId":"ae5d4995e225","slug":"data-science","createdAt":1493923906289,"deletedAt":0,"image":{"id":"1*NHWOEki_ncCX-xzbKtkEWw@2x.jpeg","originalWidth":5760,"originalHeight":3840},"name":"Data Science","description":"Query this.","relatedTopics":[],"visibility":1,"relatedTags":[],"relatedTopicIds":[],"type":"Topic"}]},"coverless":true,"slug":"hyper-parameters-in-action-introducing-deepreplay","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":true,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"hyper-parameters-in-action-introducing-deepreplay-31132a7b9631","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewImage","type":4,"text":"","layout":10,"metadata":{"id":"0*ZB4D380Kh2Y33925.","originalWidth":4928,"originalHeight":3264,"isFeatured":true}},{"name":"b1a9","type":3,"text":"Hyper-parameters in Action! Introducing DeepReplay","markups":[],"alignment":1},{"name":"492b","type":3,"text":"Introduction","markups":[],"alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false,"subtitle":"Introduction"},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"","approvedHomeCollectionId":"7f60cf5620c9","newsletterId":"","webCanonicalUrl":"","mediumUrl":"","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"mongerRequestType":1,"layerCake":3,"socialTitle":"","socialDek":"","editorialPreviewTitle":"","editorialPreviewDek":"","curationEligibleAt":0,"primaryTopicId":"ae5d4995e225","type":"Post"},"a524bf5bf1c":{"id":"a524bf5bf1c","versionId":"88ba842fdf97","creatorId":"c79695e37339","homeCollectionId":"7f60cf5620c9","title":"Hyper-parameters in action!","detectedLanguage":"en","latestVersion":"88ba842fdf97","latestPublishedVersion":"88ba842fdf97","hasUnpublishedEdits":false,"latestRev":3050,"createdAt":1521583109979,"updatedAt":1543845529014,"acceptedAt":0,"firstPublishedAt":1522933629721,"latestPublishedAt":1543845529014,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"Part I — Activation Functions","postDisplay":{"coverless":true},"metaDescription":"This is the first of a series of posts aiming at presenting in a clear, concise and as much visual as possible fashion, some of the fundamental moving parts of training a neural network."},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"1*2Zk3gPVcNOKlU0XjzJh48g.png","filter":"","backgroundSize":"","originalWidth":3000,"originalHeight":600,"strategy":"resample","height":0,"width":0},"wordCount":2265,"imageCount":17,"readingTime":10.147169811320754,"subtitle":"Part I — Activation Functions","publishedInCount":1,"usersBySocialRecommends":[],"noIndex":false,"recommends":326,"isBookmarked":false,"tags":[{"slug":"machine-learning","name":"Machine Learning","postCount":70488,"metadata":{"postCount":70488,"coverImage":{"id":"1*p9A1742mTraDjk1YufM8Bw.png","originalWidth":1366,"originalHeight":922,"isFeatured":true}},"type":"Tag"},{"slug":"deep-learning","name":"Deep Learning","postCount":17387,"metadata":{"postCount":17387,"coverImage":{"id":"1*S_OcBPkRTpKJo0iz5IaNbQ.png","originalWidth":967,"originalHeight":570,"isFeatured":true}},"type":"Tag"},{"slug":"activation-functions","name":"Activation Functions","postCount":72,"metadata":{"postCount":72,"coverImage":{"id":"1*vD3OPhPkeFK1pTkCoTs02A.jpeg","originalWidth":5184,"originalHeight":3456,"isFeatured":true}},"type":"Tag"},{"slug":"towards-data-science","name":"Towards Data Science","postCount":2159,"metadata":{"postCount":2159,"coverImage":{"id":"1*mWV37dTAOl6WxxJc37ssjg.jpeg","originalWidth":3000,"originalHeight":1994,"isFeatured":true}},"type":"Tag"},{"slug":"data-science","name":"Data Science","postCount":46553,"metadata":{"postCount":46553,"coverImage":{"id":"1*lTH3uYF9zSyjUZ1WwLc4tg.png","originalWidth":1200,"originalHeight":578,"isFeatured":true}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":10,"links":{"entries":[{"url":"http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Answer_to_the_Ultimate_Question_of_Life,_the_Universe,_and_Everything_%2842%29","alts":[],"httpStatus":200},{"url":"https://medium.com/hipster-color-science/computing-2d-affine-transformations-using-only-matrix-multiplication-2ccb31b52181","alts":[{"type":3,"url":"medium://p/2ccb31b52181"},{"type":2,"url":"medium://p/2ccb31b52181"}],"httpStatus":200},{"url":"https://towardsdatascience.com/hyper-parameters-in-action-introducing-deepreplay-31132a7b9631","alts":[{"type":2,"url":"medium://p/31132a7b9631"},{"type":3,"url":"medium://p/31132a7b9631"}],"httpStatus":200},{"url":"https://twitter.com/dvgodoy","alts":[{"type":2,"url":"twitter://user?screen_name=dvgodoy"},{"type":3,"url":"twitter://user?screen_name=dvgodoy"}],"httpStatus":200},{"url":"https://github.com/dvgodoy/deepreplay","alts":[],"httpStatus":200},{"url":"https://medium.com/@weakish","alts":[{"type":2,"url":"medium://@weakish"},{"type":3,"url":"medium://@weakish"}],"httpStatus":200},{"url":"https://www.jqr.com/article/000161","alts":[],"httpStatus":200}],"version":"0.3","generatedAt":1543845532795},"isLockedPreviewOnly":false,"metaDescription":"This is the first of a series of posts aiming at presenting in a clear, concise and as much visual as possible fashion, some of the fundamental moving parts of training a neural network.","totalClapCount":1930,"sectionCount":3,"readingList":0,"topics":[{"topicId":"ae5d4995e225","slug":"data-science","createdAt":1493923906289,"deletedAt":0,"image":{"id":"1*NHWOEki_ncCX-xzbKtkEWw@2x.jpeg","originalWidth":5760,"originalHeight":3840},"name":"Data Science","description":"Query this.","relatedTopics":[],"visibility":1,"relatedTags":[],"relatedTopicIds":[],"type":"Topic"}]},"coverless":true,"slug":"hyper-parameters-in-action","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":false,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"hyper-parameters-in-action-a524bf5bf1c","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewImage","type":4,"text":"","layout":10,"metadata":{"id":"1*2Zk3gPVcNOKlU0XjzJh48g.png","originalWidth":3000,"originalHeight":600,"isFeatured":true}},{"name":"previewTitle","type":3,"text":"Hyper-parameters in action!","alignment":1},{"name":"previewSubtitle","type":13,"text":"Part I — Activation Functions","alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false,"subtitle":"Part I — Activation Functions"},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"","approvedHomeCollectionId":"7f60cf5620c9","newsletterId":"","webCanonicalUrl":"","mediumUrl":"","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"mongerRequestType":1,"layerCake":3,"socialTitle":"","socialDek":"","editorialPreviewTitle":"","editorialPreviewDek":"","curationEligibleAt":0,"primaryTopicId":"ae5d4995e225","type":"Post"}},"Social":{"c79695e37339":{"userId":"3751a3493996","targetUserId":"c79695e37339","type":"Social"}},"SocialStats":{"c79695e37339":{"userId":"c79695e37339","usersFollowedCount":39,"usersFollowedByCount":705,"type":"SocialStats"}}},"paging":{"path":"https://medium.com/_/api/users/c79695e37339/profile/stream","next":{"limit":10,"to":"1522933629721","source":"publication-profile","ignoredIds":[],"page":1,"collectionId":"7f60cf5620c9"}},"streamItems":[{"createdAt":1558100580436,"postPreview":{"postId":"81fc5f8c4e8e"},"randomId":"877a675b5a4d","itemType":"postPreview","type":"StreamItem"},{"createdAt":1558100580436,"postPreview":{"postId":"3b1e69c12b4f"},"randomId":"60cea9518168","itemType":"postPreview","type":"StreamItem"},{"createdAt":1558100580436,"postPreview":{"postId":"690ddad7803"},"randomId":"af95d753f777","itemType":"postPreview","type":"StreamItem"},{"createdAt":1558100580436,"postPreview":{"postId":"a3ac6025181a"},"randomId":"9c924050c06b","itemType":"postPreview","type":"StreamItem"},{"createdAt":1558100580436,"postPreview":{"postId":"5f1bcea9039e"},"randomId":"981bc2e58960","itemType":"postPreview","type":"StreamItem"},{"createdAt":1558100580436,"postPreview":{"postId":"35aee1a28404"},"randomId":"5aaed881c6","itemType":"postPreview","type":"StreamItem"},{"createdAt":1558100580436,"postPreview":{"postId":"31132a7b9631"},"randomId":"11adc457543","itemType":"postPreview","type":"StreamItem"},{"createdAt":1558100580436,"postPreview":{"postId":"a524bf5bf1c"},"randomId":"ffaa865c4ebd","itemType":"postPreview","type":"StreamItem"}],"user":{"userId":"c79695e37339","name":"Daniel Godoy","username":"dvgodoy","createdAt":1521582859830,"imageId":"1*7kL4DitERABkDkP-caSAZA.png","backgroundImageId":"","bio":"Senior Data Scientist. Teacher @ Data Science Retreat","twitterScreenName":"dvgodoy","facebookAccountId":"1714299755315485","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"isWriterProgramEnrolled":true,"isQuarantined":false,"type":"User"},"userMeta":{"numberOfPostsPublished":34,"userId":"c79695e37339","userSuggestionReason":{"followeesWhoFollow":{"users":[]},"reason":"followeesWhoFollow"},"collectionIds":["9d9d52805eca","34c9bdb05ea2"],"authorTags":[{"slug":"food","name":"Food","postCount":119311,"metadata":{"postCount":119311,"coverImage":{"id":"1*jv_5N8d2VvmOzd8uROiuaw.jpeg"}},"type":"Tag"},{"slug":"machine-learning","name":"Machine Learning","postCount":70488,"metadata":{"postCount":70488,"coverImage":{"id":"1*p9A1742mTraDjk1YufM8Bw.png","originalWidth":1366,"originalHeight":922,"isFeatured":true}},"type":"Tag"},{"slug":"data-science","name":"Data Science","postCount":46553,"metadata":{"postCount":46553,"coverImage":{"id":"1*lTH3uYF9zSyjUZ1WwLc4tg.png","originalWidth":1200,"originalHeight":578,"isFeatured":true}},"type":"Tag"},{"slug":"deep-learning","name":"Deep Learning","postCount":17387,"metadata":{"postCount":17387,"coverImage":{"id":"1*S_OcBPkRTpKJo0iz5IaNbQ.png","originalWidth":967,"originalHeight":570,"isFeatured":true}},"type":"Tag"},{"slug":"project-management","name":"Project Management","postCount":15760,"metadata":{"postCount":15760,"coverImage":{"id":"1*bn3akymtDup8OCILlYv8nA.jpeg","originalWidth":3456,"originalHeight":2304,"isFeatured":true}},"type":"Tag"},{"slug":"tutorial","name":"Tutorial","postCount":14346,"metadata":{"postCount":14346,"coverImage":{"id":"1*mtho0xL9Qu-cXu61XeLrdA.jpeg","originalWidth":4912,"originalHeight":2760,"isFeatured":true}},"type":"Tag"},{"slug":"visualization","name":"Visualization","postCount":2569,"metadata":{"postCount":2569,"coverImage":{"id":"1*GZR28slKCtV8LfYeFd9FbA.png","originalWidth":1866,"originalHeight":1224,"isFeatured":true}},"type":"Tag"},{"slug":"workflow","name":"Workflow","postCount":2232,"metadata":{"postCount":2232,"coverImage":{"id":"0*tg2M13NuobQTBRrm","originalWidth":2016,"originalHeight":1134,"isFeatured":true}},"type":"Tag"},{"slug":"towards-data-science","name":"Towards Data Science","postCount":2159,"metadata":{"postCount":2159,"coverImage":{"id":"1*mWV37dTAOl6WxxJc37ssjg.jpeg","originalWidth":3000,"originalHeight":1994,"isFeatured":true}},"type":"Tag"},{"slug":"pandas","name":"Pandas","postCount":1189,"metadata":{"postCount":1189,"coverImage":{"id":"1*e_QOu6jsHfDuyOEW7wG3BQ.png","originalWidth":810,"originalHeight":451,"isFeatured":true}},"type":"Tag"},{"slug":"apache-spark","name":"Apache Spark","postCount":1125,"metadata":{"postCount":1125,"coverImage":{"id":"0*HwnSXuF99iFBtNYT","originalWidth":3862,"originalHeight":2578,"isFeatured":true,"unsplashPhotoId":"_Ch_onWf38o"}},"type":"Tag"},{"slug":"keras","name":"Keras","postCount":1112,"metadata":{"postCount":1112,"coverImage":{"id":"1*gTPr4LyZTCC0dsnnE1hCAA.png","originalWidth":1204,"originalHeight":727,"isFeatured":true}},"type":"Tag"},{"slug":"classification","name":"Classification","postCount":818,"metadata":{"postCount":818,"coverImage":{"id":"1*S_OcBPkRTpKJo0iz5IaNbQ.png","originalWidth":967,"originalHeight":570,"isFeatured":true}},"type":"Tag"},{"slug":"evaluation","name":"Evaluation","postCount":807,"metadata":{"postCount":807,"coverImage":{"id":"1*pLd-nWflD8ffj5FMu7EEYA.png","originalWidth":700,"originalHeight":441,"isFeatured":true}},"type":"Tag"},{"slug":"pytorch","name":"Pytorch","postCount":649,"metadata":{"postCount":649,"coverImage":{"id":"1*ytjIHXnlUOS6dKlCk1nNrA.png","originalWidth":4727,"originalHeight":2773,"isFeatured":true}},"type":"Tag"},{"slug":"entropy","name":"Entropy","postCount":324,"metadata":{"postCount":324,"coverImage":{"id":"1*z-4Jf9apbzR8pGb21zp4Yg.jpeg","originalWidth":1149,"originalHeight":791,"isFeatured":true}},"type":"Tag"},{"slug":"exploratory-data-analysis","name":"Exploratory Data Analysis","postCount":258,"metadata":{"postCount":258,"coverImage":{"id":"0*N8BVwsKl505JGGZu","originalWidth":1000,"originalHeight":667,"isFeatured":true}},"type":"Tag"},{"slug":"pyspark","name":"Pyspark","postCount":235,"metadata":{"postCount":235,"coverImage":{"id":"1*3PaATZRAXVWv6Rbu7lPLJg.png","originalWidth":881,"originalHeight":585,"isFeatured":true}},"type":"Tag"},{"slug":"gestao-de-projetos","name":"Gestao De Projetos","postCount":186,"metadata":{"postCount":186,"coverImage":{"id":"0*GPOsufu8jH-jrS2W.png","originalWidth":1259,"originalHeight":786,"isFeatured":true}},"type":"Tag"},{"slug":"loss-function","name":"Loss Function","postCount":68,"metadata":{"postCount":68,"coverImage":{"id":"0*BJZqDD5ieVE6XxdD","originalWidth":4000,"originalHeight":2667,"isFeatured":true,"unsplashPhotoId":"uCMKx2H1Y38"}},"type":"Tag"},{"slug":"ensina-ai","name":"Ensina Ai","postCount":0,"metadata":{"postCount":0,"coverImage":{"id":"1*ynPayTw1K70vXZvvn4a8qw.png","originalWidth":3000,"originalHeight":600,"isFeatured":true}},"type":"Tag"}],"featuredPostId":"","topWriterInTags":[],"type":"UserMeta"},"userNavItemList":{"userNavItems":[{"title":"Profile","url":"https://medium.com/@dvgodoy","systemItem":{"systemType":1},"navType":"systemItem"},{"title":"Claps","url":"https://medium.com/@dvgodoy/has-recommended","systemItem":{"systemType":4},"navType":"systemItem"},{"title":"Responses","url":"https://medium.com/@dvgodoy/responses","systemItem":{"systemType":3},"navType":"systemItem"}]},"userNavActiveIndex":-1,"collection":{"id":"7f60cf5620c9","name":"Towards Data Science","slug":"towards-data-science","tags":["DATA SCIENCE","MACHINE LEARNING","ARTIFICIAL INTELLIGENCE","ANALYTICS","PROGRAMMING"],"creatorId":"895063a310f4","description":"Sharing concepts, ideas, and codes.","shortDescription":"Sharing concepts, ideas, and codes.","image":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":216483,"activeAt":1558099624520},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"1*5EUO1kUYBthpOCPzRj_l2g.png","filter":"","backgroundSize":"","originalWidth":1010,"originalHeight":376,"strategy":"resample","height":0,"width":0},"twitterUsername":"TDataScience","facebookPageName":"towardsdatascience","collectionMastheadId":"8b6aceffde6","domain":"towardsdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["1995d56e4208","dd515a628896"]}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["e8a6d5639781","9ad95baa6bfe","edec1e9ad8c"],"sectionHeader":"Featured "}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":6,"postIds":[],"sectionHeader":"Latest"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["ae4a955e515f","11e7b1ad12f3"],"sectionHeader":"Our Letters"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"897911940e9a"}},{"type":1,"postListMetadata":{"source":2,"layout":4,"number":6,"postIds":[],"sectionHeader":"Trending"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["3bf37f75a345","3920888f831c"],"sectionHeader":"Our Readers’ Guide"}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":9,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Editors' Picks"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["96667b06af5","d691af11cc2f"],"sectionHeader":"Contribute"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["eea5e903499c","766cdd74d13e"]}},{"type":1,"postListMetadata":{"source":4,"layout":5,"number":3,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Last Chance To Read"}}],"tintColor":"#FF355876","lightText":true,"favicon":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF668AAA","point":0},{"color":"#FF61809D","point":0.1},{"color":"#FF5A7690","point":0.2},{"color":"#FF546C83","point":0.3},{"color":"#FF4D6275","point":0.4},{"color":"#FF455768","point":0.5},{"color":"#FF3D4C5A","point":0.6},{"color":"#FF34414C","point":0.7},{"color":"#FF2B353E","point":0.8},{"color":"#FF21282F","point":0.9},{"color":"#FF161B1F","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF355876","point":0},{"color":"#FF4D6C88","point":0.1},{"color":"#FF637F99","point":0.2},{"color":"#FF7791A8","point":0.3},{"color":"#FF8CA2B7","point":0.4},{"color":"#FF9FB3C6","point":0.5},{"color":"#FFB2C3D4","point":0.6},{"color":"#FFC5D2E1","point":0.7},{"color":"#FFD7E2EE","point":0.8},{"color":"#FFE9F1FA","point":0.9},{"color":"#FFFBFFFF","point":1}],"backgroundColor":"#FF355876"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEDF4FC","point":0},{"color":"#FFE9F2FD","point":0.1},{"color":"#FFE6F1FD","point":0.2},{"color":"#FFE2EFFD","point":0.3},{"color":"#FFDFEEFD","point":0.4},{"color":"#FFDBECFE","point":0.5},{"color":"#FFD7EBFE","point":0.6},{"color":"#FFD4E9FE","point":0.7},{"color":"#FFD0E7FF","point":0.8},{"color":"#FFCCE6FF","point":0.9},{"color":"#FFC8E4FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":4,"title":"Data Science","url":"https://towardsdatascience.com/data-science/home","topicId":"cf416843aadc","source":"topicId"},{"type":4,"title":"Machine Learning","url":"https://towardsdatascience.com/machine-learning/home","topicId":"a5c9b2f1cb6b","source":"topicId"},{"type":4,"title":"Programming","url":"https://towardsdatascience.com/programming/home","topicId":"41533a1dc73c","source":"topicId"},{"type":4,"title":"Visualization","url":"https://towardsdatascience.com/data-visualization/home","topicId":"825e6cb8b9ce","source":"topicId"},{"type":4,"title":"AI","url":"https://towardsdatascience.com/artificial-intelligence/home","topicId":"7f029b17bf96","source":"topicId"},{"type":4,"title":"Journalism","url":"https://towardsdatascience.com/data-journalism/home","topicId":"27a6ac3980c6","source":"topicId"},{"type":4,"title":"Picks","url":"https://towardsdatascience.com/editors-picks/home","topicId":"e81f4fc5ee6b","source":"topicId"},{"type":3,"title":"Contribute","url":"https://towardsdatascience.com/contribute/home"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-19707169-24","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5},"paidForDomainAt":1509037374118,"type":"Collection"},"profileTypeName":"publication-profile","isStandaloneEditPage":false})
// ]]></script><script>window.PARSELY = window.PARSELY || { autotrack: false }</script><script id="parsely-cfg" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/p.js"></script><script type="text/javascript">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0); branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled':  false }, function(err, data) {});</script><div class="surface-scrollOverlay"></div><script charset="UTF-8" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/main-common-async.bundle.AHOyO-i_kQOPVtd1D3V-Ag.js"></script><script charset="UTF-8" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/main-misc-screens.bundle.uSIdxZUQ14HRMlktssa7EQ.js"></script><script charset="UTF-8" src="./Understanding PyTorch with an example_ a step-by-step tutorial_files/main-notes.bundle.A5--rZtpdvaRMBwFRU9JAg.js"></script></body></html>